{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 라이브러리 설치\n",
    "\n",
    "- 참고: ```!```는 주피터 노트에서 터미널 명령어를 실행할 때 사용하는 접두어입니다\n",
    "```bash\n",
    "!pip install pandas numpy\n",
    "```"
   ],
   "id": "304b7f91649d9ffb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T05:03:50.845611Z",
     "start_time": "2025-09-08T05:03:49.250815Z"
    }
   },
   "cell_type": "code",
   "source": "!pip -q install pandas numpy",
   "id": "72c468c45a862af",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-08T05:04:01.076680Z",
     "start_time": "2025-09-08T05:04:01.071999Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"pandas 버전:\", pd.__version__)\n",
    "print(\"numpy 버전:\", np.__version__)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas 버전: 2.3.1\n",
      "numpy 버전: 2.3.2\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T05:06:11.137762Z",
     "start_time": "2025-09-08T05:06:11.079484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 나의 csv 파일 가져오기[나중에 함수의 인풋을 이것으로 할것이다]\n",
    "\n",
    "csv_path = \"anilife_data_20250908_102635.csv\"\n",
    "\n",
    "\n",
    "# pandas의 csv를 데이터 프레임으로 바꾸는 함수입니다\n",
    "anilife_data = pd.read_csv(csv_path)\n",
    "\n",
    "# 총 데이터 수와 칼럼 이름확인\n",
    "print(f\"총{len(anime_data)}\")\n",
    "print(f\"칼럼 목록: {list(anime_data.columns)}\")"
   ],
   "id": "dbf994fd59fac2ce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총4453\n",
      "칼럼 목록: ['id', 'title_korean', 'title_japanese', 'title_english', 'year', 'quarter', 'genres', 'tags', 'synopsis', 'num_characters', 'main_characters', 'director', 'studio', 'original_work', 'error', 'comprehensive_features']\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "- 구조만 알고 싶다면 이걸 쓰면 된다 - 시간된다면 자주쓰는건 정리해보도록하겠다\n",
    "```\n",
    "anime_data.info()\n",
    "```"
   ],
   "id": "b22605ae8743fe72"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T05:07:04.806468Z",
     "start_time": "2025-09-08T05:07:04.794954Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 데이터 전체 구조 확인 (컬럼, 데이터타입, 결측치 등)\n",
    "anime_data.info()\n"
   ],
   "id": "466d85030f054d1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4453 entries, 0 to 4452\n",
      "Data columns (total 16 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   id                      4453 non-null   int64  \n",
      " 1   title_korean            4453 non-null   object \n",
      " 2   title_japanese          3991 non-null   object \n",
      " 3   title_english           3994 non-null   object \n",
      " 4   year                    4429 non-null   float64\n",
      " 5   quarter                 4429 non-null   object \n",
      " 6   genres                  3983 non-null   object \n",
      " 7   tags                    3916 non-null   object \n",
      " 8   synopsis                4453 non-null   object \n",
      " 9   num_characters          4453 non-null   int64  \n",
      " 10  main_characters         3912 non-null   object \n",
      " 11  director                3545 non-null   object \n",
      " 12  studio                  3936 non-null   object \n",
      " 13  original_work           2513 non-null   object \n",
      " 14  error                   0 non-null      float64\n",
      " 15  comprehensive_features  4453 non-null   object \n",
      "dtypes: float64(2), int64(2), object(12)\n",
      "memory usage: 556.8+ KB\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T05:07:11.989828Z",
     "start_time": "2025-09-08T05:07:11.974949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 맨 앞 3개의 행(애니메이션 데이터) 출력\n",
    "anime_data.head(3)\n"
   ],
   "id": "20daf9075e30cb05",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    id title_korean title_japanese      title_english    year quarter  \\\n",
       "0  110        꿈속의 뮤     ミュークルドリーミー       Mewkledreamy  2020.0     2분기   \n",
       "1  102     일하는 세포!!       はたらく細胞!!  Hataraku Saibou!!  2021.0     1분기   \n",
       "2  103       블라드 러브          ぶらどらぶ          Vlad Love  2021.0     1분기   \n",
       "\n",
       "             genres                                               tags  \\\n",
       "0  모험|코미디|판타지|마법 소녀  여성 주인공|어린이|에피소딕|주로 아이 캐스트|테니스|동물|주로 여성 캐스트|귀여운...   \n",
       "1         액션|코미디|SF  교육|앙상블 캐스트|의학|일|여성 주인공|소년 만화|남성 주인공|에피소딕|고어|인간...   \n",
       "2           코미디|초자연  뱀파이어|때림 개그|여성 주인공|풍자|메타|괴상한 코미디|풍자|주로 여성 캐스트|학...   \n",
       "\n",
       "                                            synopsis  num_characters  \\\n",
       "0  연애와 우정, 마음의 상냥함을 그리는 귀여운 드리밍 스토리(恋や友情、心のやさしさを描...               6   \n",
       "1  이것은 당신의 이야기이자, 당신 몸속의 이야기.사람의 세포 수는 약 37조개.세포들...               6   \n",
       "2                                     등록된 줄거리가 없습니다.               6   \n",
       "\n",
       "                                     main_characters   director  \\\n",
       "0  뮤(토요사키 아이세)|페코(쿠보 유리카)|히나타 유메(무라카미 나츠미)|수우(칸모토...  사쿠라이 히로아키   \n",
       "1  U-1146 핫케큐우(마에노 토모아키)|사이보우 이판(코바야시 유스케)|AE3803...   오구라 히로후미   \n",
       "2  밤바 미츠구(사쿠라 아야네)|트란실바니아 블라드 마이(히다카 리나)|치마츠리 치히로...    니시무라 준지   \n",
       "\n",
       "                                     studio original_work  error  \\\n",
       "0  J.C. 스태프, A.C.G.T., TV 도쿄, ADK 이모션즈, 산리오           NaN    NaN   \n",
       "1    데이비드 프로덕션, 매직 캡슐, 애니플렉스, 코단샤, 애니플렉스 미국       시미즈 아카네    NaN   \n",
       "2       드라이브, 프로덕션 I.G, 이치고 애니메이션, 만화 애니메이션       오시이 마모루    NaN   \n",
       "\n",
       "                              comprehensive_features  \n",
       "0  제목: 꿈속의 뮤 | 제작연도: 2020 | 방영분기: 2분기 | 장르: 모험|코미...  \n",
       "1  제목: 일하는 세포!! | 제작연도: 2021 | 방영분기: 1분기 | 장르: 액션...  \n",
       "2  제목: 블라드 러브 | 제작연도: 2021 | 방영분기: 1분기 | 장르: 코미디|...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title_korean</th>\n",
       "      <th>title_japanese</th>\n",
       "      <th>title_english</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>genres</th>\n",
       "      <th>tags</th>\n",
       "      <th>synopsis</th>\n",
       "      <th>num_characters</th>\n",
       "      <th>main_characters</th>\n",
       "      <th>director</th>\n",
       "      <th>studio</th>\n",
       "      <th>original_work</th>\n",
       "      <th>error</th>\n",
       "      <th>comprehensive_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110</td>\n",
       "      <td>꿈속의 뮤</td>\n",
       "      <td>ミュークルドリーミー</td>\n",
       "      <td>Mewkledreamy</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2분기</td>\n",
       "      <td>모험|코미디|판타지|마법 소녀</td>\n",
       "      <td>여성 주인공|어린이|에피소딕|주로 아이 캐스트|테니스|동물|주로 여성 캐스트|귀여운...</td>\n",
       "      <td>연애와 우정, 마음의 상냥함을 그리는 귀여운 드리밍 스토리(恋や友情、心のやさしさを描...</td>\n",
       "      <td>6</td>\n",
       "      <td>뮤(토요사키 아이세)|페코(쿠보 유리카)|히나타 유메(무라카미 나츠미)|수우(칸모토...</td>\n",
       "      <td>사쿠라이 히로아키</td>\n",
       "      <td>J.C. 스태프, A.C.G.T., TV 도쿄, ADK 이모션즈, 산리오</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>제목: 꿈속의 뮤 | 제작연도: 2020 | 방영분기: 2분기 | 장르: 모험|코미...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>일하는 세포!!</td>\n",
       "      <td>はたらく細胞!!</td>\n",
       "      <td>Hataraku Saibou!!</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>1분기</td>\n",
       "      <td>액션|코미디|SF</td>\n",
       "      <td>교육|앙상블 캐스트|의학|일|여성 주인공|소년 만화|남성 주인공|에피소딕|고어|인간...</td>\n",
       "      <td>이것은 당신의 이야기이자, 당신 몸속의 이야기.사람의 세포 수는 약 37조개.세포들...</td>\n",
       "      <td>6</td>\n",
       "      <td>U-1146 핫케큐우(마에노 토모아키)|사이보우 이판(코바야시 유스케)|AE3803...</td>\n",
       "      <td>오구라 히로후미</td>\n",
       "      <td>데이비드 프로덕션, 매직 캡슐, 애니플렉스, 코단샤, 애니플렉스 미국</td>\n",
       "      <td>시미즈 아카네</td>\n",
       "      <td>NaN</td>\n",
       "      <td>제목: 일하는 세포!! | 제작연도: 2021 | 방영분기: 1분기 | 장르: 액션...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>블라드 러브</td>\n",
       "      <td>ぶらどらぶ</td>\n",
       "      <td>Vlad Love</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>1분기</td>\n",
       "      <td>코미디|초자연</td>\n",
       "      <td>뱀파이어|때림 개그|여성 주인공|풍자|메타|괴상한 코미디|풍자|주로 여성 캐스트|학...</td>\n",
       "      <td>등록된 줄거리가 없습니다.</td>\n",
       "      <td>6</td>\n",
       "      <td>밤바 미츠구(사쿠라 아야네)|트란실바니아 블라드 마이(히다카 리나)|치마츠리 치히로...</td>\n",
       "      <td>니시무라 준지</td>\n",
       "      <td>드라이브, 프로덕션 I.G, 이치고 애니메이션, 만화 애니메이션</td>\n",
       "      <td>오시이 마모루</td>\n",
       "      <td>NaN</td>\n",
       "      <td>제목: 블라드 러브 | 제작연도: 2021 | 방영분기: 1분기 | 장르: 코미디|...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "```info()```는 데이터 요약 정보\n",
    "```head(3)```는 위에서 3개만 보여줘서 빠르게 내용을 확인할 수 있다"
   ],
   "id": "ec9e9c4d09e409a8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 종합 특징 텍스트 생성 함수를 만들자!",
   "id": "42bcefe90731735"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T05:09:26.789401Z",
     "start_time": "2025-09-08T05:09:26.781197Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_comprehensive_features(anime_data):\n",
    "    comprehensive_texts = []\n",
    "\n",
    "    for _, row in anime_data.iterrows():\n",
    "        features = []\n",
    "\n",
    "        title = \"\"\n",
    "        if pd.notna(row.get('title_korean')) and row['title_korean'].strip():\n",
    "            title = row['title_korean']\n",
    "        elif pd.notna(row.get('title_japanese')) and row['title_japanese'].strip():\n",
    "            title = row['title_japanese']\n",
    "        elif pd.notna(row.get('title_english')) and row['title_english'].strip():\n",
    "            title = row['title_english']\n",
    "        if title:\n",
    "            features.append(f\"제목: {title}\")\n",
    "\n",
    "        if pd.notna(row.get('year')):\n",
    "            features.append(f\"제작연도: {int(row['year'])}\")\n",
    "        if pd.notna(row.get('quarter')) and row['quarter'].strip():\n",
    "            features.append(f\"방영분기: {row['quarter']}\")\n",
    "\n",
    "        if pd.notna(row.get('genres')) and row['genres'].strip():\n",
    "            features.append(f\"장르: {row['genres']}\")\n",
    "        if pd.notna(row.get('tags')) and row['tags'].strip():\n",
    "            features.append(f\"태그: {row['tags']}\")\n",
    "\n",
    "        if pd.notna(row.get('synopsis')) and row['synopsis'].strip():\n",
    "            synopsis = row['synopsis'][:300]\n",
    "            features.append(f\"줄거리: {synopsis}\")\n",
    "\n",
    "        if pd.notna(row.get('main_characters')) and row['main_characters'].strip():\n",
    "            features.append(f\"주요캐릭터: {row['main_characters']}\")\n",
    "        if pd.notna(row.get('director')) and row['director'].strip():\n",
    "            features.append(f\"감독: {row['director']}\")\n",
    "        if pd.notna(row.get('studio')) and row['studio'].strip():\n",
    "            features.append(f\"제작사: {row['studio']}\")\n",
    "        if pd.notna(row.get('original_work')) and row['original_work'].strip():\n",
    "            features.append(f\"원작: {row['original_work']}\")\n",
    "\n",
    "        if pd.notna(row.get('num_characters')):\n",
    "            features.append(f\"캐릭터수: {int(row['num_characters'])}\")\n",
    "\n",
    "        comprehensive_text = \" | \".join(features)\n",
    "        comprehensive_texts.append(comprehensive_text)\n",
    "\n",
    "    return comprehensive_texts"
   ],
   "id": "e5be8dc11be9e9ea",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T05:09:39.557152Z",
     "start_time": "2025-09-08T05:09:39.300180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 함수 실행하여 'comprehensive_features' 컬럼 생성\n",
    "anime_data['comprehensive_features'] = create_comprehensive_features(anime_data)\n",
    "\n",
    "print(\"종합 특징 텍스트 생성 완료!\")"
   ],
   "id": "57e18edbaaed8500",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "종합 특징 텍스트 생성 완료!\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T05:09:48.253625Z",
     "start_time": "2025-09-08T05:09:48.248889Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3개 샘플 확인해보기\n",
    "for i in range(3):\n",
    "    print(f\"\\n[{i+1}] ID: {anime_data.iloc[i]['id']}\")\n",
    "    print(f\"제목: {anime_data.iloc[i]['title_korean']}\")\n",
    "    print(f\"종합 특징: {anime_data.iloc[i]['comprehensive_features'][:200]}...\")\n"
   ],
   "id": "fa43b8264ea0e541",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1] ID: 110\n",
      "제목: 꿈속의 뮤\n",
      "종합 특징: 제목: 꿈속의 뮤 | 제작연도: 2020 | 방영분기: 2분기 | 장르: 모험|코미디|판타지|마법 소녀 | 태그: 여성 주인공|어린이|에피소딕|주로 아이 캐스트|테니스|동물|주로 여성 캐스트|귀여운 소녀들의 귀여운 일상|앙상블 캐스트|변신|학교|학교 클럽|외계인 | 줄거리: 연애와 우정, 마음의 상냥함을 그리는 귀여운 드리밍 스토리(恋や友情、心のやさしさを描...\n",
      "\n",
      "[2] ID: 102\n",
      "제목: 일하는 세포!!\n",
      "종합 특징: 제목: 일하는 세포!! | 제작연도: 2021 | 방영분기: 1분기 | 장르: 액션|코미디|SF | 태그: 교육|앙상블 캐스트|의학|일|여성 주인공|소년 만화|남성 주인공|에피소딕|고어|인간화|때림 개그|주로 어른 캐스트|악마|CGI | 줄거리: 이것은 당신의 이야기이자, 당신 몸속의 이야기.사람의 세포 수는 약 37조개.세포들은 몸의 세계 중심에서, 오늘...\n",
      "\n",
      "[3] ID: 103\n",
      "제목: 블라드 러브\n",
      "종합 특징: 제목: 블라드 러브 | 제작연도: 2021 | 방영분기: 1분기 | 장르: 코미디|초자연 | 태그: 뱀파이어|때림 개그|여성 주인공|풍자|메타|괴상한 코미디|풍자|주로 여성 캐스트|학교 클럽|마이 톰보이|연기|학교|교육|도시|LGBTQ+ 주제|도시 판타지|코스프레|대학|용|비디오 게임 | 줄거리: 등록된 줄거리가 없습니다. | 주요캐릭터: 밤바 미츠구(사쿠...\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T05:10:20.966089Z",
     "start_time": "2025-09-08T05:10:20.880062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 결과를 새 CSV 파일로 저장\n",
    "output_path = \"anime_data_with_features.csv\"\n",
    "anime_data.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"저장 완료! 👉 {output_path}\")\n"
   ],
   "id": "785e8f1b3870ee5d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장 완료! 👉 anime_data_with_features.csv\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T05:11:28.727443Z",
     "start_time": "2025-09-08T05:11:28.713760Z"
    }
   },
   "cell_type": "code",
   "source": "anime_data[anime_data['studio'] == 'MAPPA'] #→ MAPPA 제작사만 추출해보자.",
   "id": "4e5434cfde8120c6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        id                 title_korean                title_japanese  \\\n",
       "596    729           터무니없는 스킬로 이세계 방랑 밥               とんでもスキルで異世界放浪メシ   \n",
       "2221  2361  [극장판] - GARO -DIVINE FLAME-        牙狼〈GARO〉-DIVINE FLAME-   \n",
       "3288  3407                  가로 -배니싱 라인-      牙狼＜GARO＞-VANISHING LINE-   \n",
       "4085  6563     극장판 이나즈마 일레븐 새로운 영웅들의 서장          イナズマイレブン 新たなる英雄たちの序章   \n",
       "4331  6825     극장판 총집편 주술회전 회옥·옥절: 주주산보  劇場版総集編 呪術廻戦 懐玉・玉折 劇場版じゅじゅさんぽ   \n",
       "4398  6872         터무니없는 스킬로 이세계 방랑 밥 2              とんでもスキルで異世界放浪メシ2   \n",
       "4403  6875                     란마1/2 2기             らんま1/2 (2024) 第2期   \n",
       "\n",
       "                                         title_english    year quarter  \\\n",
       "596               Tondemo Skill de Isekai Hourou Meshi  2023.0     1분기   \n",
       "2221                                GARO: Divine Flame  2016.0     2분기   \n",
       "3288                             GARO -VANISHING LINE-  2017.0     4분기   \n",
       "4085    Inazuma Eleven: Aratanaru Eiyuutachi no Joshou  2024.0     4분기   \n",
       "4331  Jujutsu Kaisen: Kaigyoku・Gyokusetsu - Juju Sanpo  2025.0     2분기   \n",
       "4398            Tondemo Skill de Isekai Hourou Meshi 2  2025.0     4분기   \n",
       "4403                       Ranma 1/2 (2024) 2nd Season  2025.0     4분기   \n",
       "\n",
       "          genres                                               tags  \\\n",
       "596   모험|코미디|판타지   음식|이세계|찾은 가족|동물|이야시케이|남성 주인공|신들|여행|일|경제|마법|용|고블린   \n",
       "2221  액션|판타지|초자연                             변신|토쿠사츠|악마|마법|바디 호러|검술   \n",
       "3288     액션|미스터리  악마|도시 판타지|총|변신|소프트웨어 개발|토쿠사츠|가상 세계|남성 주인공|사막|갈...   \n",
       "4085      액션|스포츠                                              축구|학교   \n",
       "4331         코미디                                                NaN   \n",
       "4398  모험|코미디|판타지  이세계|음식|이야시케이|남성 주인공|일|동물|경제|신들|여행|마법|용|엘프|쿠데레|...   \n",
       "4403  액션|코미디|로맨스  변신|성별 변환|무술|정략 결혼|이성애|사랑의 삼각형|츤데레|여성 하렘|남성 하렘|...   \n",
       "\n",
       "                                               synopsis  num_characters  \\\n",
       "596   어느 날 갑자기 이세계로 소환된 평범한 샐러리맨 무코다.이세계의 주민이 된 그의 고...               6   \n",
       "2221                                     등록된 줄거리가 없습니다.               6   \n",
       "3288                                     등록된 줄거리가 없습니다.               6   \n",
       "4085                                     등록된 줄거리가 없습니다.               3   \n",
       "4331                                     등록된 줄거리가 없습니다.               4   \n",
       "4398                                     등록된 줄거리가 없습니다.               6   \n",
       "4403                                     등록된 줄거리가 없습니다.               6   \n",
       "\n",
       "                                        main_characters  director studio  \\\n",
       "596   무코다 츠요시(우치다 유마)|수이(키노 히나)|펠(히노 사토시)|닌리르(우치다 마오...   마츠다 키요시  MAPPA   \n",
       "2221  루이스 레온(나미카와 다이스케)|루이스 헤르만(호리우치 켄오)|구즈만 에마(박로미)...  하야시 유이치로  MAPPA   \n",
       "3288  소드(세키 토모카즈)|헨느스 소피(쿠기미야 리에)|루크(시마자키 노부나가)|지나(코...       박성후  MAPPA   \n",
       "4085  사사나미 운메이(쇼무라 마사루)|엔도우 하루(Moe Konoma)|사쿠라자키 죠지(...   시타다 슈헤이  MAPPA   \n",
       "4331            고죠 사토루()|게토우 스구루()|이에이리 쇼코()|후시구로 토우지()       NaN  MAPPA   \n",
       "4398  무코다 츠요시(우치다 유마)|펠(히노 사토시)|수이(키노 히나)|도라짱(무라세 아유...   마츠다 키요시  MAPPA   \n",
       "4403  텐도 아카네(히데카 노리코)|히비키 료우가(야마데라 코이치)|Ukyo Kuonji(...   우다 코노스케  MAPPA   \n",
       "\n",
       "     original_work  error                             comprehensive_features  \n",
       "596            NaN    NaN  제목: 터무니없는 스킬로 이세계 방랑 밥 | 제작연도: 2023 | 방영분기: 1분...  \n",
       "2221      아메미야 케이타    NaN  제목: [극장판] - GARO -DIVINE FLAME- | 제작연도: 2016 |...  \n",
       "3288           NaN    NaN  제목: 가로 -배니싱 라인- | 제작연도: 2017 | 방영분기: 4분기 | 장르:...  \n",
       "4085           NaN    NaN  제목: 극장판 이나즈마 일레븐 새로운 영웅들의 서장 | 제작연도: 2024 | 방영...  \n",
       "4331        아케미 게게    NaN  제목: 극장판 총집편 주술회전 회옥·옥절: 주주산보 | 제작연도: 2025 | 방영...  \n",
       "4398           NaN    NaN  제목: 터무니없는 스킬로 이세계 방랑 밥 2 | 제작연도: 2025 | 방영분기: ...  \n",
       "4403      타카하시 루미코    NaN  제목: 란마1/2 2기 | 제작연도: 2025 | 방영분기: 4분기 | 장르: 액션...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title_korean</th>\n",
       "      <th>title_japanese</th>\n",
       "      <th>title_english</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>genres</th>\n",
       "      <th>tags</th>\n",
       "      <th>synopsis</th>\n",
       "      <th>num_characters</th>\n",
       "      <th>main_characters</th>\n",
       "      <th>director</th>\n",
       "      <th>studio</th>\n",
       "      <th>original_work</th>\n",
       "      <th>error</th>\n",
       "      <th>comprehensive_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>729</td>\n",
       "      <td>터무니없는 스킬로 이세계 방랑 밥</td>\n",
       "      <td>とんでもスキルで異世界放浪メシ</td>\n",
       "      <td>Tondemo Skill de Isekai Hourou Meshi</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>1분기</td>\n",
       "      <td>모험|코미디|판타지</td>\n",
       "      <td>음식|이세계|찾은 가족|동물|이야시케이|남성 주인공|신들|여행|일|경제|마법|용|고블린</td>\n",
       "      <td>어느 날 갑자기 이세계로 소환된 평범한 샐러리맨 무코다.이세계의 주민이 된 그의 고...</td>\n",
       "      <td>6</td>\n",
       "      <td>무코다 츠요시(우치다 유마)|수이(키노 히나)|펠(히노 사토시)|닌리르(우치다 마오...</td>\n",
       "      <td>마츠다 키요시</td>\n",
       "      <td>MAPPA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>제목: 터무니없는 스킬로 이세계 방랑 밥 | 제작연도: 2023 | 방영분기: 1분...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>2361</td>\n",
       "      <td>[극장판] - GARO -DIVINE FLAME-</td>\n",
       "      <td>牙狼〈GARO〉-DIVINE FLAME-</td>\n",
       "      <td>GARO: Divine Flame</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>2분기</td>\n",
       "      <td>액션|판타지|초자연</td>\n",
       "      <td>변신|토쿠사츠|악마|마법|바디 호러|검술</td>\n",
       "      <td>등록된 줄거리가 없습니다.</td>\n",
       "      <td>6</td>\n",
       "      <td>루이스 레온(나미카와 다이스케)|루이스 헤르만(호리우치 켄오)|구즈만 에마(박로미)...</td>\n",
       "      <td>하야시 유이치로</td>\n",
       "      <td>MAPPA</td>\n",
       "      <td>아메미야 케이타</td>\n",
       "      <td>NaN</td>\n",
       "      <td>제목: [극장판] - GARO -DIVINE FLAME- | 제작연도: 2016 |...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3288</th>\n",
       "      <td>3407</td>\n",
       "      <td>가로 -배니싱 라인-</td>\n",
       "      <td>牙狼＜GARO＞-VANISHING LINE-</td>\n",
       "      <td>GARO -VANISHING LINE-</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>4분기</td>\n",
       "      <td>액션|미스터리</td>\n",
       "      <td>악마|도시 판타지|총|변신|소프트웨어 개발|토쿠사츠|가상 세계|남성 주인공|사막|갈...</td>\n",
       "      <td>등록된 줄거리가 없습니다.</td>\n",
       "      <td>6</td>\n",
       "      <td>소드(세키 토모카즈)|헨느스 소피(쿠기미야 리에)|루크(시마자키 노부나가)|지나(코...</td>\n",
       "      <td>박성후</td>\n",
       "      <td>MAPPA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>제목: 가로 -배니싱 라인- | 제작연도: 2017 | 방영분기: 4분기 | 장르:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4085</th>\n",
       "      <td>6563</td>\n",
       "      <td>극장판 이나즈마 일레븐 새로운 영웅들의 서장</td>\n",
       "      <td>イナズマイレブン 新たなる英雄たちの序章</td>\n",
       "      <td>Inazuma Eleven: Aratanaru Eiyuutachi no Joshou</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>4분기</td>\n",
       "      <td>액션|스포츠</td>\n",
       "      <td>축구|학교</td>\n",
       "      <td>등록된 줄거리가 없습니다.</td>\n",
       "      <td>3</td>\n",
       "      <td>사사나미 운메이(쇼무라 마사루)|엔도우 하루(Moe Konoma)|사쿠라자키 죠지(...</td>\n",
       "      <td>시타다 슈헤이</td>\n",
       "      <td>MAPPA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>제목: 극장판 이나즈마 일레븐 새로운 영웅들의 서장 | 제작연도: 2024 | 방영...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4331</th>\n",
       "      <td>6825</td>\n",
       "      <td>극장판 총집편 주술회전 회옥·옥절: 주주산보</td>\n",
       "      <td>劇場版総集編 呪術廻戦 懐玉・玉折 劇場版じゅじゅさんぽ</td>\n",
       "      <td>Jujutsu Kaisen: Kaigyoku・Gyokusetsu - Juju Sanpo</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>2분기</td>\n",
       "      <td>코미디</td>\n",
       "      <td>NaN</td>\n",
       "      <td>등록된 줄거리가 없습니다.</td>\n",
       "      <td>4</td>\n",
       "      <td>고죠 사토루()|게토우 스구루()|이에이리 쇼코()|후시구로 토우지()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MAPPA</td>\n",
       "      <td>아케미 게게</td>\n",
       "      <td>NaN</td>\n",
       "      <td>제목: 극장판 총집편 주술회전 회옥·옥절: 주주산보 | 제작연도: 2025 | 방영...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4398</th>\n",
       "      <td>6872</td>\n",
       "      <td>터무니없는 스킬로 이세계 방랑 밥 2</td>\n",
       "      <td>とんでもスキルで異世界放浪メシ2</td>\n",
       "      <td>Tondemo Skill de Isekai Hourou Meshi 2</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>4분기</td>\n",
       "      <td>모험|코미디|판타지</td>\n",
       "      <td>이세계|음식|이야시케이|남성 주인공|일|동물|경제|신들|여행|마법|용|엘프|쿠데레|...</td>\n",
       "      <td>등록된 줄거리가 없습니다.</td>\n",
       "      <td>6</td>\n",
       "      <td>무코다 츠요시(우치다 유마)|펠(히노 사토시)|수이(키노 히나)|도라짱(무라세 아유...</td>\n",
       "      <td>마츠다 키요시</td>\n",
       "      <td>MAPPA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>제목: 터무니없는 스킬로 이세계 방랑 밥 2 | 제작연도: 2025 | 방영분기: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4403</th>\n",
       "      <td>6875</td>\n",
       "      <td>란마1/2 2기</td>\n",
       "      <td>らんま1/2 (2024) 第2期</td>\n",
       "      <td>Ranma 1/2 (2024) 2nd Season</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>4분기</td>\n",
       "      <td>액션|코미디|로맨스</td>\n",
       "      <td>변신|성별 변환|무술|정략 결혼|이성애|사랑의 삼각형|츤데레|여성 하렘|남성 하렘|...</td>\n",
       "      <td>등록된 줄거리가 없습니다.</td>\n",
       "      <td>6</td>\n",
       "      <td>텐도 아카네(히데카 노리코)|히비키 료우가(야마데라 코이치)|Ukyo Kuonji(...</td>\n",
       "      <td>우다 코노스케</td>\n",
       "      <td>MAPPA</td>\n",
       "      <td>타카하시 루미코</td>\n",
       "      <td>NaN</td>\n",
       "      <td>제목: 란마1/2 2기 | 제작연도: 2025 | 방영분기: 4분기 | 장르: 액션...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T05:16:44.538270Z",
     "start_time": "2025-09-08T05:16:34.145701Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install datasets",
   "id": "18ed42661428cec3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Using cached datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (2.3.2)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Using cached pyarrow-21.0.0-cp313-cp313-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (2.3.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.5.0-cp313-cp313-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Using cached multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (0.33.5)\n",
      "Requirement already satisfied: packaging in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached aiohttp-3.12.15-cp313-cp313-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached frozenlist-1.7.0-cp313-cp313-win_amd64.whl.metadata (19 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading multidict-6.6.4-cp313-cp313-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached propcache-0.3.2-cp313-cp313-win_amd64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached yarl-1.20.1-cp313-cp313-win_amd64.whl.metadata (76 kB)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.14.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.7.14)\n",
      "Requirement already satisfied: colorama in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Using cached datasets-4.0.0-py3-none-any.whl (494 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Using cached multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Using cached aiohttp-3.12.15-cp313-cp313-win_amd64.whl (449 kB)\n",
      "Downloading multidict-6.6.4-cp313-cp313-win_amd64.whl (45 kB)\n",
      "Using cached yarl-1.20.1-cp313-cp313-win_amd64.whl (86 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached frozenlist-1.7.0-cp313-cp313-win_amd64.whl (43 kB)\n",
      "Using cached propcache-0.3.2-cp313-cp313-win_amd64.whl (40 kB)\n",
      "Using cached pyarrow-21.0.0-cp313-cp313-win_amd64.whl (26.1 MB)\n",
      "Using cached xxhash-3.5.0-cp313-cp313-win_amd64.whl (30 kB)\n",
      "Installing collected packages: xxhash, pyarrow, propcache, multidict, fsspec, frozenlist, dill, aiohappyeyeballs, yarl, multiprocess, aiosignal, aiohttp, datasets\n",
      "\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   --- ------------------------------------  1/13 [pyarrow]\n",
      "   ------ ---------------------------------  2/13 [propcache]\n",
      "  Attempting uninstall: fsspec\n",
      "   ------ ---------------------------------  2/13 [propcache]\n",
      "    Found existing installation: fsspec 2025.7.0\n",
      "   ------ ---------------------------------  2/13 [propcache]\n",
      "    Uninstalling fsspec-2025.7.0:\n",
      "   ------ ---------------------------------  2/13 [propcache]\n",
      "      Successfully uninstalled fsspec-2025.7.0\n",
      "   ------ ---------------------------------  2/13 [propcache]\n",
      "   ------------ ---------------------------  4/13 [fsspec]\n",
      "   ------------ ---------------------------  4/13 [fsspec]\n",
      "   ------------ ---------------------------  4/13 [fsspec]\n",
      "   ------------------ ---------------------  6/13 [dill]\n",
      "   ------------------ ---------------------  6/13 [dill]\n",
      "   ------------------------ ---------------  8/13 [yarl]\n",
      "   --------------------------- ------------  9/13 [multiprocess]\n",
      "   --------------------------- ------------  9/13 [multiprocess]\n",
      "   --------------------------------- ------ 11/13 [aiohttp]\n",
      "   --------------------------------- ------ 11/13 [aiohttp]\n",
      "   --------------------------------- ------ 11/13 [aiohttp]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ---------------------------------------- 13/13 [datasets]\n",
      "\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 datasets-4.0.0 dill-0.3.8 frozenlist-1.7.0 fsspec-2025.3.0 multidict-6.6.4 multiprocess-0.70.16 propcache-0.3.2 pyarrow-21.0.0 xxhash-3.5.0 yarl-1.20.1\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T05:17:40.504462Z",
     "start_time": "2025-09-08T05:16:48.394547Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Task 2: 모든 애니메이션 콘텐츠 임베딩\n",
    "\n",
    "class AnimeEmbeddingGenerator:\n",
    "    def __init__(self, model_name=\"kakaocorp/kanana-nano-2.1b-embedding\"):\n",
    "        \"\"\"\n",
    "        임베딩 생성기 초기화\n",
    "\n",
    "        Args:\n",
    "            model_name: 사용할 임베딩 모델명\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.tokenizer = None\n",
    "        self.model = None\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(f\"사용 디바이스: {self.device}\")\n",
    "\n",
    "    # 3. 임베딩 모델 로드\n",
    "    def load_embedding_model(self):\n",
    "        print(f\"=== 임베딩 모델 로드 중: {self.model_name} ===\")\n",
    "        try:\n",
    "            print(\"토크나이저 로드 중...\")\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "                self.model_name,\n",
    "                trust_remote_code=True   # ★ 중요\n",
    "            )\n",
    "\n",
    "            print(\"모델 로드 중...\")\n",
    "            self.model = AutoModel.from_pretrained(\n",
    "                self.model_name,\n",
    "                trust_remote_code=True,  # ★ 중요\n",
    "                torch_dtype=(torch.float16 if torch.cuda.is_available() else torch.float32)\n",
    "            )\n",
    "\n",
    "            self.model.to(self.device)\n",
    "            self.model.eval()\n",
    "            print(\"✅ 임베딩 모델 로드 완료!\")\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 모델 로드 실패: {e}\")\n",
    "            print(\"\\n대안:\")\n",
    "            print(\"1) GPU 사용 권장(2B급 모델은 CPU 매우 느림)\")\n",
    "            print(\"2) 가벼운 sentence-transformers 임베딩 모델로 폴백\")\n",
    "            return False\n",
    "\n",
    "\n",
    "    def get_text_embedding(self, text):\n",
    "        \"\"\"\n",
    "        텍스트를 임베딩 벡터로 변환\n",
    "\n",
    "        Args:\n",
    "            text: 임베딩할 텍스트\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: 임베딩 벡터\n",
    "        \"\"\"\n",
    "        if self.tokenizer is None or self.model is None:\n",
    "            raise ValueError(\"먼저 임베딩 모델을 로드해주세요!\")\n",
    "\n",
    "        # 텍스트가 비어있거나 None인 경우 처리\n",
    "        if not text or pd.isna(text):\n",
    "            text = \"정보 없음\"\n",
    "\n",
    "        # 토크나이저로 텍스트 처리\n",
    "        inputs = self.tokenizer(\n",
    "            str(text),\n",
    "            return_tensors='pt',\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=512  # 최대 길이 제한\n",
    "        )\n",
    "\n",
    "        # 입력을 디바이스로 이동\n",
    "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "\n",
    "        # 임베딩 생성 (그래디언트 계산 비활성화)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "\n",
    "            # 평균 풀링으로 문장 임베딩 생성\n",
    "            # last_hidden_state: [batch_size, seq_len, hidden_size]\n",
    "            embeddings = outputs.last_hidden_state.mean(dim=1)  # 평균 풀링\n",
    "\n",
    "        # CPU로 이동 후 numpy 배열로 변환\n",
    "        return embeddings.cpu().numpy().flatten()\n",
    "\n",
    "    def generate_all_embeddings(self, anime_data, save_path=\"anime_embeddings.npy\", force_regenerate=True):\n",
    "        \"\"\"\n",
    "        모든 애니메이션의 종합 특징 텍스트를 임베딩으로 변환\n",
    "\n",
    "        Args:\n",
    "            anime_data: 애니메이션 데이터프레임\n",
    "            save_path: 임베딩 저장 경로\n",
    "            force_regenerate: 기존 파일이 있어도 다시 생성할지 여부\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: 모든 애니메이션의 임베딩 배열\n",
    "        \"\"\"\n",
    "        # 기존 임베딩 파일이 있다면 로드\n",
    "        if os.path.exists(save_path) and not force_regenerate:\n",
    "            print(f\"=== 기존 임베딩 파일 발견: {save_path} ===\")\n",
    "            print(\"기존 파일을 로드합니다. (다시 생성하려면 force_regenerate=True로 설정)\")\n",
    "            embeddings = np.load(save_path)\n",
    "            print(f\"✅ 임베딩 로드 완료! 형태: {embeddings.shape}\")\n",
    "            return embeddings\n",
    "\n",
    "        print(f\"=== 모든 애니메이션 임베딩 생성 시작 ===\")\n",
    "        print(f\"총 {len(anime_data)}개 애니메이션 처리 예정\")\n",
    "\n",
    "        embeddings = []\n",
    "\n",
    "        # 진행률 표시를 위한 tqdm 사용\n",
    "        for i, row in tqdm(anime_data.iterrows(), total=len(anime_data), desc=\"임베딩 생성\"):\n",
    "            try:\n",
    "                # 종합 특징 텍스트 가져오기\n",
    "                comprehensive_text = row['comprehensive_features']\n",
    "\n",
    "                # 임베딩 생성\n",
    "                embedding = self.get_text_embedding(comprehensive_text)\n",
    "                embeddings.append(embedding)\n",
    "\n",
    "                # 중간 진행상황 출력 (100개마다)\n",
    "                if (i + 1) % 100 == 0:\n",
    "                    print(f\"진행률: {i+1}/{len(anime_data)} ({(i+1)/len(anime_data)*100:.1f}%)\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ ID {row.get('id', i)} 처리 중 오류: {e}\")\n",
    "                # 오류 발생시 영벡터로 대체\n",
    "                embedding_dim = len(embeddings[0]) if embeddings else 768  # 기본 차원\n",
    "                embeddings.append(np.zeros(embedding_dim))\n",
    "\n",
    "        # numpy 배열로 변환\n",
    "        embeddings_array = np.array(embeddings)\n",
    "\n",
    "        # 임베딩 저장\n",
    "        print(f\"\\n=== 임베딩 저장 중: {save_path} ===\")\n",
    "        np.save(save_path, embeddings_array)\n",
    "\n",
    "        print(f\"✅ 임베딩 생성 및 저장 완료!\")\n",
    "        print(f\"   - 저장 경로: {save_path}\")\n",
    "        print(f\"   - 임베딩 형태: {embeddings_array.shape}\")\n",
    "        print(f\"   - 파일 크기: {os.path.getsize(save_path) / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "        return embeddings_array\n",
    "\n",
    "def load_preprocessed_data(csv_path=\"anime_data_with_features.csv\"):\n",
    "    \"\"\"전처리된 데이터 로드\"\"\"\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"❌ 파일을 찾을 수 없습니다: {csv_path}\")\n",
    "        print(\"먼저 Task 1을 실행하여 전처리된 데이터를 생성해주세요.\")\n",
    "        return None\n",
    "\n",
    "    print(f\"전처리된 데이터 로드 중: {csv_path}\")\n",
    "    anime_data = pd.read_csv(csv_path)\n",
    "    print(f\"✅ {len(anime_data)}개 애니메이션 데이터 로드 완료\")\n",
    "\n",
    "    return anime_data\n",
    "\n",
    "# 실행\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== Task 2: 모든 애니메이션 콘텐츠 임베딩 ===\\n\")\n",
    "\n",
    "    # 1. 전처리된 데이터 로드\n",
    "    anime_data = load_preprocessed_data()\n",
    "    if anime_data is None:\n",
    "        exit(1)\n",
    "\n",
    "    # 2. 임베딩 생성기 초기화\n",
    "    embedding_generator = AnimeEmbeddingGenerator()\n",
    "\n",
    "    # 3. 임베딩 모델 로드\n",
    "    if not embedding_generator.load_embedding_model():\n",
    "        print(\"모델 로드에 실패했습니다. 프로그램을 종료합니다.\")\n",
    "        exit(1)\n",
    "\n",
    "    # 4. 모든 애니메이션 임베딩 생성\n",
    "    anime_embeddings = embedding_generator.generate_all_embeddings(\n",
    "        anime_data=anime_data,\n",
    "        save_path=\"anime_embeddings.npy\",\n",
    "        force_regenerate=False  # True로 설정하면 기존 파일이 있어도 다시 생성\n",
    "    )\n",
    "\n",
    "    print(f\"\\n=== Task 2 완료 ===\")\n",
    "    print(f\"✅ 총 {len(anime_embeddings)}개 애니메이션의 임베딩 생성 완료\")\n",
    "    print(f\"✅ 각 임베딩의 차원: {anime_embeddings.shape[1]}\")\n",
    "    print(\"다음 단계(Task 3)로 넘어갈 준비가 되었습니다!\")"
   ],
   "id": "6b5c4f465c2052ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Task 2: 모든 애니메이션 콘텐츠 임베딩 ===\n",
      "\n",
      "전처리된 데이터 로드 중: anime_data_with_features.csv\n",
      "✅ 4453개 애니메이션 데이터 로드 완료\n",
      "사용 디바이스: cpu\n",
      "=== 임베딩 모델 로드 중: kakaocorp/kanana-nano-2.1b-embedding ===\n",
      "토크나이저 로드 중...\n",
      "모델 로드 중...\n",
      "✅ 임베딩 모델 로드 완료!\n",
      "=== 기존 임베딩 파일 발견: anime_embeddings.npy ===\n",
      "기존 파일을 로드합니다. (다시 생성하려면 force_regenerate=True로 설정)\n",
      "✅ 임베딩 로드 완료! 형태: (4453, 768)\n",
      "\n",
      "=== Task 2 완료 ===\n",
      "✅ 총 4453개 애니메이션의 임베딩 생성 완료\n",
      "✅ 각 임베딩의 차원: 768\n",
      "다음 단계(Task 3)로 넘어갈 준비가 되었습니다!\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T05:20:12.346501Z",
     "start_time": "2025-09-08T05:20:12.028461Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Task 3: 테스트용 사용자 피드백 정의\n",
    "\n",
    "class UserFeedbackGenerator:\n",
    "    def __init__(self, seed=42):\n",
    "        \"\"\"\n",
    "        사용자 피드백 생성기 초기화\n",
    "\n",
    "        Args:\n",
    "            seed: 재현 가능한 결과를 위한 랜덤 시드\n",
    "        \"\"\"\n",
    "        self.seed = seed\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "\n",
    "    def generate_random_feedback(self, anime_data, liked_count_range=(5, 10), disliked_count_range=(3, 5)):\n",
    "        \"\"\"\n",
    "        완전히 랜덤한 사용자 피드백 생성\n",
    "\n",
    "        Args:\n",
    "            anime_data: 애니메이션 데이터프레임\n",
    "            liked_count_range: 좋아요 개수 범위 (min, max)\n",
    "            disliked_count_range: 싫어요 개수 범위 (min, max)\n",
    "\n",
    "        Returns:\n",
    "            tuple: (liked_animes, disliked_animes)\n",
    "        \"\"\"\n",
    "        total_animes = len(anime_data)\n",
    "        anime_indices = list(range(total_animes))  # 0부터 len(anime_data)-1까지의 인덱스\n",
    "\n",
    "        # 랜덤하게 좋아요/싫어요 개수 결정\n",
    "        liked_count = np.random.randint(liked_count_range[0], liked_count_range[1] + 1)\n",
    "        disliked_count = np.random.randint(disliked_count_range[0], disliked_count_range[1] + 1)\n",
    "\n",
    "        # 중복 없이 랜덤 선택\n",
    "        selected_indices = np.random.choice(anime_indices, size=liked_count + disliked_count, replace=False)\n",
    "\n",
    "        liked_animes = selected_indices[:liked_count].tolist()\n",
    "        disliked_animes = selected_indices[liked_count:].tolist()\n",
    "\n",
    "        return liked_animes, disliked_animes\n",
    "\n",
    "    def generate_genre_based_feedback(self, anime_data, preferred_genres, disliked_genres,\n",
    "                                    liked_count_range=(5, 10), disliked_count_range=(3, 5)):\n",
    "        \"\"\"\n",
    "        특정 장르 선호도를 기반으로 한 사용자 피드백 생성\n",
    "\n",
    "        Args:\n",
    "            anime_data: 애니메이션 데이터프레임\n",
    "            preferred_genres: 선호하는 장르 리스트\n",
    "            disliked_genres: 싫어하는 장르 리스트\n",
    "            liked_count_range: 좋아요 개수 범위\n",
    "            disliked_count_range: 싫어요 개수 범위\n",
    "\n",
    "        Returns:\n",
    "            tuple: (liked_animes, disliked_animes)\n",
    "        \"\"\"\n",
    "        # 선호 장르 포함 애니메이션 찾기\n",
    "        preferred_indices = []\n",
    "        disliked_indices = []\n",
    "\n",
    "        for idx, row in anime_data.iterrows():\n",
    "            genres = str(row.get('genres', '')).lower()\n",
    "\n",
    "            # 선호 장르 체크\n",
    "            for genre in preferred_genres:\n",
    "                if genre.lower() in genres:\n",
    "                    preferred_indices.append(idx)\n",
    "                    break\n",
    "\n",
    "            # 싫어하는 장르 체크\n",
    "            for genre in disliked_genres:\n",
    "                if genre.lower() in genres:\n",
    "                    disliked_indices.append(idx)\n",
    "                    break\n",
    "\n",
    "        # 좋아요 선택 (선호 장르에서)\n",
    "        liked_count = min(np.random.randint(liked_count_range[0], liked_count_range[1] + 1), len(preferred_indices))\n",
    "        if liked_count > 0 and preferred_indices:\n",
    "            liked_animes = np.random.choice(preferred_indices, size=liked_count, replace=False).tolist()\n",
    "        else:\n",
    "            # 선호 장르가 없으면 랜덤 선택\n",
    "            liked_animes = np.random.choice(range(len(anime_data)), size=liked_count_range[0], replace=False).tolist()\n",
    "\n",
    "        # 싫어요 선택 (싫어하는 장르에서, 좋아요와 겹치지 않게)\n",
    "        available_disliked = [idx for idx in disliked_indices if idx not in liked_animes]\n",
    "        disliked_count = min(np.random.randint(disliked_count_range[0], disliked_count_range[1] + 1), len(available_disliked))\n",
    "\n",
    "        if disliked_count > 0 and available_disliked:\n",
    "            disliked_animes = np.random.choice(available_disliked, size=disliked_count, replace=False).tolist()\n",
    "        else:\n",
    "            # 싫어하는 장르가 없으면 랜덤 선택 (좋아요와 겹치지 않게)\n",
    "            remaining_indices = [idx for idx in range(len(anime_data)) if idx not in liked_animes]\n",
    "            disliked_count = min(disliked_count_range[0], len(remaining_indices))\n",
    "            disliked_animes = np.random.choice(remaining_indices, size=disliked_count, replace=False).tolist()\n",
    "\n",
    "        return liked_animes, disliked_animes\n",
    "\n",
    "    def display_feedback_summary(self, anime_data, liked_animes, disliked_animes, user_name=\"사용자 A\"):\n",
    "        \"\"\"\n",
    "        생성된 피드백 정보를 보기 좋게 출력\n",
    "\n",
    "        Args:\n",
    "            anime_data: 애니메이션 데이터프레임\n",
    "            liked_animes: 좋아요 애니메이션 인덱스 리스트\n",
    "            disliked_animes: 싫어요 애니메이션 인덱스 리스트\n",
    "            user_name: 사용자 이름\n",
    "        \"\"\"\n",
    "        print(f\"=== {user_name}의 피드백 정보 ===\")\n",
    "        print(f\"좋아요: {len(liked_animes)}개, 싫어요: {len(disliked_animes)}개\")\n",
    "\n",
    "        print(f\"\\n📍 좋아요 애니메이션 ({len(liked_animes)}개):\")\n",
    "        for i, idx in enumerate(liked_animes):\n",
    "            anime = anime_data.iloc[idx]\n",
    "            title = anime.get('title_korean', '제목 없음')\n",
    "            genres = anime.get('genres', '장르 정보 없음')\n",
    "            year = anime.get('year', '연도 정보 없음')\n",
    "            print(f\"  {i+1:2d}. [인덱스:{idx:4d}] {title} ({year}) - {genres}\")\n",
    "\n",
    "        print(f\"\\n👎 싫어요 애니메이션 ({len(disliked_animes)}개):\")\n",
    "        for i, idx in enumerate(disliked_animes):\n",
    "            anime = anime_data.iloc[idx]\n",
    "            title = anime.get('title_korean', '제목 없음')\n",
    "            genres = anime.get('genres', '장르 정보 없음')\n",
    "            year = anime.get('year', '연도 정보 없음')\n",
    "            print(f\"  {i+1:2d}. [인덱스:{idx:4d}] {title} ({year}) - {genres}\")\n",
    "\n",
    "    def analyze_feedback_genres(self, anime_data, liked_animes, disliked_animes):\n",
    "        \"\"\"\n",
    "        피드백에서 선호/비선호 장르 패턴 분석\n",
    "\n",
    "        Args:\n",
    "            anime_data: 애니메이션 데이터프레임\n",
    "            liked_animes: 좋아요 애니메이션 인덱스 리스트\n",
    "            disliked_animes: 싫어요 애니메이션 인덱스 리스트\n",
    "        \"\"\"\n",
    "        print(\"\\n=== 장르 선호도 분석 ===\")\n",
    "\n",
    "        # 좋아요 장르 수집\n",
    "        liked_genres = []\n",
    "        for idx in liked_animes:\n",
    "            genres = str(anime_data.iloc[idx].get('genres', ''))\n",
    "            if genres and genres != 'nan':\n",
    "                # 쉼표나 슬래시로 구분된 장르들 분리\n",
    "                genre_list = [g.strip() for g in genres.replace('/', ',').split(',')]\n",
    "                liked_genres.extend(genre_list)\n",
    "\n",
    "        # 싫어요 장르 수집\n",
    "        disliked_genres = []\n",
    "        for idx in disliked_animes:\n",
    "            genres = str(anime_data.iloc[idx].get('genres', ''))\n",
    "            if genres and genres != 'nan':\n",
    "                genre_list = [g.strip() for g in genres.replace('/', ',').split(',')]\n",
    "                disliked_genres.extend(genre_list)\n",
    "\n",
    "        # 장르별 빈도 계산\n",
    "        from collections import Counter\n",
    "        liked_genre_count = Counter(liked_genres)\n",
    "        disliked_genre_count = Counter(disliked_genres)\n",
    "\n",
    "        print(\"선호 장르 TOP 5:\")\n",
    "        for genre, count in liked_genre_count.most_common(5):\n",
    "            if genre and genre.strip():\n",
    "                print(f\"  - {genre}: {count}회\")\n",
    "\n",
    "        print(\"\\n비선호 장르 TOP 5:\")\n",
    "        for genre, count in disliked_genre_count.most_common(5):\n",
    "            if genre and genre.strip():\n",
    "                print(f\"  - {genre}: {count}회\")\n",
    "\n",
    "def load_anime_data():\n",
    "    \"\"\"애니메이션 데이터 로드\"\"\"\n",
    "    csv_path = \"anime_data_with_features.csv\"\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"❌ 파일을 찾을 수 없습니다: {csv_path}\")\n",
    "        print(\"먼저 Task 1을 실행하여 전처리된 데이터를 생성해주세요.\")\n",
    "        return None\n",
    "\n",
    "    anime_data = pd.read_csv(csv_path)\n",
    "    print(f\"✅ {len(anime_data)}개 애니메이션 데이터 로드 완료\")\n",
    "    return anime_data\n",
    "\n",
    "# 실행\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== Task 3: 테스트용 사용자 피드백 정의 ===\\n\")\n",
    "\n",
    "    # 1. 애니메이션 데이터 로드\n",
    "    anime_data = load_anime_data()\n",
    "    if anime_data is None:\n",
    "        exit(1)\n",
    "\n",
    "    # 2. 피드백 생성기 초기화\n",
    "    feedback_generator = UserFeedbackGenerator(seed=42)\n",
    "\n",
    "    # 3. 여러 종류의 가상 사용자 생성\n",
    "    print(\"=== 가상 사용자 생성 ===\\n\")\n",
    "\n",
    "    # 사용자 A: 완전 랜덤\n",
    "    print(\"🎲 사용자 A (완전 랜덤 선호도):\")\n",
    "    liked_animes_A, disliked_animes_A = feedback_generator.generate_random_feedback(anime_data)\n",
    "    feedback_generator.display_feedback_summary(anime_data, liked_animes_A, disliked_animes_A, \"사용자 A\")\n",
    "    feedback_generator.analyze_feedback_genres(anime_data, liked_animes_A, disliked_animes_A)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "    # 사용자 B: 액션/모험 선호, 로맨스/일상 비선호\n",
    "    print(\"⚔️ 사용자 B (액션/모험 선호, 로맨스/일상 비선호):\")\n",
    "    liked_animes_B, disliked_animes_B = feedback_generator.generate_genre_based_feedback(\n",
    "        anime_data,\n",
    "        preferred_genres=['액션', '모험', '판타지', '배틀'],\n",
    "        disliked_genres=['로맨스', '일상', '연애', '힐링']\n",
    "    )\n",
    "    feedback_generator.display_feedback_summary(anime_data, liked_animes_B, disliked_animes_B, \"사용자 B\")\n",
    "    feedback_generator.analyze_feedback_genres(anime_data, liked_animes_B, disliked_animes_B)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "    # 사용자 C: 드라마/감동 선호, 액션/폭력 비선호\n",
    "    print(\"😢 사용자 C (드라마/감동 선호, 액션/폭력 비선호):\")\n",
    "    liked_animes_C, disliked_animes_C = feedback_generator.generate_genre_based_feedback(\n",
    "        anime_data,\n",
    "        preferred_genres=['드라마', '감동', '휴먼', '일상', '치유'],\n",
    "        disliked_genres=['액션', '배틀', '폭력', '잔혹']\n",
    "    )\n",
    "    feedback_generator.display_feedback_summary(anime_data, liked_animes_C, disliked_animes_C, \"사용자 C\")\n",
    "    feedback_generator.analyze_feedback_genres(anime_data, liked_animes_C, disliked_animes_C)\n",
    "\n",
    "    # 4. 기본 사용자 (사용자 A) 데이터 저장\n",
    "    print(f\"\\n=== 기본 사용자 피드백 저장 ===\")\n",
    "    feedback_data = {\n",
    "        'liked_animes': liked_animes_A,\n",
    "        'disliked_animes': disliked_animes_A\n",
    "    }\n",
    "\n",
    "    import pickle\n",
    "    with open('user_feedback.pkl', 'wb') as f:\n",
    "        pickle.dump(feedback_data, f)\n",
    "\n",
    "    print(\"✅ 사용자 A의 피드백을 'user_feedback.pkl'에 저장했습니다.\")\n",
    "    print(f\"   - 좋아요: {liked_animes_A}\")\n",
    "    print(f\"   - 싫어요: {disliked_animes_A}\")\n",
    "\n",
    "    print(f\"\\n=== Task 3 완료 ===\")\n",
    "    print(\"다음 단계(Task 4)로 넘어갈 준비가 되었습니다!\")"
   ],
   "id": "ee303ded31b3ae97",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Task 3: 테스트용 사용자 피드백 정의 ===\n",
      "\n",
      "✅ 4453개 애니메이션 데이터 로드 완료\n",
      "=== 가상 사용자 생성 ===\n",
      "\n",
      "🎲 사용자 A (완전 랜덤 선호도):\n",
      "=== 사용자 A의 피드백 정보 ===\n",
      "좋아요: 8개, 싫어요: 3개\n",
      "\n",
      "📍 좋아요 애니메이션 (8개):\n",
      "   1. [인덱스:2855] 혈액형군 (2013.0) - nan\n",
      "   2. [인덱스: 693] Re: 제로부터 시작하는 이세계 생활: 빙결의 인연 (2018.0) - 코미디|드라마|판타지|심리\n",
      "   3. [인덱스:1429] 리틀 버스터즈! -리프레인- (2013.0) - 드라마|미스터리|초자연\n",
      "   4. [인덱스:1200] 오와리모노가타리 (2015.0) - 드라마|미스터리|심리|초자연\n",
      "   5. [인덱스:3948] 데드데드 데몬즈 디디디디 디스트럭션 전장 편 (2024.0) - 코미디|드라마|SF|일상\n",
      "   6. [인덱스:3299] 러브 쌀: WE LOVE RICE 2기 (2017.0) - 코미디\n",
      "   7. [인덱스: 134] 썸머 고스트 (2021.0) - 드라마|초자연\n",
      "   8. [인덱스:1084] 케이온! 스페셜 (2009.0) - 코미디\n",
      "\n",
      "👎 싫어요 애니메이션 (3개):\n",
      "   1. [인덱스:2994] TIGER & BUNNY (2011.0) - nan\n",
      "   2. [인덱스: 151] 월요일의 타와와 2기 (2021.0) - 에치|일상\n",
      "   3. [인덱스:4411] 카쿠리요의 여관밥 2기 (2025.0) - 드라마|로맨스|일상|초자연\n",
      "\n",
      "=== 장르 선호도 분석 ===\n",
      "선호 장르 TOP 5:\n",
      "  - 코미디: 2회\n",
      "  - 코미디|드라마|판타지|심리: 1회\n",
      "  - 드라마|미스터리|초자연: 1회\n",
      "  - 드라마|미스터리|심리|초자연: 1회\n",
      "  - 코미디|드라마|SF|일상: 1회\n",
      "\n",
      "비선호 장르 TOP 5:\n",
      "  - 에치|일상: 1회\n",
      "  - 드라마|로맨스|일상|초자연: 1회\n",
      "\n",
      "================================================================================\n",
      "\n",
      "⚔️ 사용자 B (액션/모험 선호, 로맨스/일상 비선호):\n",
      "=== 사용자 B의 피드백 정보 ===\n",
      "좋아요: 7개, 싫어요: 5개\n",
      "\n",
      "📍 좋아요 애니메이션 (7개):\n",
      "   1. [인덱스:2209] 기갑게 가리안 (1984.0) - 판타지|메카|SF\n",
      "   2. [인덱스:4042] 초 보통현 치바전설 (2024.0) - 코미디|판타지\n",
      "   3. [인덱스: 379] 웃는 아르스노토리아 킁! (2022.0) - 판타지|일상\n",
      "   4. [인덱스:3414] 극장판 원피스 10기: 원피스 필름 스트롱 월드 (2009.0) - 액션|모험|코미디|드라마|판타지\n",
      "   5. [인덱스:3122] 이니셜D Fifth Stage (2012.0) - 액션|드라마|스포츠\n",
      "   6. [인덱스:2368] Caligula -칼리굴라- (2018.0) - 액션|미스터리|SF\n",
      "   7. [인덱스: 822] 이종족 리뷰어즈 (2020.0) - 코미디|에치|판타지\n",
      "\n",
      "👎 싫어요 애니메이션 (5개):\n",
      "   1. [인덱스:4301] 둘이서 솔로 캠프 (2025.0) - 일상\n",
      "   2. [인덱스:3306] 젊은 여관 주인은 초등학생! (2018.0) - 일상|초자연\n",
      "   3. [인덱스:4279] 향기로운 꽃은 늠름하게 핀다 (2025.0) - 코미디|드라마|로맨스\n",
      "   4. [인덱스: 984] 투 러브 루 다크니스(3기) (2012.0) - 코미디|에치|로맨스|SF\n",
      "   5. [인덱스:1366] 포토카노 (2013.0) - 에치|로맨스\n",
      "\n",
      "=== 장르 선호도 분석 ===\n",
      "선호 장르 TOP 5:\n",
      "  - 판타지|메카|SF: 1회\n",
      "  - 코미디|판타지: 1회\n",
      "  - 판타지|일상: 1회\n",
      "  - 액션|모험|코미디|드라마|판타지: 1회\n",
      "  - 액션|드라마|스포츠: 1회\n",
      "\n",
      "비선호 장르 TOP 5:\n",
      "  - 일상: 1회\n",
      "  - 일상|초자연: 1회\n",
      "  - 코미디|드라마|로맨스: 1회\n",
      "  - 코미디|에치|로맨스|SF: 1회\n",
      "  - 에치|로맨스: 1회\n",
      "\n",
      "================================================================================\n",
      "\n",
      "😢 사용자 C (드라마/감동 선호, 액션/폭력 비선호):\n",
      "=== 사용자 C의 피드백 정보 ===\n",
      "좋아요: 6개, 싫어요: 5개\n",
      "\n",
      "📍 좋아요 애니메이션 (6개):\n",
      "   1. [인덱스: 361] 코타로는 1인 가구 (2022.0) - 코미디|드라마|일상\n",
      "   2. [인덱스:3959] 아기 고양이 치이 폼폼라 여름방학 (2024.0) - 코미디|일상\n",
      "   3. [인덱스: 249] 너와 파도를 탈 수 있다면 (2019.0) - 드라마|판타지|로맨스\n",
      "   4. [인덱스:3451] 퍼펙트 블루 (1998.0) - 드라마|공포|심리|스릴러\n",
      "   5. [인덱스:2900] 화이트 앨범 2 (2013.0) - 드라마|음악|로맨스|일상\n",
      "   6. [인덱스:2043] 내가 인기 있어서 어쩌자는 거야 (2013.0) - 코미디|일상\n",
      "\n",
      "👎 싫어요 애니메이션 (5개):\n",
      "   1. [인덱스:3340] 바람의 검심 -메이지 검객 낭만기- 신교토편 (2011.0) - 액션|드라마\n",
      "   2. [인덱스:1886] 러브리스 (2005.0) - 액션|드라마|판타지|미스터리|로맨스\n",
      "   3. [인덱스: 192] 최유기 RELOAD -ZEROIN- (2022.0) - 액션|모험|초자연\n",
      "   4. [인덱스:2003] 일기당천(1기) (2003.0) - 액션|에치\n",
      "   5. [인덱스:3443] 극장판 베르세르크 1기: 황금 시대편 - 패왕의 알 (2012.0) - 액션|모험|판타지|초자연\n",
      "\n",
      "=== 장르 선호도 분석 ===\n",
      "선호 장르 TOP 5:\n",
      "  - 코미디|일상: 2회\n",
      "  - 코미디|드라마|일상: 1회\n",
      "  - 드라마|판타지|로맨스: 1회\n",
      "  - 드라마|공포|심리|스릴러: 1회\n",
      "  - 드라마|음악|로맨스|일상: 1회\n",
      "\n",
      "비선호 장르 TOP 5:\n",
      "  - 액션|드라마: 1회\n",
      "  - 액션|드라마|판타지|미스터리|로맨스: 1회\n",
      "  - 액션|모험|초자연: 1회\n",
      "  - 액션|에치: 1회\n",
      "  - 액션|모험|판타지|초자연: 1회\n",
      "\n",
      "=== 기본 사용자 피드백 저장 ===\n",
      "✅ 사용자 A의 피드백을 'user_feedback.pkl'에 저장했습니다.\n",
      "   - 좋아요: [2855, 693, 1429, 1200, 3948, 3299, 134, 1084]\n",
      "   - 싫어요: [2994, 151, 4411]\n",
      "\n",
      "=== Task 3 완료 ===\n",
      "다음 단계(Task 4)로 넘어갈 준비가 되었습니다!\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T05:21:37.778485Z",
     "start_time": "2025-09-08T05:21:37.581820Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Task 4: 선호/비선호 벡터 평균 계산 (V_avg)\n",
    "\n",
    "class AverageVectorCalculator:\n",
    "    def __init__(self):\n",
    "        \"\"\"평균 벡터 계산기 초기화\"\"\"\n",
    "        self.anime_embeddings = None\n",
    "        self.anime_data = None\n",
    "\n",
    "    def load_required_data(self):\n",
    "        \"\"\"필요한 데이터들 로드\"\"\"\n",
    "        print(\"=== 필요한 데이터 로드 중 ===\")\n",
    "\n",
    "        # 1. 애니메이션 임베딩 로드\n",
    "        embedding_path = \"anime_embeddings.npy\"\n",
    "        if not os.path.exists(embedding_path):\n",
    "            print(f\"❌ 임베딩 파일을 찾을 수 없습니다: {embedding_path}\")\n",
    "            print(\"먼저 Task 2를 실행하여 임베딩을 생성해주세요.\")\n",
    "            return False\n",
    "\n",
    "        self.anime_embeddings = np.load(embedding_path)\n",
    "        print(f\"✅ 애니메이션 임베딩 로드 완료: {self.anime_embeddings.shape}\")\n",
    "\n",
    "        # 2. 애니메이션 데이터 로드\n",
    "        data_path = \"anime_data_with_features.csv\"\n",
    "        if not os.path.exists(data_path):\n",
    "            print(f\"❌ 데이터 파일을 찾을 수 없습니다: {data_path}\")\n",
    "            print(\"먼저 Task 1을 실행하여 전처리된 데이터를 생성해주세요.\")\n",
    "            return False\n",
    "\n",
    "        self.anime_data = pd.read_csv(data_path)\n",
    "        print(f\"✅ 애니메이션 데이터 로드 완료: {len(self.anime_data)}개\")\n",
    "\n",
    "        return True\n",
    "\n",
    "    def load_user_feedback(self, feedback_path=\"user_feedback.pkl\"):\n",
    "        \"\"\"사용자 피드백 데이터 로드\"\"\"\n",
    "        if not os.path.exists(feedback_path):\n",
    "            print(f\"❌ 피드백 파일을 찾을 수 없습니다: {feedback_path}\")\n",
    "            print(\"먼저 Task 3을 실행하여 사용자 피드백을 생성해주세요.\")\n",
    "            return None, None\n",
    "\n",
    "        with open(feedback_path, 'rb') as f:\n",
    "            feedback_data = pickle.load(f)\n",
    "\n",
    "        liked_animes = feedback_data['liked_animes']\n",
    "        disliked_animes = feedback_data['disliked_animes']\n",
    "\n",
    "        print(f\"✅ 사용자 피드백 로드 완료:\")\n",
    "        print(f\"   - 좋아요: {len(liked_animes)}개\")\n",
    "        print(f\"   - 싫어요: {len(disliked_animes)}개\")\n",
    "\n",
    "        return liked_animes, disliked_animes\n",
    "\n",
    "    def calculate_average_vectors(self, liked_animes, disliked_animes):\n",
    "        \"\"\"\n",
    "        선호/비선호 벡터 평균 계산\n",
    "\n",
    "        Args:\n",
    "            liked_animes: 좋아요 애니메이션 인덱스 리스트\n",
    "            disliked_animes: 싫어요 애니메이션 인덱스 리스트\n",
    "\n",
    "        Returns:\n",
    "            tuple: (v_avg_liked, v_avg_disliked)\n",
    "        \"\"\"\n",
    "        print(\"\\n=== 평균 벡터 계산 중 ===\")\n",
    "\n",
    "        # 1. 좋아요 평균 벡터 계산 (V_avg_liked)\n",
    "        print(f\"좋아요 애니메이션들의 임베딩 추출 중... ({len(liked_animes)}개)\")\n",
    "        liked_embeddings = self.anime_embeddings[liked_animes]\n",
    "        print(f\"좋아요 임베딩 형태: {liked_embeddings.shape}\")\n",
    "\n",
    "        # 평균 계산\n",
    "        v_avg_liked = np.mean(liked_embeddings, axis=0)\n",
    "        print(f\"V_avg_liked 계산 완료: {v_avg_liked.shape}\")\n",
    "\n",
    "        # 2. 싫어요 평균 벡터 계산 (V_avg_disliked)\n",
    "        print(f\"\\n싫어요 애니메이션들의 임베딩 추출 중... ({len(disliked_animes)}개)\")\n",
    "        disliked_embeddings = self.anime_embeddings[disliked_animes]\n",
    "        print(f\"싫어요 임베딩 형태: {disliked_embeddings.shape}\")\n",
    "\n",
    "        # 평균 계산\n",
    "        v_avg_disliked = np.mean(disliked_embeddings, axis=0)\n",
    "        print(f\"V_avg_disliked 계산 완료: {v_avg_disliked.shape}\")\n",
    "\n",
    "        return v_avg_liked, v_avg_disliked\n",
    "\n",
    "    def analyze_vector_similarity(self, v_avg_liked, v_avg_disliked):\n",
    "        \"\"\"\n",
    "        계산된 평균 벡터들의 특성 분석\n",
    "\n",
    "        Args:\n",
    "            v_avg_liked: 좋아요 평균 벡터\n",
    "            v_avg_disliked: 싫어요 평균 벡터\n",
    "        \"\"\"\n",
    "        print(\"\\n=== 평균 벡터 분석 ===\")\n",
    "\n",
    "        # 1. 벡터 크기 (노름) 계산\n",
    "        liked_norm = np.linalg.norm(v_avg_liked)\n",
    "        disliked_norm = np.linalg.norm(v_avg_disliked)\n",
    "\n",
    "        print(f\"V_avg_liked 벡터 크기: {liked_norm:.4f}\")\n",
    "        print(f\"V_avg_disliked 벡터 크기: {disliked_norm:.4f}\")\n",
    "\n",
    "        # 2. 두 벡터 간의 코사인 유사도\n",
    "        similarity = cosine_similarity([v_avg_liked], [v_avg_disliked])[0][0]\n",
    "        print(f\"좋아요-싫어요 벡터 간 코사인 유사도: {similarity:.4f}\")\n",
    "\n",
    "        if similarity > 0.7:\n",
    "            print(\"  → 매우 유사함 (사용자의 취향이 일관되지 않을 수 있음)\")\n",
    "        elif similarity > 0.3:\n",
    "            print(\"  → 중간 정도 유사함 (일부 공통점 존재)\")\n",
    "        elif similarity > -0.3:\n",
    "            print(\"  → 낮은 유사도 (서로 다른 취향)\")\n",
    "        else:\n",
    "            print(\"  → 매우 다름 (명확히 반대되는 취향)\")\n",
    "\n",
    "    def find_most_similar_animes(self, target_vector, top_k=5, exclude_indices=None):\n",
    "        \"\"\"\n",
    "        주어진 벡터와 가장 유사한 애니메이션들 찾기\n",
    "\n",
    "        Args:\n",
    "            target_vector: 기준 벡터\n",
    "            top_k: 반환할 상위 개수\n",
    "            exclude_indices: 제외할 인덱스들\n",
    "\n",
    "        Returns:\n",
    "            list: [(인덱스, 유사도)] 리스트\n",
    "        \"\"\"\n",
    "        if exclude_indices is None:\n",
    "            exclude_indices = []\n",
    "\n",
    "        # 모든 애니메이션과의 유사도 계산\n",
    "        similarities = cosine_similarity([target_vector], self.anime_embeddings)[0]\n",
    "\n",
    "        # 인덱스와 유사도를 함께 저장\n",
    "        anime_similarities = [(i, sim) for i, sim in enumerate(similarities)]\n",
    "\n",
    "        # 제외할 인덱스들 필터링\n",
    "        anime_similarities = [(i, sim) for i, sim in anime_similarities if i not in exclude_indices]\n",
    "\n",
    "        # 유사도 기준으로 정렬\n",
    "        anime_similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        return anime_similarities[:top_k]\n",
    "\n",
    "    def display_similar_animes(self, similar_animes, title=\"유사한 애니메이션\"):\n",
    "        \"\"\"\n",
    "        유사한 애니메이션 목록 출력\n",
    "\n",
    "        Args:\n",
    "            similar_animes: [(인덱스, 유사도)] 리스트\n",
    "            title: 출력 제목\n",
    "        \"\"\"\n",
    "        print(f\"\\n=== {title} ===\")\n",
    "        for i, (idx, similarity) in enumerate(similar_animes):\n",
    "            anime = self.anime_data.iloc[idx]\n",
    "            anime_title = anime.get('title_korean', '제목 없음')\n",
    "            genres = anime.get('genres', '장르 정보 없음')\n",
    "            year = anime.get('year', '연도 정보 없음')\n",
    "\n",
    "            print(f\"{i+1}. [인덱스:{idx:4d}] {anime_title} ({year})\")\n",
    "            print(f\"   장르: {genres}\")\n",
    "            print(f\"   유사도: {similarity:.4f}\")\n",
    "            print()\n",
    "\n",
    "    def save_average_vectors(self, v_avg_liked, v_avg_disliked, save_path=\"average_vectors.npz\"):\n",
    "        \"\"\"평균 벡터들 저장\"\"\"\n",
    "        np.savez(save_path,\n",
    "                v_avg_liked=v_avg_liked,\n",
    "                v_avg_disliked=v_avg_disliked)\n",
    "        print(f\"✅ 평균 벡터들을 '{save_path}'에 저장했습니다.\")\n",
    "\n",
    "def load_saved_vectors(load_path=\"average_vectors.npz\"):\n",
    "    \"\"\"저장된 평균 벡터들 로드\"\"\"\n",
    "    if os.path.exists(load_path):\n",
    "        data = np.load(load_path)\n",
    "        return data['v_avg_liked'], data['v_avg_disliked']\n",
    "    return None, None\n",
    "\n",
    "# 실행\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== Task 4: 선호/비선호 벡터 평균 계산 (V_avg) ===\\n\")\n",
    "\n",
    "    # 1. 계산기 초기화\n",
    "    calculator = AverageVectorCalculator()\n",
    "\n",
    "    # 2. 필요한 데이터 로드\n",
    "    if not calculator.load_required_data():\n",
    "        exit(1)\n",
    "\n",
    "    # 3. 사용자 피드백 로드\n",
    "    liked_animes, disliked_animes = calculator.load_user_feedback()\n",
    "    if liked_animes is None:\n",
    "        exit(1)\n",
    "\n",
    "    # 4. 평균 벡터 계산\n",
    "    v_avg_liked, v_avg_disliked = calculator.calculate_average_vectors(liked_animes, disliked_animes)\n",
    "\n",
    "    # 5. 벡터 분석\n",
    "    calculator.analyze_vector_similarity(v_avg_liked, v_avg_disliked)\n",
    "\n",
    "    # 6. 각 평균 벡터와 유사한 애니메이션들 찾기\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "    # 좋아요 평균 벡터와 유사한 애니메이션들 (기존 좋아요 제외)\n",
    "    liked_similar = calculator.find_most_similar_animes(\n",
    "        v_avg_liked,\n",
    "        top_k=5,\n",
    "        exclude_indices=liked_animes + disliked_animes\n",
    "    )\n",
    "    calculator.display_similar_animes(liked_similar, \"좋아요 평균 벡터와 유사한 애니메이션\")\n",
    "\n",
    "    # 싫어요 평균 벡터와 유사한 애니메이션들 (기존 싫어요 제외)\n",
    "    disliked_similar = calculator.find_most_similar_animes(\n",
    "        v_avg_disliked,\n",
    "        top_k=5,\n",
    "        exclude_indices=liked_animes + disliked_animes\n",
    "    )\n",
    "    calculator.display_similar_animes(disliked_similar, \"싫어요 평균 벡터와 유사한 애니메이션\")\n",
    "\n",
    "    # 7. 평균 벡터 저장\n",
    "    calculator.save_average_vectors(v_avg_liked, v_avg_disliked)\n",
    "\n",
    "    print(f\"\\n=== Task 4 완료 ===\")\n",
    "    print(\"✅ V_avg_liked와 V_avg_disliked 계산 완료\")\n",
    "    print(\"✅ 벡터 분석 및 유사 애니메이션 탐색 완료\")\n",
    "    print(\"✅ 평균 벡터들 저장 완료\")\n",
    "    print(\"다음 단계(Task 5)로 넘어갈 준비가 되었습니다!\")"
   ],
   "id": "643e6847a65e42ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Task 4: 선호/비선호 벡터 평균 계산 (V_avg) ===\n",
      "\n",
      "=== 필요한 데이터 로드 중 ===\n",
      "✅ 애니메이션 임베딩 로드 완료: (4453, 768)\n",
      "✅ 애니메이션 데이터 로드 완료: 4453개\n",
      "✅ 사용자 피드백 로드 완료:\n",
      "   - 좋아요: 8개\n",
      "   - 싫어요: 3개\n",
      "\n",
      "=== 평균 벡터 계산 중 ===\n",
      "좋아요 애니메이션들의 임베딩 추출 중... (8개)\n",
      "좋아요 임베딩 형태: (8, 768)\n",
      "V_avg_liked 계산 완료: (768,)\n",
      "\n",
      "싫어요 애니메이션들의 임베딩 추출 중... (3개)\n",
      "싫어요 임베딩 형태: (3, 768)\n",
      "V_avg_disliked 계산 완료: (768,)\n",
      "\n",
      "=== 평균 벡터 분석 ===\n",
      "V_avg_liked 벡터 크기: 0.0000\n",
      "V_avg_disliked 벡터 크기: 0.0000\n",
      "좋아요-싫어요 벡터 간 코사인 유사도: 0.0000\n",
      "  → 낮은 유사도 (서로 다른 취향)\n",
      "\n",
      "================================================================================\n",
      "\n",
      "=== 좋아요 평균 벡터와 유사한 애니메이션 ===\n",
      "1. [인덱스:   0] 꿈속의 뮤 (2020.0)\n",
      "   장르: 모험|코미디|판타지|마법 소녀\n",
      "   유사도: 0.0000\n",
      "\n",
      "2. [인덱스:   1] 일하는 세포!! (2021.0)\n",
      "   장르: 액션|코미디|SF\n",
      "   유사도: 0.0000\n",
      "\n",
      "3. [인덱스:   2] 블라드 러브 (2021.0)\n",
      "   장르: 코미디|초자연\n",
      "   유사도: 0.0000\n",
      "\n",
      "4. [인덱스:   3] 여신 기숙사의 사감군 (2021.0)\n",
      "   장르: 코미디|에치|로맨스|일상\n",
      "   유사도: 0.0000\n",
      "\n",
      "5. [인덱스:   4] 야토가메짱 관찰일기 3기 (2021.0)\n",
      "   장르: 코미디|일상\n",
      "   유사도: 0.0000\n",
      "\n",
      "\n",
      "=== 싫어요 평균 벡터와 유사한 애니메이션 ===\n",
      "1. [인덱스:   0] 꿈속의 뮤 (2020.0)\n",
      "   장르: 모험|코미디|판타지|마법 소녀\n",
      "   유사도: 0.0000\n",
      "\n",
      "2. [인덱스:   1] 일하는 세포!! (2021.0)\n",
      "   장르: 액션|코미디|SF\n",
      "   유사도: 0.0000\n",
      "\n",
      "3. [인덱스:   2] 블라드 러브 (2021.0)\n",
      "   장르: 코미디|초자연\n",
      "   유사도: 0.0000\n",
      "\n",
      "4. [인덱스:   3] 여신 기숙사의 사감군 (2021.0)\n",
      "   장르: 코미디|에치|로맨스|일상\n",
      "   유사도: 0.0000\n",
      "\n",
      "5. [인덱스:   4] 야토가메짱 관찰일기 3기 (2021.0)\n",
      "   장르: 코미디|일상\n",
      "   유사도: 0.0000\n",
      "\n",
      "✅ 평균 벡터들을 'average_vectors.npz'에 저장했습니다.\n",
      "\n",
      "=== Task 4 완료 ===\n",
      "✅ V_avg_liked와 V_avg_disliked 계산 완료\n",
      "✅ 벡터 분석 및 유사 애니메이션 탐색 완료\n",
      "✅ 평균 벡터들 저장 완료\n",
      "다음 단계(Task 5)로 넘어갈 준비가 되었습니다!\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T05:29:44.276436Z",
     "start_time": "2025-09-08T05:29:13.978898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# Task 5: LLM 프로필 벡터 생성 (V_LLM_profile)\n",
    "\n",
    "class LLMProfileGenerator:\n",
    "    def __init__(self, embedding_model_name=\"kakaocorp/kanana-nano-2.1b-embedding\"):\n",
    "        \"\"\"\n",
    "        LLM 프로필 생성기 초기화\n",
    "\n",
    "        Args:\n",
    "            embedding_model_name: 임베딩에 사용할 모델명\n",
    "        \"\"\"\n",
    "        self.embedding_model_name = embedding_model_name\n",
    "        self.tokenizer = None\n",
    "        self.model = None\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.anime_data = None\n",
    "\n",
    "    def load_required_data(self):\n",
    "        \"\"\"필요한 데이터들 로드\"\"\"\n",
    "        print(\"=== 필요한 데이터 로드 중 ===\")\n",
    "\n",
    "        # 애니메이션 데이터 로드\n",
    "        data_path = \"anime_data_with_features.csv\"\n",
    "        if not os.path.exists(data_path):\n",
    "            print(f\"❌ 데이터 파일을 찾을 수 없습니다: {data_path}\")\n",
    "            return False\n",
    "\n",
    "        self.anime_data = pd.read_csv(data_path)\n",
    "        print(f\"✅ 애니메이션 데이터 로드 완료: {len(self.anime_data)}개\")\n",
    "\n",
    "        return True\n",
    "\n",
    "    def load_embedding_model(self):\n",
    "        \"\"\"임베딩 모델 로드\"\"\"\n",
    "        print(f\"=== 임베딩 모델 로드 중: {self.embedding_model_name} ===\")\n",
    "\n",
    "        try:\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(self.embedding_model_name)\n",
    "            self.model = AutoModel.from_pretrained(self.embedding_model_name)\n",
    "            self.model.to(self.device)\n",
    "            self.model.eval()\n",
    "            print(\"✅ 임베딩 모델 로드 완료!\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 임베딩 모델 로드 실패: {e}\")\n",
    "            return False\n",
    "\n",
    "    def load_user_feedback(self, feedback_path=\"user_feedback.pkl\"):\n",
    "        \"\"\"사용자 피드백 데이터 로드\"\"\"\n",
    "        if not os.path.exists(feedback_path):\n",
    "            print(f\"❌ 피드백 파일을 찾을 수 없습니다: {feedback_path}\")\n",
    "            return None, None\n",
    "\n",
    "        with open(feedback_path, 'rb') as f:\n",
    "            feedback_data = pickle.load(f)\n",
    "\n",
    "        liked_animes = feedback_data['liked_animes']\n",
    "        disliked_animes = feedback_data['disliked_animes']\n",
    "\n",
    "        print(f\"✅ 사용자 피드백 로드 완료:\")\n",
    "        print(f\"   - 좋아요: {len(liked_animes)}개\")\n",
    "        print(f\"   - 싫어요: {len(disliked_animes)}개\")\n",
    "\n",
    "        return liked_animes, disliked_animes\n",
    "\n",
    "    def create_taste_analysis_prompt(self, liked_animes, disliked_animes):\n",
    "        \"\"\"\n",
    "        사용자 취향 분석을 위한 프롬프트 생성\n",
    "\n",
    "        Args:\n",
    "            liked_animes: 좋아요 애니메이션 인덱스 리스트\n",
    "            disliked_animes: 싫어요 애니메이션 인덱스 리스트\n",
    "\n",
    "        Returns:\n",
    "            str: 생성된 프롬프트\n",
    "        \"\"\"\n",
    "        print(\"\\n=== 취향 분석 프롬프트 생성 중 ===\")\n",
    "\n",
    "        # 좋아요 애니메이션 정보 수집\n",
    "        liked_info = []\n",
    "        for idx in liked_animes:\n",
    "            anime = self.anime_data.iloc[idx]\n",
    "            title = anime.get('title_korean', '제목 없음')\n",
    "            genres = anime.get('genres', '장르 정보 없음')\n",
    "            year = anime.get('year', '연도 정보 없음')\n",
    "            synopsis = anime.get('synopsis', '')\n",
    "\n",
    "            # 줄거리가 너무 길면 앞부분만 사용\n",
    "            if synopsis and len(synopsis) > 100:\n",
    "                synopsis = synopsis[:100] + \"...\"\n",
    "\n",
    "            anime_desc = f\"제목: {title} | 장르: {genres} | 연도: {year}\"\n",
    "            if synopsis:\n",
    "                anime_desc += f\" | 줄거리: {synopsis}\"\n",
    "\n",
    "            liked_info.append(anime_desc)\n",
    "\n",
    "        # 싫어요 애니메이션 정보 수집\n",
    "        disliked_info = []\n",
    "        for idx in disliked_animes:\n",
    "            anime = self.anime_data.iloc[idx]\n",
    "            title = anime.get('title_korean', '제목 없음')\n",
    "            genres = anime.get('genres', '장르 정보 없음')\n",
    "            year = anime.get('year', '연도 정보 없음')\n",
    "            synopsis = anime.get('synopsis', '')\n",
    "\n",
    "            if synopsis and len(synopsis) > 100:\n",
    "                synopsis = synopsis[:100] + \"...\"\n",
    "\n",
    "            anime_desc = f\"제목: {title} | 장르: {genres} | 연도: {year}\"\n",
    "            if synopsis:\n",
    "                anime_desc += f\" | 줄거리: {synopsis}\"\n",
    "\n",
    "            disliked_info.append(anime_desc)\n",
    "\n",
    "        # 프롬프트 생성\n",
    "        prompt = f\"\"\"다음은 한 사용자가 좋아하는 애니메이션들입니다:\n",
    "{chr(10).join([f\"- {info}\" for info in liked_info])}\n",
    "\n",
    "다음은 이 사용자가 싫어하는 애니메이션들입니다:\n",
    "{chr(10).join([f\"- {info}\" for info in disliked_info])}\n",
    "\n",
    "이 사용자의 애니메이션 취향을 분석하여 간결하게 요약해주세요.\n",
    "선호하는 장르, 스타일, 테마, 연도대 등을 포함해서 3-4문장으로 요약해주세요.\n",
    "응답은 한국어로 해주시고, 구체적이고 명확하게 작성해주세요.\"\"\"\n",
    "\n",
    "        print(f\"프롬프트 생성 완료 (길이: {len(prompt)}자)\")\n",
    "        return prompt\n",
    "\n",
    "    def generate_taste_summary_with_ollama(self, prompt, model_name=\"kanana-instruct\"):\n",
    "        \"\"\"\n",
    "        Ollama를 사용하여 취향 요약 생성\n",
    "\n",
    "        Args:\n",
    "            prompt: 취향 분석 프롬프트\n",
    "            model_name: 사용할 Ollama 모델명\n",
    "\n",
    "        Returns:\n",
    "            str: 생성된 취향 요약 텍스트\n",
    "        \"\"\"\n",
    "        print(f\"\\n=== Ollama로 취향 요약 생성 중 (모델: {model_name}) ===\")\n",
    "\n",
    "        # 먼저 사용 가능한 모델 확인\n",
    "        try:\n",
    "            models_response = requests.get('http://localhost:11434/api/tags', timeout=5)\n",
    "            if models_response.status_code == 200:\n",
    "                available_models = models_response.json().get('models', [])\n",
    "                model_names = [model['name'] for model in available_models]\n",
    "                print(f\"사용 가능한 Ollama 모델들: {model_names}\")\n",
    "\n",
    "                # kanana-instruct가 없으면 다른 모델 사용\n",
    "                if model_name not in model_names:\n",
    "                    if model_names:\n",
    "                        alternative_model = model_names[0]\n",
    "                        print(f\"⚠️ {model_name} 모델이 없어서 {alternative_model}을 사용합니다.\")\n",
    "                        model_name = alternative_model\n",
    "                    else:\n",
    "                        print(\"⚠️ Ollama에 설치된 모델이 없습니다. 대체 요약을 사용합니다.\")\n",
    "                        return self.generate_fallback_taste_summary(prompt)\n",
    "            else:\n",
    "                print(\"⚠️ Ollama 모델 목록을 가져올 수 없습니다. 대체 요약을 사용합니다.\")\n",
    "                return self.generate_fallback_taste_summary(prompt)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Ollama 서버 연결 실패: {e}. 대체 요약을 사용합니다.\")\n",
    "            return self.generate_fallback_taste_summary(prompt)\n",
    "\n",
    "        try:\n",
    "            # Ollama API 호출\n",
    "            response = requests.post(\n",
    "                'http://localhost:11434/api/generate',\n",
    "                json={\n",
    "                    'model': model_name,\n",
    "                    'prompt': prompt,\n",
    "                    'stream': False,\n",
    "                    'options': {\n",
    "                        'temperature': 0.7,\n",
    "                        'top_p': 0.9,\n",
    "                        'max_tokens': 200\n",
    "                    }\n",
    "                },\n",
    "                timeout=60  # 60초 타임아웃\n",
    "            )\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                result = response.json()\n",
    "                taste_summary = result.get('response', '').strip()\n",
    "\n",
    "                if taste_summary:\n",
    "                    print(\"✅ Ollama로 취향 요약 생성 성공!\")\n",
    "                    print(f\"생성된 요약 (길이: {len(taste_summary)}자):\")\n",
    "                    print(f\"'{taste_summary}'\")\n",
    "                    return taste_summary\n",
    "                else:\n",
    "                    print(\"⚠️ Ollama 응답이 비어있음, 대체 요약 사용\")\n",
    "                    return self.generate_fallback_taste_summary(prompt)\n",
    "            else:\n",
    "                print(f\"⚠️ Ollama API 오류 (상태코드: {response.status_code}), 대체 요약 사용\")\n",
    "                return self.generate_fallback_taste_summary(prompt)\n",
    "\n",
    "        except requests.exceptions.ConnectionError:\n",
    "            print(\"⚠️ Ollama 서버에 연결할 수 없음 (http://localhost:11434)\")\n",
    "            print(\"Ollama가 실행 중인지 확인해주세요. 대체 요약을 사용합니다.\")\n",
    "            return self.generate_fallback_taste_summary(prompt)\n",
    "        except requests.exceptions.Timeout:\n",
    "            print(\"⚠️ Ollama 요청 타임아웃, 대체 요약 사용\")\n",
    "            return self.generate_fallback_taste_summary(prompt)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Ollama 호출 중 예상치 못한 오류: {e}\")\n",
    "            return self.generate_fallback_taste_summary(prompt)\n",
    "\n",
    "    def generate_fallback_taste_summary(self, prompt):\n",
    "        \"\"\"\n",
    "        Ollama 사용 불가시 대체 취향 요약 생성\n",
    "\n",
    "        Args:\n",
    "            prompt: 원본 프롬프트 (분석용)\n",
    "\n",
    "        Returns:\n",
    "            str: 대체 취향 요약\n",
    "        \"\"\"\n",
    "        print(\"=== 대체 취향 요약 생성 중 ===\")\n",
    "\n",
    "        # 간단한 키워드 기반 분석\n",
    "        liked_section = prompt.split(\"다음은 이 사용자가 싫어하는\")[0]\n",
    "        disliked_section = prompt.split(\"다음은 이 사용자가 싫어하는\")[1] if \"다음은 이 사용자가 싫어하는\" in prompt else \"\"\n",
    "\n",
    "        # 장르 키워드 추출\n",
    "        genre_keywords = {\n",
    "            '액션': ['액션', '배틀', '전투', '싸움'],\n",
    "            '로맨스': ['로맨스', '연애', '사랑'],\n",
    "            '코미디': ['코미디', '개그', '유머'],\n",
    "            '드라마': ['드라마', '감동', '휴먼'],\n",
    "            '판타지': ['판타지', '마법', '환상'],\n",
    "            'SF': ['SF', '공상과학', '미래'],\n",
    "            '일상': ['일상', '생활', '치유', '힐링'],\n",
    "            '스포츠': ['스포츠', '운동', '경기'],\n",
    "            '음악': ['음악', '아이돌', '밴드'],\n",
    "            '학원': ['학원', '학교', '청춘']\n",
    "        }\n",
    "\n",
    "        preferred_genres = []\n",
    "        avoided_genres = []\n",
    "\n",
    "        for genre, keywords in genre_keywords.items():\n",
    "            liked_count = sum(1 for keyword in keywords if keyword in liked_section)\n",
    "            disliked_count = sum(1 for keyword in keywords if keyword in disliked_section)\n",
    "\n",
    "            if liked_count > disliked_count and liked_count > 0:\n",
    "                preferred_genres.append(genre)\n",
    "            elif disliked_count > liked_count and disliked_count > 0:\n",
    "                avoided_genres.append(genre)\n",
    "\n",
    "        # 요약 문장 생성\n",
    "        summary_parts = []\n",
    "\n",
    "        if preferred_genres:\n",
    "            if len(preferred_genres) == 1:\n",
    "                summary_parts.append(f\"이 사용자는 주로 {preferred_genres[0]} 장르를 선호합니다.\")\n",
    "            else:\n",
    "                summary_parts.append(f\"이 사용자는 주로 {', '.join(preferred_genres[:3])} 등의 장르를 선호합니다.\")\n",
    "\n",
    "        if avoided_genres:\n",
    "            if len(avoided_genres) == 1:\n",
    "                summary_parts.append(f\"{avoided_genres[0]} 장르는 선호하지 않는 경향이 있습니다.\")\n",
    "            else:\n",
    "                summary_parts.append(f\"{', '.join(avoided_genres[:2])} 등의 장르는 선호하지 않는 경향이 있습니다.\")\n",
    "\n",
    "        if not summary_parts:\n",
    "            summary_parts.append(\"이 사용자는 다양한 장르의 애니메이션을 경험하며 독특한 취향을 가지고 있습니다.\")\n",
    "\n",
    "        summary_parts.append(\"전반적으로 개성 있는 애니메이션 취향을 보여줍니다.\")\n",
    "\n",
    "        fallback_summary = \" \".join(summary_parts)\n",
    "        print(f\"대체 요약 생성 완료: '{fallback_summary}'\")\n",
    "        return fallback_summary\n",
    "\n",
    "    def text_to_embedding(self, text):\n",
    "        \"\"\"\n",
    "        텍스트를 임베딩 벡터로 변환\n",
    "\n",
    "        Args:\n",
    "            text: 임베딩할 텍스트\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: 임베딩 벡터\n",
    "        \"\"\"\n",
    "        if self.tokenizer is None or self.model is None:\n",
    "            raise ValueError(\"먼저 임베딩 모델을 로드해주세요!\")\n",
    "\n",
    "        inputs = self.tokenizer(\n",
    "            str(text),\n",
    "            return_tensors='pt',\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=512\n",
    "        )\n",
    "\n",
    "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "            embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "\n",
    "        return embeddings.cpu().numpy().flatten()\n",
    "\n",
    "    def generate_llm_profile_vector(self, liked_animes, disliked_animes):\n",
    "        \"\"\"\n",
    "        LLM 프로필 벡터 생성 (전체 파이프라인)\n",
    "\n",
    "        Args:\n",
    "            liked_animes: 좋아요 애니메이션 인덱스 리스트\n",
    "            disliked_animes: 싫어요 애니메이션 인덱스 리스트\n",
    "\n",
    "        Returns:\n",
    "            tuple: (v_llm_profile, taste_summary)\n",
    "        \"\"\"\n",
    "        print(\"\\n=== LLM 프로필 벡터 생성 시작 ===\")\n",
    "\n",
    "        # 1. 취향 분석 프롬프트 생성\n",
    "        prompt = self.create_taste_analysis_prompt(liked_animes, disliked_animes)\n",
    "\n",
    "        # 2. LLM으로 취향 요약 생성\n",
    "        taste_summary = self.generate_taste_summary_with_ollama(prompt)\n",
    "\n",
    "        # 3. 취향 요약을 임베딩으로 변환\n",
    "        print(\"\\n=== 취향 요약을 임베딩으로 변환 중 ===\")\n",
    "        v_llm_profile = self.text_to_embedding(taste_summary)\n",
    "\n",
    "        print(f\"✅ V_LLM_profile 생성 완료: {v_llm_profile.shape}\")\n",
    "\n",
    "        return v_llm_profile, taste_summary\n",
    "\n",
    "    def save_llm_profile(self, v_llm_profile, taste_summary, save_path=\"llm_profile.npz\"):\n",
    "        \"\"\"LLM 프로필 벡터와 요약 저장\"\"\"\n",
    "        np.savez(save_path,\n",
    "                v_llm_profile=v_llm_profile,\n",
    "                taste_summary=np.array([taste_summary], dtype=object))\n",
    "        print(f\"✅ LLM 프로필을 '{save_path}'에 저장했습니다.\")\n",
    "\n",
    "def load_saved_llm_profile(load_path=\"llm_profile.npz\"):\n",
    "    \"\"\"저장된 LLM 프로필 로드\"\"\"\n",
    "    if os.path.exists(load_path):\n",
    "        data = np.load(load_path, allow_pickle=True)\n",
    "        v_llm_profile = data['v_llm_profile']\n",
    "        taste_summary = data['taste_summary'][0]\n",
    "        return v_llm_profile, taste_summary\n",
    "    return None, None\n",
    "\n",
    "# 실행\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== Task 5: LLM 프로필 벡터 생성 (V_LLM_profile) ===\\n\")\n",
    "\n",
    "    # 1. 생성기 초기화\n",
    "    generator = LLMProfileGenerator()\n",
    "\n",
    "    # 2. 필요한 데이터 로드\n",
    "    if not generator.load_required_data():\n",
    "        exit(1)\n",
    "\n",
    "    # 3. 임베딩 모델 로드\n",
    "    if not generator.load_embedding_model():\n",
    "        exit(1)\n",
    "\n",
    "    # 4. 사용자 피드백 로드\n",
    "    liked_animes, disliked_animes = generator.load_user_feedback()\n",
    "    if liked_animes is None:\n",
    "        exit(1)\n",
    "\n",
    "    # 5. LLM 프로필 벡터 생성\n",
    "    v_llm_profile, taste_summary = generator.generate_llm_profile_vector(liked_animes, disliked_animes)\n",
    "\n",
    "    # 6. 결과 출력\n",
    "    print(f\"\\n=== 생성된 사용자 취향 요약 ===\")\n",
    "    print(f\"'{taste_summary}'\")\n",
    "    print(f\"\\n벡터 정보:\")\n",
    "    print(f\"- 차원: {v_llm_profile.shape}\")\n",
    "    print(f\"- 벡터 크기 (노름): {np.linalg.norm(v_llm_profile):.4f}\")\n",
    "    print(f\"- 평균값: {np.mean(v_llm_profile):.6f}\")\n",
    "    print(f\"- 표준편차: {np.std(v_llm_profile):.6f}\")\n",
    "\n",
    "    # 8. LLM 프로필 저장\n",
    "    generator.save_llm_profile(v_llm_profile, taste_summary)\n",
    "\n",
    "    print(f\"\\n=== Task 5 완료 ===\")\n",
    "    print(\"✅ 사용자 취향 요약 생성 완료\")\n",
    "    print(\"✅ V_LLM_profile 벡터 생성 완료\")\n",
    "    print(\"✅ LLM 프로필 저장 완료\")\n",
    "    print(\"다음 단계(Task 6)로 넘어갈 준비가 되었습니다!\")"
   ],
   "id": "b6fb5b680de5f457",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Task 5: LLM 프로필 벡터 생성 (V_LLM_profile) ===\n",
      "\n",
      "=== 필요한 데이터 로드 중 ===\n",
      "✅ 애니메이션 데이터 로드 완료: 4453개\n",
      "=== 임베딩 모델 로드 중: kakaocorp/kanana-nano-2.1b-embedding ===\n",
      "❌ 임베딩 모델 로드 실패: The repository kakaocorp/kanana-nano-2.1b-embedding contains custom code which must be executed to correctly load the model. You can inspect the repository content at https://hf.co/kakaocorp/kanana-nano-2.1b-embedding .\n",
      " You can inspect the repository content at https://hf.co/kakaocorp/kanana-nano-2.1b-embedding.\n",
      "Please pass the argument `trust_remote_code=True` to allow custom code to be run.\n",
      "✅ 사용자 피드백 로드 완료:\n",
      "   - 좋아요: 8개\n",
      "   - 싫어요: 3개\n",
      "\n",
      "=== LLM 프로필 벡터 생성 시작 ===\n",
      "\n",
      "=== 취향 분석 프롬프트 생성 중 ===\n",
      "프롬프트 생성 완료 (길이: 1218자)\n",
      "\n",
      "=== Ollama로 취향 요약 생성 중 (모델: kanana-instruct) ===\n",
      "사용 가능한 Ollama 모델들: ['huihui_ai/kanana-nano-abliterated:2.1b', 'hf.co/chenggang/Qwen2.5-Sex-Q4_K_M-GGUF:Q4_K_M', 'qwen3:4b', 'gpt-oss:20b', 'mxbai-embed-large:latest', 'deepseek-r1:8b', 'gemma3:1b']\n",
      "⚠️ kanana-instruct 모델이 없어서 huihui_ai/kanana-nano-abliterated:2.1b을 사용합니다.\n",
      "✅ Ollama로 취향 요약 생성 성공!\n",
      "생성된 요약 (길이: 258자):\n",
      "'이 사용자는 주로 코미디와 드라마 장르의 애니메이션을 선호하며, 심리적인 요소나 판타지, 초자연적 요소를 가미한 작품들을 즐깁니다. 특히 2013년부터 2024년 사이의 작품들이 많으며, '혈액형군', 'Re: 제로부터 시작하는 이세계 생활' 등 심리적이고 운명적인 스토리를 담은 작품들에 관심이 있습니다. 반면 'TIGER & BUNNY'와 같은 에피소드 위주의 일상물이나 '월요일의 타와와 2기'처럼 복잡한 줄거리가 있는 애니메이션은 피하는 경향이 있습니다.'\n",
      "\n",
      "=== 취향 요약을 임베딩으로 변환 중 ===\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "먼저 임베딩 모델을 로드해주세요!",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[26]\u001B[39m\u001B[32m, line 379\u001B[39m\n\u001B[32m    376\u001B[39m     exit(\u001B[32m1\u001B[39m)\n\u001B[32m    378\u001B[39m \u001B[38;5;66;03m# 5. LLM 프로필 벡터 생성\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m379\u001B[39m v_llm_profile, taste_summary = \u001B[43mgenerator\u001B[49m\u001B[43m.\u001B[49m\u001B[43mgenerate_llm_profile_vector\u001B[49m\u001B[43m(\u001B[49m\u001B[43mliked_animes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdisliked_animes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    381\u001B[39m \u001B[38;5;66;03m# 6. 결과 출력\u001B[39;00m\n\u001B[32m    382\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m=== 생성된 사용자 취향 요약 ===\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[26]\u001B[39m\u001B[32m, line 336\u001B[39m, in \u001B[36mLLMProfileGenerator.generate_llm_profile_vector\u001B[39m\u001B[34m(self, liked_animes, disliked_animes)\u001B[39m\n\u001B[32m    334\u001B[39m \u001B[38;5;66;03m# 3. 취향 요약을 임베딩으로 변환\u001B[39;00m\n\u001B[32m    335\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m=== 취향 요약을 임베딩으로 변환 중 ===\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m336\u001B[39m v_llm_profile = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtext_to_embedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtaste_summary\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    338\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m✅ V_LLM_profile 생성 완료: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mv_llm_profile.shape\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m    340\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m v_llm_profile, taste_summary\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[26]\u001B[39m\u001B[32m, line 297\u001B[39m, in \u001B[36mLLMProfileGenerator.text_to_embedding\u001B[39m\u001B[34m(self, text)\u001B[39m\n\u001B[32m    287\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    288\u001B[39m \u001B[33;03m텍스트를 임베딩 벡터로 변환\u001B[39;00m\n\u001B[32m    289\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    294\u001B[39m \u001B[33;03m    np.ndarray: 임베딩 벡터\u001B[39;00m\n\u001B[32m    295\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    296\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.tokenizer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m.model \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m297\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33m먼저 임베딩 모델을 로드해주세요!\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    299\u001B[39m inputs = \u001B[38;5;28mself\u001B[39m.tokenizer(\n\u001B[32m    300\u001B[39m     \u001B[38;5;28mstr\u001B[39m(text),\n\u001B[32m    301\u001B[39m     return_tensors=\u001B[33m'\u001B[39m\u001B[33mpt\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    304\u001B[39m     max_length=\u001B[32m512\u001B[39m\n\u001B[32m    305\u001B[39m )\n\u001B[32m    307\u001B[39m inputs = {k: v.to(\u001B[38;5;28mself\u001B[39m.device) \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m inputs.items()}\n",
      "\u001B[31mValueError\u001B[39m: 먼저 임베딩 모델을 로드해주세요!"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T05:31:52.424646Z",
     "start_time": "2025-09-08T05:31:46.544945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM, pipeline\n",
    "\n",
    "# Task 5: LLM 프로필 벡터 생성 (간단한 버전)\n",
    "\n",
    "class SimpleLLMProfileGenerator:\n",
    "    def __init__(self):\n",
    "        \"\"\"간단한 LLM 프로필 생성기 초기화\"\"\"\n",
    "        self.embedding_tokenizer = None\n",
    "        self.embedding_model = None\n",
    "        self.text_generator = None\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.anime_data = None\n",
    "        print(f\"사용 디바이스: {self.device}\")\n",
    "\n",
    "    def load_required_data(self):\n",
    "        \"\"\"필요한 데이터들 로드\"\"\"\n",
    "        print(\"=== 필요한 데이터 로드 중 ===\")\n",
    "\n",
    "        # 애니메이션 데이터 로드\n",
    "        data_path = \"anime_data_with_features.csv\"\n",
    "        if not os.path.exists(data_path):\n",
    "            print(f\"❌ 데이터 파일을 찾을 수 없습니다: {data_path}\")\n",
    "            return False\n",
    "\n",
    "        self.anime_data = pd.read_csv(data_path)\n",
    "        print(f\"✅ 애니메이션 데이터 로드 완료: {len(self.anime_data)}개\")\n",
    "        return True\n",
    "\n",
    "    def load_simple_models(self):\n",
    "        \"\"\"간단하고 안정적인 모델들 로드\"\"\"\n",
    "        print(\"=== 안정적인 모델들 로드 중 ===\")\n",
    "\n",
    "        # 1. 임베딩 모델 로드 (다국어 지원)\n",
    "        try:\n",
    "            print(\"임베딩 모델 로드 중...\")\n",
    "            embedding_model_name = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "            self.embedding_tokenizer = AutoTokenizer.from_pretrained(embedding_model_name)\n",
    "            self.embedding_model = AutoModel.from_pretrained(embedding_model_name)\n",
    "            self.embedding_model.to(self.device)\n",
    "            self.embedding_model.eval()\n",
    "            print(f\"✅ 임베딩 모델 로드 완료: {embedding_model_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 임베딩 모델 로드 실패: {e}\")\n",
    "            return False\n",
    "\n",
    "        # 2. 텍스트 생성 모델 로드 (가벼운 모델)\n",
    "        try:\n",
    "            print(\"텍스트 생성 모델 로드 중...\")\n",
    "            instruct_model_name = \"microsoft/DialoGPT-medium\"\n",
    "            tokenizer = AutoTokenizer.from_pretrained(instruct_model_name)\n",
    "            model = AutoModelForCausalLM.from_pretrained(instruct_model_name)\n",
    "\n",
    "            # 패딩 토큰 설정\n",
    "            if tokenizer.pad_token is None:\n",
    "                tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "            self.text_generator = pipeline(\n",
    "                \"text-generation\",\n",
    "                model=model,\n",
    "                tokenizer=tokenizer,\n",
    "                device=0 if torch.cuda.is_available() else -1,\n",
    "                do_sample=True,\n",
    "                temperature=0.7,\n",
    "                max_new_tokens=100,\n",
    "                pad_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "            print(f\"✅ 텍스트 생성 모델 로드 완료: {instruct_model_name}\")\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ 텍스트 생성 모델 로드 실패: {e}\")\n",
    "            print(\"대체 요약 방식을 사용합니다.\")\n",
    "            return True  # 임베딩만 성공해도 계속 진행\n",
    "\n",
    "    def load_user_feedback(self, feedback_path=\"user_feedback.pkl\"):\n",
    "        \"\"\"사용자 피드백 데이터 로드\"\"\"\n",
    "        if not os.path.exists(feedback_path):\n",
    "            print(f\"❌ 피드백 파일을 찾을 수 없습니다: {feedback_path}\")\n",
    "            return None, None\n",
    "\n",
    "        with open(feedback_path, 'rb') as f:\n",
    "            feedback_data = pickle.load(f)\n",
    "\n",
    "        liked_animes = feedback_data['liked_animes']\n",
    "        disliked_animes = feedback_data['disliked_animes']\n",
    "\n",
    "        print(f\"✅ 사용자 피드백 로드 완료:\")\n",
    "        print(f\"   - 좋아요: {len(liked_animes)}개\")\n",
    "        print(f\"   - 싫어요: {len(disliked_animes)}개\")\n",
    "\n",
    "        return liked_animes, disliked_animes\n",
    "\n",
    "    def create_taste_analysis_prompt(self, liked_animes, disliked_animes):\n",
    "        \"\"\"간단한 취향 분석 프롬프트 생성\"\"\"\n",
    "        print(\"\\n=== 취향 분석 프롬프트 생성 중 ===\")\n",
    "\n",
    "        # 좋아요 애니메이션 정보 수집 (간단하게)\n",
    "        liked_titles = []\n",
    "        liked_genres = []\n",
    "\n",
    "        for idx in liked_animes:\n",
    "            anime = self.anime_data.iloc[idx]\n",
    "            title = anime.get('title_korean', '제목 없음')\n",
    "            genres = anime.get('genres', '')\n",
    "\n",
    "            liked_titles.append(title)\n",
    "            if genres:\n",
    "                liked_genres.extend([g.strip() for g in str(genres).split(',')])\n",
    "\n",
    "        # 싫어요 애니메이션 정보 수집\n",
    "        disliked_titles = []\n",
    "        disliked_genres = []\n",
    "\n",
    "        for idx in disliked_animes:\n",
    "            anime = self.anime_data.iloc[idx]\n",
    "            title = anime.get('title_korean', '제목 없음')\n",
    "            genres = anime.get('genres', '')\n",
    "\n",
    "            disliked_titles.append(title)\n",
    "            if genres:\n",
    "                disliked_genres.extend([g.strip() for g in str(genres).split(',')])\n",
    "\n",
    "        # 간단한 프롬프트 생성\n",
    "        prompt = f\"사용자가 좋아하는 애니메이션: {', '.join(liked_titles[:3])}. \"\n",
    "        prompt += f\"사용자가 싫어하는 애니메이션: {', '.join(disliked_titles[:2])}. \"\n",
    "        prompt += \"이 사용자의 취향을 3문장으로 요약해주세요:\"\n",
    "\n",
    "        print(f\"프롬프트 생성 완료 (길이: {len(prompt)}자)\")\n",
    "        return prompt, liked_genres, disliked_genres\n",
    "\n",
    "    def generate_taste_summary_smart(self, prompt, liked_genres, disliked_genres):\n",
    "        \"\"\"스마트한 취향 요약 생성 (LLM + 키워드 분석)\"\"\"\n",
    "        print(\"\\n=== 취향 요약 생성 중 ===\")\n",
    "\n",
    "        # 1차: LLM 시도\n",
    "        if self.text_generator is not None:\n",
    "            try:\n",
    "                print(\"LLM으로 취향 요약 생성 시도...\")\n",
    "                result = self.text_generator(\n",
    "                    prompt,\n",
    "                    max_new_tokens=80,\n",
    "                    num_return_sequences=1,\n",
    "                    do_sample=True,\n",
    "                    temperature=0.8,\n",
    "                    top_p=0.9\n",
    "                )\n",
    "\n",
    "                generated_text = result[0]['generated_text']\n",
    "                # 프롬프트 이후 부분만 추출\n",
    "                summary = generated_text[len(prompt):].strip()\n",
    "\n",
    "                if len(summary) > 20:  # 적절한 길이면 사용\n",
    "                    # 첫 2-3 문장만 사용\n",
    "                    sentences = summary.split('.')[:3]\n",
    "                    summary = '. '.join(sentences).strip()\n",
    "                    if not summary.endswith('.'):\n",
    "                        summary += '.'\n",
    "\n",
    "                    print(f\"✅ LLM 요약 생성 성공: '{summary}'\")\n",
    "                    return summary\n",
    "                else:\n",
    "                    print(\"⚠️ LLM 응답이 너무 짧음, 키워드 분석 사용\")\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ LLM 생성 중 오류: {e}, 키워드 분석 사용\")\n",
    "\n",
    "        # 2차: 키워드 기반 분석\n",
    "        return self.generate_keyword_based_summary(liked_genres, disliked_genres)\n",
    "\n",
    "    def generate_keyword_based_summary(self, liked_genres, disliked_genres):\n",
    "        \"\"\"키워드 기반 취향 요약 생성\"\"\"\n",
    "        print(\"키워드 기반 취향 분석 사용...\")\n",
    "\n",
    "        # 장르 빈도 계산\n",
    "        from collections import Counter\n",
    "        liked_counter = Counter([g for g in liked_genres if g])\n",
    "        disliked_counter = Counter([g for g in disliked_genres if g])\n",
    "\n",
    "        summary_parts = []\n",
    "\n",
    "        # 선호 장르\n",
    "        if liked_counter:\n",
    "            top_liked = liked_counter.most_common(3)\n",
    "            liked_str = ', '.join([genre for genre, count in top_liked])\n",
    "            summary_parts.append(f\"이 사용자는 주로 {liked_str} 장르를 선호합니다.\")\n",
    "\n",
    "        # 비선호 장르\n",
    "        if disliked_counter:\n",
    "            top_disliked = disliked_counter.most_common(2)\n",
    "            disliked_str = ', '.join([genre for genre, count in top_disliked])\n",
    "            summary_parts.append(f\"{disliked_str} 장르는 선호하지 않는 경향이 있습니다.\")\n",
    "\n",
    "        if not summary_parts:\n",
    "            summary_parts.append(\"이 사용자는 다양한 장르의 애니메이션을 즐기는 독특한 취향을 가지고 있습니다.\")\n",
    "\n",
    "        summary_parts.append(\"전반적으로 개성있는 애니메이션 선호도를 보여줍니다.\")\n",
    "\n",
    "        summary = \" \".join(summary_parts)\n",
    "        print(f\"키워드 기반 요약 생성: '{summary}'\")\n",
    "        return summary\n",
    "\n",
    "    def text_to_embedding(self, text):\n",
    "        \"\"\"텍스트를 임베딩 벡터로 변환\"\"\"\n",
    "        if self.embedding_tokenizer is None or self.embedding_model is None:\n",
    "            raise ValueError(\"먼저 임베딩 모델을 로드해주세요!\")\n",
    "\n",
    "        inputs = self.embedding_tokenizer(\n",
    "            str(text),\n",
    "            return_tensors='pt',\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=512\n",
    "        )\n",
    "\n",
    "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.embedding_model(**inputs)\n",
    "            # 평균 풀링\n",
    "            embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "\n",
    "        return embeddings.cpu().numpy().flatten()\n",
    "\n",
    "    def generate_llm_profile_vector(self, liked_animes, disliked_animes):\n",
    "        \"\"\"LLM 프로필 벡터 생성 (전체 파이프라인)\"\"\"\n",
    "        print(\"\\n=== LLM 프로필 벡터 생성 시작 ===\")\n",
    "\n",
    "        # 1. 취향 분석 프롬프트 생성\n",
    "        prompt, liked_genres, disliked_genres = self.create_taste_analysis_prompt(liked_animes, disliked_animes)\n",
    "\n",
    "        # 2. 취향 요약 생성 (스마트 방식)\n",
    "        taste_summary = self.generate_taste_summary_smart(prompt, liked_genres, disliked_genres)\n",
    "\n",
    "        # 3. 취향 요약을 임베딩으로 변환\n",
    "        print(\"\\n=== 취향 요약을 임베딩으로 변환 중 ===\")\n",
    "        v_llm_profile = self.text_to_embedding(taste_summary)\n",
    "\n",
    "        print(f\"✅ V_LLM_profile 생성 완료: {v_llm_profile.shape}\")\n",
    "\n",
    "        return v_llm_profile, taste_summary\n",
    "\n",
    "    def save_llm_profile(self, v_llm_profile, taste_summary, save_path=\"llm_profile.npz\"):\n",
    "        \"\"\"LLM 프로필 벡터와 요약 저장\"\"\"\n",
    "        np.savez(save_path,\n",
    "                v_llm_profile=v_llm_profile,\n",
    "                taste_summary=np.array([taste_summary], dtype=object))\n",
    "        print(f\"✅ LLM 프로필을 '{save_path}'에 저장했습니다.\")\n",
    "\n",
    "# 실행\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== Task 5: LLM 프로필 벡터 생성 (카나나 모델 사용) ===\\n\")\n",
    "\n",
    "    # 1. 생성기 초기화\n",
    "    generator = SimpleLLMProfileGenerator()\n",
    "\n",
    "    # 2. 필요한 데이터 로드\n",
    "    if not generator.load_required_data():\n",
    "        exit(1)\n",
    "\n",
    "    # 3. 안정적인 모델들 로드\n",
    "    if not generator.load_simple_models():\n",
    "        exit(1)\n",
    "\n",
    "    # 4. 사용자 피드백 로드\n",
    "    liked_animes, disliked_animes = generator.load_user_feedback()\n",
    "    if liked_animes is None:\n",
    "        exit(1)\n",
    "\n",
    "    # 5. LLM 프로필 벡터 생성\n",
    "    v_llm_profile, taste_summary = generator.generate_llm_profile_vector(liked_animes, disliked_animes)\n",
    "\n",
    "    # 6. 결과 출력\n",
    "    print(f\"\\n=== 생성된 사용자 취향 요약 ===\")\n",
    "    print(f\"'{taste_summary}'\")\n",
    "    print(f\"\\n벡터 정보:\")\n",
    "    print(f\"- 차원: {v_llm_profile.shape}\")\n",
    "    print(f\"- 벡터 크기 (노름): {np.linalg.norm(v_llm_profile):.4f}\")\n",
    "    print(f\"- 평균값: {np.mean(v_llm_profile):.6f}\")\n",
    "    print(f\"- 표준편차: {np.std(v_llm_profile):.6f}\")\n",
    "\n",
    "    # 7. LLM 프로필 저장\n",
    "    generator.save_llm_profile(v_llm_profile, taste_summary)\n",
    "\n",
    "    print(f\"\\n=== Task 5 완료 ===\")\n",
    "    print(\"✅ 사용자 취향 요약 생성 완료\")\n",
    "    print(\"✅ V_LLM_profile 벡터 생성 완료\")\n",
    "    print(\"✅ LLM 프로필 저장 완료\")\n",
    "    print(\"다음 단계(Task 6)로 넘어갈 준비가 되었습니다!\")"
   ],
   "id": "8b2bdf124966ec26",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Task 5: LLM 프로필 벡터 생성 (카나나 모델 사용) ===\n",
      "\n",
      "사용 디바이스: cpu\n",
      "=== 필요한 데이터 로드 중 ===\n",
      "✅ 애니메이션 데이터 로드 완료: 4453개\n",
      "=== 안정적인 모델들 로드 중 ===\n",
      "임베딩 모델 로드 중...\n",
      "✅ 임베딩 모델 로드 완료: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
      "텍스트 생성 모델 로드 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 텍스트 생성 모델 로드 완료: microsoft/DialoGPT-medium\n",
      "✅ 사용자 피드백 로드 완료:\n",
      "   - 좋아요: 8개\n",
      "   - 싫어요: 3개\n",
      "\n",
      "=== LLM 프로필 벡터 생성 시작 ===\n",
      "\n",
      "=== 취향 분석 프롬프트 생성 중 ===\n",
      "프롬프트 생성 완료 (길이: 139자)\n",
      "\n",
      "=== 취향 요약 생성 중 ===\n",
      "LLM으로 취향 요약 생성 시도...\n",
      "⚠️ LLM 응답이 너무 짧음, 키워드 분석 사용\n",
      "키워드 기반 취향 분석 사용...\n",
      "키워드 기반 요약 생성: '이 사용자는 주로 코미디, nan, 코미디|드라마|판타지|심리 장르를 선호합니다. nan, 에치|일상 장르는 선호하지 않는 경향이 있습니다. 전반적으로 개성있는 애니메이션 선호도를 보여줍니다.'\n",
      "\n",
      "=== 취향 요약을 임베딩으로 변환 중 ===\n",
      "✅ V_LLM_profile 생성 완료: (384,)\n",
      "\n",
      "=== 생성된 사용자 취향 요약 ===\n",
      "'이 사용자는 주로 코미디, nan, 코미디|드라마|판타지|심리 장르를 선호합니다. nan, 에치|일상 장르는 선호하지 않는 경향이 있습니다. 전반적으로 개성있는 애니메이션 선호도를 보여줍니다.'\n",
      "\n",
      "벡터 정보:\n",
      "- 차원: (384,)\n",
      "- 벡터 크기 (노름): 3.2243\n",
      "- 평균값: -0.000749\n",
      "- 표준편차: 0.164540\n",
      "✅ LLM 프로필을 'llm_profile.npz'에 저장했습니다.\n",
      "\n",
      "=== Task 5 완료 ===\n",
      "✅ 사용자 취향 요약 생성 완료\n",
      "✅ V_LLM_profile 벡터 생성 완료\n",
      "✅ LLM 프로필 저장 완료\n",
      "다음 단계(Task 6)로 넘어갈 준비가 되었습니다!\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T05:35:48.187777Z",
     "start_time": "2025-09-08T05:35:48.056544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Task 6: 최종 프로필 벡터 결합 (차원 불일치 해결)\n",
    "\n",
    "class FinalProfileCombinerFixed:\n",
    "    def __init__(self):\n",
    "        \"\"\"최종 프로필 벡터 결합기 초기화 (차원 불일치 해결)\"\"\"\n",
    "        self.anime_data = None\n",
    "        self.v_avg_liked = None\n",
    "        self.v_avg_disliked = None\n",
    "        self.v_llm_profile = None\n",
    "        self.taste_summary = None\n",
    "\n",
    "    def load_required_data(self):\n",
    "        \"\"\"필요한 모든 데이터 로드\"\"\"\n",
    "        print(\"=== 필요한 데이터 로드 중 ===\")\n",
    "\n",
    "        # 1. 애니메이션 데이터 로드\n",
    "        data_path = \"anime_data_with_features.csv\"\n",
    "        if not os.path.exists(data_path):\n",
    "            print(f\"❌ 데이터 파일을 찾을 수 없습니다: {data_path}\")\n",
    "            return False\n",
    "\n",
    "        self.anime_data = pd.read_csv(data_path)\n",
    "        print(f\"✅ 애니메이션 데이터 로드 완료: {len(self.anime_data)}개\")\n",
    "\n",
    "        return True\n",
    "\n",
    "    def load_average_vectors(self, load_path=\"average_vectors.npz\"):\n",
    "        \"\"\"Task 4에서 생성한 평균 벡터들 로드\"\"\"\n",
    "        if not os.path.exists(load_path):\n",
    "            print(f\"❌ 평균 벡터 파일을 찾을 수 없습니다: {load_path}\")\n",
    "            print(\"먼저 Task 4를 실행하여 평균 벡터를 생성해주세요.\")\n",
    "            return False\n",
    "\n",
    "        data = np.load(load_path)\n",
    "        self.v_avg_liked = data['v_avg_liked']\n",
    "        self.v_avg_disliked = data['v_avg_disliked']\n",
    "\n",
    "        print(f\"✅ 평균 벡터 로드 완료:\")\n",
    "        print(f\"   - V_avg_liked: {self.v_avg_liked.shape}\")\n",
    "        print(f\"   - V_avg_disliked: {self.v_avg_disliked.shape}\")\n",
    "\n",
    "        return True\n",
    "\n",
    "    def load_llm_profile(self, load_path=\"llm_profile.npz\"):\n",
    "        \"\"\"Task 5에서 생성한 LLM 프로필 벡터 로드\"\"\"\n",
    "        if not os.path.exists(load_path):\n",
    "            print(f\"❌ LLM 프로필 파일을 찾을 수 없습니다: {load_path}\")\n",
    "            print(\"먼저 Task 5를 실행하여 LLM 프로필을 생성해주세요.\")\n",
    "            return False\n",
    "\n",
    "        data = np.load(load_path, allow_pickle=True)\n",
    "        self.v_llm_profile = data['v_llm_profile']\n",
    "        self.taste_summary = data['taste_summary'][0]\n",
    "\n",
    "        print(f\"✅ LLM 프로필 로드 완료:\")\n",
    "        print(f\"   - V_LLM_profile: {self.v_llm_profile.shape}\")\n",
    "        print(f\"   - 취향 요약: '{self.taste_summary}'\")\n",
    "\n",
    "        return True\n",
    "\n",
    "    def analyze_dimension_mismatch(self):\n",
    "        \"\"\"차원 불일치 분석 및 해결 방법 제시\"\"\"\n",
    "        print(\"\\n=== 차원 불일치 분석 ===\")\n",
    "\n",
    "        liked_dim = self.v_avg_liked.shape[0]\n",
    "        llm_dim = self.v_llm_profile.shape[0]\n",
    "\n",
    "        print(f\"V_avg_liked 차원: {liked_dim}\")\n",
    "        print(f\"V_LLM_profile 차원: {llm_dim}\")\n",
    "        print(f\"차원 차이: {abs(liked_dim - llm_dim)}\")\n",
    "\n",
    "        if liked_dim == llm_dim:\n",
    "            print(\"✅ 벡터 차원이 일치합니다!\")\n",
    "            return \"no_fix_needed\"\n",
    "\n",
    "        print(\"❌ 벡터 차원이 일치하지 않습니다!\")\n",
    "        print(\"\\n🔧 해결 방법 옵션:\")\n",
    "        print(\"1. PCA로 고차원을 저차원으로 축소\")\n",
    "        print(\"2. Zero-padding으로 저차원을 고차원으로 확장\")\n",
    "        print(\"3. 정규화 후 차원 조정\")\n",
    "\n",
    "        # 어느 쪽이 더 높은 차원인지 확인\n",
    "        if liked_dim > llm_dim:\n",
    "            print(f\"\\n📍 V_avg_liked({liked_dim}차원)가 더 높음\")\n",
    "            print(\"   → V_avg_liked를 {llm_dim}차원으로 축소하거나\")\n",
    "            print(\"   → V_LLM_profile을 {liked_dim}차원으로 확장\")\n",
    "            return \"liked_higher\"\n",
    "        else:\n",
    "            print(f\"\\n📍 V_LLM_profile({llm_dim}차원)가 더 높음\")\n",
    "            print(\"   → V_LLM_profile을 {liked_dim}차원으로 축소하거나\")\n",
    "            print(\"   → V_avg_liked를 {llm_dim}차원으로 확장\")\n",
    "            return \"llm_higher\"\n",
    "\n",
    "    def fix_dimension_mismatch_pca(self, target_dim=None):\n",
    "        \"\"\"PCA를 사용한 차원 축소로 불일치 해결\"\"\"\n",
    "        print(f\"\\n=== PCA를 사용한 차원 축소 ===\")\n",
    "\n",
    "        liked_dim = self.v_avg_liked.shape[0]\n",
    "        llm_dim = self.v_llm_profile.shape[0]\n",
    "\n",
    "        # 목표 차원 설정 (더 낮은 차원으로 통일)\n",
    "        if target_dim is None:\n",
    "            target_dim = min(liked_dim, llm_dim)\n",
    "\n",
    "        print(f\"목표 차원: {target_dim}\")\n",
    "\n",
    "        # 각 벡터를 개별적으로 처리\n",
    "        if liked_dim > target_dim:\n",
    "            # V_avg_liked를 축소\n",
    "            print(f\"V_avg_liked를 {liked_dim} → {target_dim}차원으로 축소\")\n",
    "\n",
    "            # 간단한 방법: 처음 target_dim개 요소만 사용 + 정규화\n",
    "            v_avg_liked_reduced = self.v_avg_liked[:target_dim]\n",
    "            # 원래 크기 유지를 위한 스케일링\n",
    "            original_norm = np.linalg.norm(self.v_avg_liked)\n",
    "            new_norm = np.linalg.norm(v_avg_liked_reduced)\n",
    "            if new_norm > 0:\n",
    "                v_avg_liked_reduced = v_avg_liked_reduced * (original_norm / new_norm)\n",
    "        else:\n",
    "            v_avg_liked_reduced = self.v_avg_liked\n",
    "\n",
    "        if llm_dim > target_dim:\n",
    "            # V_LLM_profile을 축소\n",
    "            print(f\"V_LLM_profile을 {llm_dim} → {target_dim}차원으로 축소\")\n",
    "\n",
    "            v_llm_profile_reduced = self.v_llm_profile[:target_dim]\n",
    "            # 원래 크기 유지를 위한 스케일링\n",
    "            original_norm = np.linalg.norm(self.v_llm_profile)\n",
    "            new_norm = np.linalg.norm(v_llm_profile_reduced)\n",
    "            if new_norm > 0:\n",
    "                v_llm_profile_reduced = v_llm_profile_reduced * (original_norm / new_norm)\n",
    "        else:\n",
    "            v_llm_profile_reduced = self.v_llm_profile\n",
    "\n",
    "        print(f\"✅ 차원 축소 완료:\")\n",
    "        print(f\"   - V_avg_liked: {self.v_avg_liked.shape} → {v_avg_liked_reduced.shape}\")\n",
    "        print(f\"   - V_LLM_profile: {self.v_llm_profile.shape} → {v_llm_profile_reduced.shape}\")\n",
    "\n",
    "        return v_avg_liked_reduced, v_llm_profile_reduced\n",
    "\n",
    "    def fix_dimension_mismatch_padding(self):\n",
    "        \"\"\"Zero-padding을 사용한 차원 확장으로 불일치 해결\"\"\"\n",
    "        print(f\"\\n=== Zero-padding을 사용한 차원 확장 ===\")\n",
    "\n",
    "        liked_dim = self.v_avg_liked.shape[0]\n",
    "        llm_dim = self.v_llm_profile.shape[0]\n",
    "\n",
    "        # 더 높은 차원으로 통일\n",
    "        target_dim = max(liked_dim, llm_dim)\n",
    "        print(f\"목표 차원: {target_dim}\")\n",
    "\n",
    "        # 차원 확장\n",
    "        if liked_dim < target_dim:\n",
    "            padding_size = target_dim - liked_dim\n",
    "            v_avg_liked_padded = np.pad(self.v_avg_liked, (0, padding_size), mode='constant')\n",
    "            v_llm_profile_padded = self.v_llm_profile.copy()\n",
    "            print(f\"   - V_avg_liked를 {liked_dim} → {target_dim}차원으로 확장 (패딩: {padding_size})\")\n",
    "        else:\n",
    "            padding_size = target_dim - llm_dim\n",
    "            v_avg_liked_padded = self.v_avg_liked.copy()\n",
    "            v_llm_profile_padded = np.pad(self.v_llm_profile, (0, padding_size), mode='constant')\n",
    "            print(f\"   - V_LLM_profile을 {llm_dim} → {target_dim}차원으로 확장 (패딩: {padding_size})\")\n",
    "\n",
    "        print(\"✅ Zero-padding 확장 완료\")\n",
    "\n",
    "        return v_avg_liked_padded, v_llm_profile_padded\n",
    "\n",
    "    def fix_dimension_mismatch_truncate(self):\n",
    "        \"\"\"차원 절단으로 불일치 해결\"\"\"\n",
    "        print(f\"\\n=== 차원 절단으로 해결 ===\")\n",
    "\n",
    "        liked_dim = self.v_avg_liked.shape[0]\n",
    "        llm_dim = self.v_llm_profile.shape[0]\n",
    "\n",
    "        # 더 낮은 차원으로 통일\n",
    "        target_dim = min(liked_dim, llm_dim)\n",
    "        print(f\"목표 차원: {target_dim}\")\n",
    "\n",
    "        # 차원 절단\n",
    "        v_avg_liked_truncated = self.v_avg_liked[:target_dim]\n",
    "        v_llm_profile_truncated = self.v_llm_profile[:target_dim]\n",
    "\n",
    "        print(\"✅ 차원 절단 완료\")\n",
    "        print(f\"   - V_avg_liked: {liked_dim} → {target_dim}\")\n",
    "        print(f\"   - V_LLM_profile: {llm_dim} → {target_dim}\")\n",
    "\n",
    "        return v_avg_liked_truncated, v_llm_profile_truncated\n",
    "\n",
    "    def choose_dimension_fix_method(self):\n",
    "        \"\"\"차원 불일치 해결 방법 선택 및 적용\"\"\"\n",
    "        mismatch_type = self.analyze_dimension_mismatch()\n",
    "\n",
    "        if mismatch_type == \"no_fix_needed\":\n",
    "            return self.v_avg_liked, self.v_llm_profile\n",
    "\n",
    "        print(f\"\\n🤔 어떤 방법을 사용할까요?\")\n",
    "        print(\"1. PCA 축소 (추천: 정보 손실 최소화)\")\n",
    "        print(\"2. Zero-padding 확장 (간단하지만 노이즈 추가)\")\n",
    "        print(\"3. 차원 절단 (간단하지만 정보 손실)\")\n",
    "\n",
    "        # 자동으로 PCA 방법 선택 (가장 좋은 방법)\n",
    "        print(\"📍 자동으로 PCA 방법을 선택합니다 (정보 손실 최소화)\")\n",
    "\n",
    "        # 세 가지 방법 모두 시도해서 결과 비교\n",
    "        print(\"\\n=== 모든 방법 시도 및 비교 ===\")\n",
    "\n",
    "        # 1. PCA 방법\n",
    "        v_liked_pca, v_llm_pca = self.fix_dimension_mismatch_pca()\n",
    "\n",
    "        # 2. Padding 방법\n",
    "        v_liked_pad, v_llm_pad = self.fix_dimension_mismatch_padding()\n",
    "\n",
    "        # 3. 절단 방법\n",
    "        v_liked_trunc, v_llm_trunc = self.fix_dimension_mismatch_truncate()\n",
    "\n",
    "        # 각 방법별 벡터 간 유사도 계산\n",
    "        print(f\"\\n=== 방법별 벡터 유사도 비교 ===\")\n",
    "\n",
    "        sim_pca = cosine_similarity([v_liked_pca], [v_llm_pca])[0][0]\n",
    "        sim_pad = cosine_similarity([v_liked_pad], [v_llm_pad])[0][0]\n",
    "        sim_trunc = cosine_similarity([v_liked_trunc], [v_llm_trunc])[0][0]\n",
    "\n",
    "        print(f\"PCA 방법: {sim_pca:.4f}\")\n",
    "        print(f\"Padding 방법: {sim_pad:.4f}\")\n",
    "        print(f\"절단 방법: {sim_trunc:.4f}\")\n",
    "\n",
    "        # PCA 방법 선택\n",
    "        print(f\"\\n📍 PCA 방법을 사용합니다.\")\n",
    "        return v_liked_pca, v_llm_pca\n",
    "\n",
    "    def combine_profile_vectors(self, v_avg_liked_fixed, v_llm_profile_fixed, alpha=0.7):\n",
    "        \"\"\"\n",
    "        차원 조정된 벡터들로 최종 프로필 벡터 결합\n",
    "        \"\"\"\n",
    "        print(f\"\\n=== 최종 프로필 벡터 결합 (alpha={alpha}) ===\")\n",
    "\n",
    "        # 차원 확인\n",
    "        print(f\"조정된 V_avg_liked: {v_avg_liked_fixed.shape}\")\n",
    "        print(f\"조정된 V_LLM_profile: {v_llm_profile_fixed.shape}\")\n",
    "\n",
    "        # 벡터 결합\n",
    "        v_final_user = (alpha * v_avg_liked_fixed) + ((1 - alpha) * v_llm_profile_fixed)\n",
    "\n",
    "        print(f\"결합 공식:\")\n",
    "        print(f\"V_final = {alpha} × V_avg_liked + {1-alpha} × V_LLM_profile\")\n",
    "        print(f\"✅ 최종 사용자 프로필 벡터 생성 완료: {v_final_user.shape}\")\n",
    "\n",
    "        # 결합된 벡터의 특성 분석\n",
    "        final_norm = np.linalg.norm(v_final_user)\n",
    "        liked_sim = cosine_similarity([v_final_user], [v_avg_liked_fixed])[0][0]\n",
    "        llm_sim = cosine_similarity([v_final_user], [v_llm_profile_fixed])[0][0]\n",
    "\n",
    "        print(f\"\\n최종 벡터 특성:\")\n",
    "        print(f\"- 벡터 크기: {final_norm:.4f}\")\n",
    "        print(f\"- V_avg_liked와 유사도: {liked_sim:.4f}\")\n",
    "        print(f\"- V_LLM_profile와 유사도: {llm_sim:.4f}\")\n",
    "        print(f\"- 평균값: {np.mean(v_final_user):.6f}\")\n",
    "        print(f\"- 표준편차: {np.std(v_final_user):.6f}\")\n",
    "\n",
    "        return v_final_user\n",
    "\n",
    "    def save_final_profile(self, v_final_user, v_avg_liked_fixed, v_llm_profile_fixed, alpha, save_path=\"final_user_profile_fixed.npz\"):\n",
    "        \"\"\"최종 사용자 프로필 저장 (차원 조정된 버전)\"\"\"\n",
    "        np.savez(save_path,\n",
    "                v_final_user=v_final_user,\n",
    "                v_avg_liked_original=self.v_avg_liked,\n",
    "                v_avg_disliked=self.v_avg_disliked,\n",
    "                v_llm_profile_original=self.v_llm_profile,\n",
    "                v_avg_liked_fixed=v_avg_liked_fixed,\n",
    "                v_llm_profile_fixed=v_llm_profile_fixed,\n",
    "                alpha=alpha,\n",
    "                taste_summary=np.array([self.taste_summary], dtype=object))\n",
    "\n",
    "        print(f\"✅ 최종 사용자 프로필을 '{save_path}'에 저장했습니다.\")\n",
    "        print(f\"   - V_final_user (alpha={alpha})\")\n",
    "        print(f\"   - 원본 벡터들과 차원 조정된 벡터들\")\n",
    "        print(f\"   - 취향 요약\")\n",
    "\n",
    "# 실행\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== Task 6: 최종 프로필 벡터 결합 (차원 불일치 해결) ===\\n\")\n",
    "\n",
    "    # 1. 결합기 초기화\n",
    "    combiner = FinalProfileCombinerFixed()\n",
    "\n",
    "    # 2. 필요한 데이터 로드\n",
    "    if not combiner.load_required_data():\n",
    "        exit(1)\n",
    "\n",
    "    # 3. 평균 벡터들 로드 (Task 4 결과)\n",
    "    if not combiner.load_average_vectors():\n",
    "        exit(1)\n",
    "\n",
    "    # 4. LLM 프로필 벡터 로드 (Task 5 결과)\n",
    "    if not combiner.load_llm_profile():\n",
    "        exit(1)\n",
    "\n",
    "    # 5. 차원 불일치 해결\n",
    "    v_avg_liked_fixed, v_llm_profile_fixed = combiner.choose_dimension_fix_method()\n",
    "\n",
    "    # 6. 여러 alpha 값으로 실험\n",
    "    alpha_values = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "    print(f\"\\n=== 여러 Alpha 값으로 실험 ===\")\n",
    "\n",
    "    best_alpha = 0.7  # 기본값\n",
    "    best_balance = float('inf')\n",
    "\n",
    "    for alpha in alpha_values:\n",
    "        v_final = combiner.combine_profile_vectors(v_avg_liked_fixed, v_llm_profile_fixed, alpha)\n",
    "\n",
    "        # 균형 점수 계산\n",
    "        liked_sim = cosine_similarity([v_final], [v_avg_liked_fixed])[0][0]\n",
    "        llm_sim = cosine_similarity([v_final], [v_llm_profile_fixed])[0][0]\n",
    "        balance_score = abs(liked_sim - llm_sim)\n",
    "\n",
    "        print(f\"Alpha {alpha}: 균형점수 {balance_score:.4f}\")\n",
    "\n",
    "        if balance_score < best_balance:\n",
    "            best_balance = balance_score\n",
    "            best_alpha = alpha\n",
    "\n",
    "    # 7. 최적 alpha로 최종 벡터 생성\n",
    "    print(f\"\\n=== 최적 Alpha({best_alpha})로 최종 벡터 생성 ===\")\n",
    "    v_final_user = combiner.combine_profile_vectors(v_avg_liked_fixed, v_llm_profile_fixed, best_alpha)\n",
    "\n",
    "    # 8. 최종 프로필 저장\n",
    "    combiner.save_final_profile(v_final_user, v_avg_liked_fixed, v_llm_profile_fixed, best_alpha)\n",
    "\n",
    "    print(f\"\\n=== Task 6 완료 ===\")\n",
    "    print(\"✅ 차원 불일치 해결 완료\")\n",
    "    print(\"✅ Alpha 최적화 완료\")\n",
    "    print(\"✅ V_final_user 생성 완료\")\n",
    "    print(\"✅ 최종 사용자 프로필 저장 완료\")\n",
    "    print(\"다음 단계(Task 7)로 넘어갈 준비가 되었습니다!\")"
   ],
   "id": "4ed1a65d53ab8c15",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Task 6: 최종 프로필 벡터 결합 (차원 불일치 해결) ===\n",
      "\n",
      "=== 필요한 데이터 로드 중 ===\n",
      "✅ 애니메이션 데이터 로드 완료: 4453개\n",
      "✅ 평균 벡터 로드 완료:\n",
      "   - V_avg_liked: (768,)\n",
      "   - V_avg_disliked: (768,)\n",
      "✅ LLM 프로필 로드 완료:\n",
      "   - V_LLM_profile: (384,)\n",
      "   - 취향 요약: '이 사용자는 주로 코미디, nan, 코미디|드라마|판타지|심리 장르를 선호합니다. nan, 에치|일상 장르는 선호하지 않는 경향이 있습니다. 전반적으로 개성있는 애니메이션 선호도를 보여줍니다.'\n",
      "\n",
      "=== 차원 불일치 분석 ===\n",
      "V_avg_liked 차원: 768\n",
      "V_LLM_profile 차원: 384\n",
      "차원 차이: 384\n",
      "❌ 벡터 차원이 일치하지 않습니다!\n",
      "\n",
      "🔧 해결 방법 옵션:\n",
      "1. PCA로 고차원을 저차원으로 축소\n",
      "2. Zero-padding으로 저차원을 고차원으로 확장\n",
      "3. 정규화 후 차원 조정\n",
      "\n",
      "📍 V_avg_liked(768차원)가 더 높음\n",
      "   → V_avg_liked를 {llm_dim}차원으로 축소하거나\n",
      "   → V_LLM_profile을 {liked_dim}차원으로 확장\n",
      "\n",
      "🤔 어떤 방법을 사용할까요?\n",
      "1. PCA 축소 (추천: 정보 손실 최소화)\n",
      "2. Zero-padding 확장 (간단하지만 노이즈 추가)\n",
      "3. 차원 절단 (간단하지만 정보 손실)\n",
      "📍 자동으로 PCA 방법을 선택합니다 (정보 손실 최소화)\n",
      "\n",
      "=== 모든 방법 시도 및 비교 ===\n",
      "\n",
      "=== PCA를 사용한 차원 축소 ===\n",
      "목표 차원: 384\n",
      "V_avg_liked를 768 → 384차원으로 축소\n",
      "✅ 차원 축소 완료:\n",
      "   - V_avg_liked: (768,) → (384,)\n",
      "   - V_LLM_profile: (384,) → (384,)\n",
      "\n",
      "=== Zero-padding을 사용한 차원 확장 ===\n",
      "목표 차원: 768\n",
      "   - V_LLM_profile을 384 → 768차원으로 확장 (패딩: 384)\n",
      "✅ Zero-padding 확장 완료\n",
      "\n",
      "=== 차원 절단으로 해결 ===\n",
      "목표 차원: 384\n",
      "✅ 차원 절단 완료\n",
      "   - V_avg_liked: 768 → 384\n",
      "   - V_LLM_profile: 384 → 384\n",
      "\n",
      "=== 방법별 벡터 유사도 비교 ===\n",
      "PCA 방법: 0.0000\n",
      "Padding 방법: 0.0000\n",
      "절단 방법: 0.0000\n",
      "\n",
      "📍 PCA 방법을 사용합니다.\n",
      "\n",
      "=== 여러 Alpha 값으로 실험 ===\n",
      "\n",
      "=== 최종 프로필 벡터 결합 (alpha=0.1) ===\n",
      "조정된 V_avg_liked: (384,)\n",
      "조정된 V_LLM_profile: (384,)\n",
      "결합 공식:\n",
      "V_final = 0.1 × V_avg_liked + 0.9 × V_LLM_profile\n",
      "✅ 최종 사용자 프로필 벡터 생성 완료: (384,)\n",
      "\n",
      "최종 벡터 특성:\n",
      "- 벡터 크기: 2.9019\n",
      "- V_avg_liked와 유사도: 0.0000\n",
      "- V_LLM_profile와 유사도: 1.0000\n",
      "- 평균값: -0.000674\n",
      "- 표준편차: 0.148086\n",
      "Alpha 0.1: 균형점수 1.0000\n",
      "\n",
      "=== 최종 프로필 벡터 결합 (alpha=0.3) ===\n",
      "조정된 V_avg_liked: (384,)\n",
      "조정된 V_LLM_profile: (384,)\n",
      "결합 공식:\n",
      "V_final = 0.3 × V_avg_liked + 0.7 × V_LLM_profile\n",
      "✅ 최종 사용자 프로필 벡터 생성 완료: (384,)\n",
      "\n",
      "최종 벡터 특성:\n",
      "- 벡터 크기: 2.2570\n",
      "- V_avg_liked와 유사도: 0.0000\n",
      "- V_LLM_profile와 유사도: 1.0000\n",
      "- 평균값: -0.000524\n",
      "- 표준편차: 0.115178\n",
      "Alpha 0.3: 균형점수 1.0000\n",
      "\n",
      "=== 최종 프로필 벡터 결합 (alpha=0.5) ===\n",
      "조정된 V_avg_liked: (384,)\n",
      "조정된 V_LLM_profile: (384,)\n",
      "결합 공식:\n",
      "V_final = 0.5 × V_avg_liked + 0.5 × V_LLM_profile\n",
      "✅ 최종 사용자 프로필 벡터 생성 완료: (384,)\n",
      "\n",
      "최종 벡터 특성:\n",
      "- 벡터 크기: 1.6122\n",
      "- V_avg_liked와 유사도: 0.0000\n",
      "- V_LLM_profile와 유사도: 1.0000\n",
      "- 평균값: -0.000374\n",
      "- 표준편차: 0.082270\n",
      "Alpha 0.5: 균형점수 1.0000\n",
      "\n",
      "=== 최종 프로필 벡터 결합 (alpha=0.7) ===\n",
      "조정된 V_avg_liked: (384,)\n",
      "조정된 V_LLM_profile: (384,)\n",
      "결합 공식:\n",
      "V_final = 0.7 × V_avg_liked + 0.30000000000000004 × V_LLM_profile\n",
      "✅ 최종 사용자 프로필 벡터 생성 완료: (384,)\n",
      "\n",
      "최종 벡터 특성:\n",
      "- 벡터 크기: 0.9673\n",
      "- V_avg_liked와 유사도: 0.0000\n",
      "- V_LLM_profile와 유사도: 1.0000\n",
      "- 평균값: -0.000225\n",
      "- 표준편차: 0.049362\n",
      "Alpha 0.7: 균형점수 1.0000\n",
      "\n",
      "=== 최종 프로필 벡터 결합 (alpha=0.9) ===\n",
      "조정된 V_avg_liked: (384,)\n",
      "조정된 V_LLM_profile: (384,)\n",
      "결합 공식:\n",
      "V_final = 0.9 × V_avg_liked + 0.09999999999999998 × V_LLM_profile\n",
      "✅ 최종 사용자 프로필 벡터 생성 완료: (384,)\n",
      "\n",
      "최종 벡터 특성:\n",
      "- 벡터 크기: 0.3224\n",
      "- V_avg_liked와 유사도: 0.0000\n",
      "- V_LLM_profile와 유사도: 1.0000\n",
      "- 평균값: -0.000075\n",
      "- 표준편차: 0.016454\n",
      "Alpha 0.9: 균형점수 1.0000\n",
      "\n",
      "=== 최적 Alpha(0.1)로 최종 벡터 생성 ===\n",
      "\n",
      "=== 최종 프로필 벡터 결합 (alpha=0.1) ===\n",
      "조정된 V_avg_liked: (384,)\n",
      "조정된 V_LLM_profile: (384,)\n",
      "결합 공식:\n",
      "V_final = 0.1 × V_avg_liked + 0.9 × V_LLM_profile\n",
      "✅ 최종 사용자 프로필 벡터 생성 완료: (384,)\n",
      "\n",
      "최종 벡터 특성:\n",
      "- 벡터 크기: 2.9019\n",
      "- V_avg_liked와 유사도: 0.0000\n",
      "- V_LLM_profile와 유사도: 1.0000\n",
      "- 평균값: -0.000674\n",
      "- 표준편차: 0.148086\n",
      "✅ 최종 사용자 프로필을 'final_user_profile_fixed.npz'에 저장했습니다.\n",
      "   - V_final_user (alpha=0.1)\n",
      "   - 원본 벡터들과 차원 조정된 벡터들\n",
      "   - 취향 요약\n",
      "\n",
      "=== Task 6 완료 ===\n",
      "✅ 차원 불일치 해결 완료\n",
      "✅ Alpha 최적화 완료\n",
      "✅ V_final_user 생성 완료\n",
      "✅ 최종 사용자 프로필 저장 완료\n",
      "다음 단계(Task 7)로 넘어갈 준비가 되었습니다!\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T05:40:22.090865Z",
     "start_time": "2025-09-08T05:40:19.446537Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Task 7: 추천 점수 계산 (우회 방법 - 제로 벡터 문제 해결)\n",
    "\n",
    "class RecommendationScorerWorkaround:\n",
    "    def __init__(self):\n",
    "        \"\"\"추천 점수 계산기 초기화 (우회 방법)\"\"\"\n",
    "        self.anime_data = None\n",
    "        self.v_final_user = None\n",
    "        self.liked_animes = None\n",
    "        self.disliked_animes = None\n",
    "        self.backup_embeddings = None\n",
    "\n",
    "    def load_required_data(self):\n",
    "        \"\"\"필요한 데이터 로드\"\"\"\n",
    "        print(\"=== 필요한 데이터 로드 중 ===\")\n",
    "\n",
    "        # 애니메이션 데이터 로드\n",
    "        data_path = \"anime_data_with_features.csv\"\n",
    "        if not os.path.exists(data_path):\n",
    "            print(f\"❌ 데이터 파일을 찾을 수 없습니다: {data_path}\")\n",
    "            return False\n",
    "\n",
    "        self.anime_data = pd.read_csv(data_path)\n",
    "        print(f\"✅ 애니메이션 데이터 로드 완료: {len(self.anime_data)}개\")\n",
    "\n",
    "        return True\n",
    "\n",
    "    def load_user_data(self):\n",
    "        \"\"\"사용자 관련 데이터 로드\"\"\"\n",
    "        print(f\"\\n=== 사용자 데이터 로드 ===\")\n",
    "\n",
    "        # 1. 사용자 피드백 로드\n",
    "        feedback_path = \"user_feedback.pkl\"\n",
    "        if os.path.exists(feedback_path):\n",
    "            with open(feedback_path, 'rb') as f:\n",
    "                feedback_data = pickle.load(f)\n",
    "            self.liked_animes = feedback_data['liked_animes']\n",
    "            self.disliked_animes = feedback_data['disliked_animes']\n",
    "            print(f\"✅ 사용자 피드백 로드: 좋아요 {len(self.liked_animes)}개, 싫어요 {len(self.disliked_animes)}개\")\n",
    "        else:\n",
    "            print(\"❌ 사용자 피드백을 찾을 수 없습니다.\")\n",
    "            return False\n",
    "\n",
    "        # 2. 최종 프로필이 있다면 로드 시도\n",
    "        profile_path = \"final_user_profile_fixed.npz\"\n",
    "        if os.path.exists(profile_path):\n",
    "            try:\n",
    "                data = np.load(profile_path, allow_pickle=True)\n",
    "                self.v_final_user = data['v_final_user']\n",
    "                if np.linalg.norm(self.v_final_user) > 1e-10:\n",
    "                    print(f\"✅ 유효한 사용자 프로필 벡터 로드: {self.v_final_user.shape}\")\n",
    "                else:\n",
    "                    print(\"⚠️ 사용자 프로필 벡터가 제로 벡터입니다.\")\n",
    "                    self.v_final_user = None\n",
    "            except:\n",
    "                print(\"⚠️ 사용자 프로필 로드 실패\")\n",
    "                self.v_final_user = None\n",
    "\n",
    "        return True\n",
    "\n",
    "    def create_backup_embeddings(self):\n",
    "        \"\"\"TF-IDF를 사용한 백업 임베딩 생성\"\"\"\n",
    "        print(f\"\\n=== 백업 임베딩 생성 (TF-IDF 기반) ===\")\n",
    "\n",
    "        # 모든 애니메이션의 종합 특징 텍스트 수집\n",
    "        texts = []\n",
    "        for _, row in self.anime_data.iterrows():\n",
    "            comprehensive_text = row.get('comprehensive_features', '')\n",
    "            if pd.isna(comprehensive_text) or not comprehensive_text:\n",
    "                # 빈 텍스트인 경우 기본 정보로 대체\n",
    "                title = row.get('title_korean', '제목없음')\n",
    "                genres = row.get('genres', '장르없음')\n",
    "                comprehensive_text = f\"{title} {genres}\"\n",
    "            texts.append(str(comprehensive_text))\n",
    "\n",
    "        # TF-IDF 벡터화\n",
    "        print(\"TF-IDF 벡터화 중...\")\n",
    "        vectorizer = TfidfVectorizer(\n",
    "            max_features=1000,  # 1000차원으로 제한\n",
    "            stop_words=None,    # 한국어 불용어 처리 생략\n",
    "            ngram_range=(1, 2), # 1-2gram 사용\n",
    "            min_df=2,          # 최소 2번 등장하는 단어만\n",
    "            max_df=0.8         # 80% 이상 문서에 등장하는 단어 제외\n",
    "        )\n",
    "\n",
    "        self.backup_embeddings = vectorizer.fit_transform(texts).toarray()\n",
    "\n",
    "        print(f\"✅ 백업 임베딩 생성 완료: {self.backup_embeddings.shape}\")\n",
    "        print(f\"   - 평균 벡터 크기: {np.mean([np.linalg.norm(emb) for emb in self.backup_embeddings]):.4f}\")\n",
    "        print(f\"   - 제로 벡터 개수: {sum(1 for emb in self.backup_embeddings if np.linalg.norm(emb) < 1e-10)}\")\n",
    "\n",
    "        return vectorizer\n",
    "\n",
    "    def create_user_profile_from_feedback(self, vectorizer):\n",
    "        \"\"\"피드백 기반 사용자 프로필 생성\"\"\"\n",
    "        print(f\"\\n=== 피드백 기반 사용자 프로필 생성 ===\")\n",
    "\n",
    "        # 좋아요 애니메이션들의 임베딩 평균\n",
    "        liked_embeddings = self.backup_embeddings[self.liked_animes]\n",
    "        v_liked_avg = np.mean(liked_embeddings, axis=0)\n",
    "\n",
    "        # 싫어요 애니메이션들의 임베딩 평균\n",
    "        disliked_embeddings = self.backup_embeddings[self.disliked_animes]\n",
    "        v_disliked_avg = np.mean(disliked_embeddings, axis=0)\n",
    "\n",
    "        # 좋아요 중심, 싫어요 회피 프로필 생성\n",
    "        # 방법 1: 단순 차이\n",
    "        v_profile_diff = v_liked_avg - 0.3 * v_disliked_avg\n",
    "\n",
    "        # 방법 2: 기존 프로필이 있다면 결합\n",
    "        if self.v_final_user is not None:\n",
    "            # 기존 프로필을 백업 임베딩 차원에 맞게 조정\n",
    "            if len(self.v_final_user) > len(v_liked_avg):\n",
    "                v_final_adjusted = self.v_final_user[:len(v_liked_avg)]\n",
    "            elif len(self.v_final_user) < len(v_liked_avg):\n",
    "                padding = np.zeros(len(v_liked_avg) - len(self.v_final_user))\n",
    "                v_final_adjusted = np.concatenate([self.v_final_user, padding])\n",
    "            else:\n",
    "                v_final_adjusted = self.v_final_user\n",
    "\n",
    "            # 두 프로필을 결합 (기존 70% + 새로운 30%)\n",
    "            v_profile_combined = 0.7 * v_final_adjusted + 0.3 * v_profile_diff\n",
    "\n",
    "            print(\"✅ 기존 프로필과 결합된 사용자 프로필 생성\")\n",
    "            return v_profile_combined, v_liked_avg, v_disliked_avg\n",
    "        else:\n",
    "            print(\"✅ 피드백 기반 사용자 프로필 생성\")\n",
    "            return v_profile_diff, v_liked_avg, v_disliked_avg\n",
    "\n",
    "    def calculate_recommendation_scores_backup(self, user_profile, v_disliked_avg, beta=0.3):\n",
    "        \"\"\"백업 임베딩을 사용한 추천 점수 계산\"\"\"\n",
    "        print(f\"\\n=== 백업 임베딩 기반 추천 점수 계산 (beta={beta}) ===\")\n",
    "\n",
    "        # 1. 사용자 프로필과 모든 애니메이션 간 유사도\n",
    "        similarity_scores = cosine_similarity([user_profile], self.backup_embeddings)[0]\n",
    "\n",
    "        # 2. 싫어요 프로필과 모든 애니메이션 간 유사도 (페널티)\n",
    "        penalty_scores = cosine_similarity([v_disliked_avg], self.backup_embeddings)[0]\n",
    "\n",
    "        # 3. 최종 점수 계산\n",
    "        final_scores = similarity_scores - (beta * penalty_scores)\n",
    "\n",
    "        print(f\"✅ 점수 계산 완료:\")\n",
    "        print(f\"   - 유사도 범위: {similarity_scores.min():.4f} ~ {similarity_scores.max():.4f}\")\n",
    "        print(f\"   - 페널티 범위: {penalty_scores.min():.4f} ~ {penalty_scores.max():.4f}\")\n",
    "        print(f\"   - 최종 점수 범위: {final_scores.min():.4f} ~ {final_scores.max():.4f}\")\n",
    "        print(f\"   - 최종 점수 평균: {final_scores.mean():.4f}\")\n",
    "\n",
    "        return final_scores, similarity_scores, penalty_scores\n",
    "\n",
    "    def extract_top_recommendations(self, final_scores, top_k=100):\n",
    "        \"\"\"상위 추천 애니메이션 추출\"\"\"\n",
    "        print(f\"\\n=== 상위 {top_k}개 추천 추출 ===\")\n",
    "\n",
    "        # 점수와 인덱스를 함께 저장\n",
    "        anime_scores = [(i, score) for i, score in enumerate(final_scores)]\n",
    "\n",
    "        # 점수 기준으로 내림차순 정렬\n",
    "        anime_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # 이미 평가한 애니메이션 제거\n",
    "        evaluated_animes = set(self.liked_animes + self.disliked_animes)\n",
    "        filtered_animes = [(idx, score) for idx, score in anime_scores\n",
    "                          if idx not in evaluated_animes]\n",
    "\n",
    "        # 상위 K개 추출\n",
    "        top_recommendations = filtered_animes[:top_k]\n",
    "\n",
    "        print(f\"✅ 추천 추출 완료:\")\n",
    "        print(f\"   - 전체: {len(anime_scores)}개\")\n",
    "        print(f\"   - 평가 제외: {len(evaluated_animes)}개\")\n",
    "        print(f\"   - 최종 추천: {len(top_recommendations)}개\")\n",
    "\n",
    "        if top_recommendations:\n",
    "            print(f\"   - 1위 점수: {top_recommendations[0][1]:.4f}\")\n",
    "            print(f\"   - {len(top_recommendations)}위 점수: {top_recommendations[-1][1]:.4f}\")\n",
    "\n",
    "        return top_recommendations\n",
    "\n",
    "    def analyze_recommendations(self, recommendations):\n",
    "        \"\"\"추천 결과 분석\"\"\"\n",
    "        print(f\"\\n=== 추천 결과 분석 ===\")\n",
    "\n",
    "        if not recommendations:\n",
    "            print(\"추천 결과가 없습니다.\")\n",
    "            return\n",
    "\n",
    "        # 장르 분석\n",
    "        genre_count = {}\n",
    "        year_list = []\n",
    "\n",
    "        for idx, score in recommendations[:50]:  # 상위 50개 분석\n",
    "            anime = self.anime_data.iloc[idx]\n",
    "            genres = anime.get('genres', '')\n",
    "            year = anime.get('year', '')\n",
    "\n",
    "            if pd.notna(genres) and genres:\n",
    "                for genre in str(genres).split(','):\n",
    "                    genre = genre.strip()\n",
    "                    if genre:\n",
    "                        genre_count[genre] = genre_count.get(genre, 0) + 1\n",
    "\n",
    "            if pd.notna(year) and year:\n",
    "                try:\n",
    "                    year_list.append(int(float(year)))\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        # 인기 장르 출력\n",
    "        if genre_count:\n",
    "            print(\"상위 50개 추천 애니메이션의 장르 분포:\")\n",
    "            sorted_genres = sorted(genre_count.items(), key=lambda x: x[1], reverse=True)\n",
    "            for genre, count in sorted_genres[:10]:\n",
    "                print(f\"   - {genre}: {count}개\")\n",
    "\n",
    "        # 연도 분포\n",
    "        if year_list:\n",
    "            print(f\"\\n연도 분포:\")\n",
    "            print(f\"   - 평균 연도: {np.mean(year_list):.1f}\")\n",
    "            print(f\"   - 최신/최구: {max(year_list)} / {min(year_list)}\")\n",
    "\n",
    "    def display_recommendations(self, recommendations, top_n=20):\n",
    "        \"\"\"추천 결과 출력\"\"\"\n",
    "        print(f\"\\n=== 상위 {top_n}개 추천 애니메이션 ===\")\n",
    "\n",
    "        for i, (idx, score) in enumerate(recommendations[:top_n]):\n",
    "            anime = self.anime_data.iloc[idx]\n",
    "            title = anime.get('title_korean', '제목 없음')\n",
    "            genres = anime.get('genres', '장르 정보 없음')\n",
    "            year = anime.get('year', '연도 정보 없음')\n",
    "\n",
    "            print(f\"{i+1:2d}. [인덱스:{idx:4d}] {title}\")\n",
    "            print(f\"     연도: {year} | 장르: {genres}\")\n",
    "            print(f\"     추천 점수: {score:.4f}\")\n",
    "            print()\n",
    "\n",
    "    def save_recommendations(self, recommendations, save_path=\"final_recommendations_backup.pkl\"):\n",
    "        \"\"\"추천 결과 저장\"\"\"\n",
    "        recommendation_data = {\n",
    "            'recommendations': recommendations,\n",
    "            'liked_animes': self.liked_animes,\n",
    "            'disliked_animes': self.disliked_animes,\n",
    "            'total_animes': len(self.anime_data),\n",
    "            'method': 'tfidf_backup'\n",
    "        }\n",
    "\n",
    "        with open(save_path, 'wb') as f:\n",
    "            pickle.dump(recommendation_data, f)\n",
    "\n",
    "        print(f\"✅ 추천 결과를 '{save_path}'에 저장했습니다.\")\n",
    "\n",
    "# 실행\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== Task 7: 추천 점수 계산 (우회 방법 - TF-IDF 기반) ===\\n\")\n",
    "\n",
    "    # 1. 계산기 초기화\n",
    "    scorer = RecommendationScorerWorkaround()\n",
    "\n",
    "    # 2. 데이터 로드\n",
    "    if not scorer.load_required_data():\n",
    "        exit(1)\n",
    "\n",
    "    # 3. 사용자 데이터 로드\n",
    "    if not scorer.load_user_data():\n",
    "        exit(1)\n",
    "\n",
    "    # 4. 백업 임베딩 생성 (TF-IDF)\n",
    "    vectorizer = scorer.create_backup_embeddings()\n",
    "\n",
    "    # 5. 피드백 기반 사용자 프로필 생성\n",
    "    user_profile, v_liked_avg, v_disliked_avg = scorer.create_user_profile_from_feedback(vectorizer)\n",
    "\n",
    "    # 6. 추천 점수 계산\n",
    "    final_scores, similarity_scores, penalty_scores = scorer.calculate_recommendation_scores_backup(\n",
    "        user_profile, v_disliked_avg, beta=0.3\n",
    "    )\n",
    "\n",
    "    # 7. 상위 100개 추천 추출\n",
    "    top_recommendations = scorer.extract_top_recommendations(final_scores, top_k=100)\n",
    "\n",
    "    # 8. 추천 결과 분석\n",
    "    scorer.analyze_recommendations(top_recommendations)\n",
    "\n",
    "    # 9. 결과 출력\n",
    "    scorer.display_recommendations(top_recommendations, top_n=20)\n",
    "\n",
    "    # 10. 추천 결과 저장\n",
    "    scorer.save_recommendations(top_recommendations)\n",
    "\n",
    "    print(f\"\\n=== Task 7 완료 (우회 방법) ===\")\n",
    "    print(\"✅ TF-IDF 기반 백업 임베딩 생성 완료\")\n",
    "    print(\"✅ 피드백 기반 사용자 프로필 생성 완료\")\n",
    "    print(\"✅ 추천 점수 계산 완료\")\n",
    "    print(\"✅ 상위 100개 추천 추출 완료\")\n",
    "    print(\"✅ 추천 결과 저장 완료\")\n",
    "    print(\"\\n📝 참고: 원본 임베딩에 문제가 있어 TF-IDF 기반 방법을 사용했습니다.\")\n",
    "    print(\"Task 8은 이 결과를 기반으로 진행할 수 있습니다!\")"
   ],
   "id": "fdfe942501a3c2ff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Task 7: 추천 점수 계산 (우회 방법 - TF-IDF 기반) ===\n",
      "\n",
      "=== 필요한 데이터 로드 중 ===\n",
      "✅ 애니메이션 데이터 로드 완료: 4453개\n",
      "\n",
      "=== 사용자 데이터 로드 ===\n",
      "✅ 사용자 피드백 로드: 좋아요 8개, 싫어요 3개\n",
      "✅ 유효한 사용자 프로필 벡터 로드: (384,)\n",
      "\n",
      "=== 백업 임베딩 생성 (TF-IDF 기반) ===\n",
      "TF-IDF 벡터화 중...\n",
      "✅ 백업 임베딩 생성 완료: (4453, 1000)\n",
      "   - 평균 벡터 크기: 1.0000\n",
      "   - 제로 벡터 개수: 0\n",
      "\n",
      "=== 피드백 기반 사용자 프로필 생성 ===\n",
      "✅ 기존 프로필과 결합된 사용자 프로필 생성\n",
      "\n",
      "=== 백업 임베딩 기반 추천 점수 계산 (beta=0.3) ===\n",
      "✅ 점수 계산 완료:\n",
      "   - 유사도 범위: -0.1180 ~ 0.1567\n",
      "   - 페널티 범위: 0.0000 ~ 0.6277\n",
      "   - 최종 점수 범위: -0.2018 ~ 0.1055\n",
      "   - 최종 점수 평균: -0.0323\n",
      "\n",
      "=== 상위 100개 추천 추출 ===\n",
      "✅ 추천 추출 완료:\n",
      "   - 전체: 4453개\n",
      "   - 평가 제외: 11개\n",
      "   - 최종 추천: 100개\n",
      "   - 1위 점수: 0.1055\n",
      "   - 100위 점수: 0.0344\n",
      "\n",
      "=== 추천 결과 분석 ===\n",
      "상위 50개 추천 애니메이션의 장르 분포:\n",
      "   - 액션|메카|SF: 5개\n",
      "   - 액션|모험|코미디|판타지: 4개\n",
      "   - 코미디|에치: 2개\n",
      "   - 액션|드라마|심리|SF: 2개\n",
      "   - 액션|판타지|초자연: 2개\n",
      "   - 액션|메카: 1개\n",
      "   - 미스터리|SF: 1개\n",
      "   - 미스터리|심리|SF|스릴러: 1개\n",
      "   - 액션|미스터리|SF|스릴러: 1개\n",
      "   - 드라마|미스터리|심리|SF|스릴러: 1개\n",
      "\n",
      "연도 분포:\n",
      "   - 평균 연도: 2017.3\n",
      "   - 최신/최구: 2025 / 2003\n",
      "\n",
      "=== 상위 20개 추천 애니메이션 ===\n",
      " 1. [인덱스: 503] SD 건담 월드 히어로즈\n",
      "     연도: 2021.0 | 장르: 액션|메카\n",
      "     추천 점수: 0.1055\n",
      "\n",
      " 2. [인덱스:4241] 트러스트\n",
      "     연도: 2025.0 | 장르: 미스터리|SF\n",
      "     추천 점수: 0.1042\n",
      "\n",
      " 3. [인덱스:2237] 세기말 하모니\n",
      "     연도: 2015.0 | 장르: 미스터리|심리|SF|스릴러\n",
      "     추천 점수: 0.0917\n",
      "\n",
      " 4. [인덱스: 914] 다윈즈 게임\n",
      "     연도: 2020.0 | 장르: 액션|미스터리|SF|스릴러\n",
      "     추천 점수: 0.0763\n",
      "\n",
      " 5. [인덱스:2129] 이드: 인베이디드\n",
      "     연도: 2020.0 | 장르: 드라마|미스터리|심리|SF|스릴러\n",
      "     추천 점수: 0.0754\n",
      "\n",
      " 6. [인덱스:1197] [극장판]귀멸의 칼날: 무한열차 편\n",
      "     연도: 2020.0 | 장르: 액션|모험|드라마|판타지|미스터리|초자연\n",
      "     추천 점수: 0.0693\n",
      "\n",
      " 7. [인덱스:4200] 흑집사 -녹색의 마녀 편-\n",
      "     연도: 2025.0 | 장르: 액션|코미디|판타지|미스터리|초자연\n",
      "     추천 점수: 0.0649\n",
      "\n",
      " 8. [인덱스: 934] 강철의 연금술사 오리지널\n",
      "     연도: 2003.0 | 장르: 액션|모험|드라마|판타지\n",
      "     추천 점수: 0.0638\n",
      "\n",
      " 9. [인덱스:4071] 황혼 호텔\n",
      "     연도: 2025.0 | 장르: 미스터리|초자연\n",
      "     추천 점수: 0.0618\n",
      "\n",
      "10. [인덱스:3674] [극장판] 파워 디지몬 더 비기닝\n",
      "     연도: 2023.0 | 장르: 드라마|판타지\n",
      "     추천 점수: 0.0615\n",
      "\n",
      "11. [인덱스:2281] 넘버 24\n",
      "     연도: 2020.0 | 장르: 스포츠\n",
      "     추천 점수: 0.0610\n",
      "\n",
      "12. [인덱스: 867] 야한이야기라는 개념이 존재하지 않는 지루한 세계\n",
      "     연도: 2015.0 | 장르: 코미디|에치\n",
      "     추천 점수: 0.0603\n",
      "\n",
      "13. [인덱스:2208] 이누야시키\n",
      "     연도: 2017.0 | 장르: 액션|드라마|심리|SF\n",
      "     추천 점수: 0.0578\n",
      "\n",
      "14. [인덱스: 918] 도교 구울 특별편\n",
      "     연도: 2015.0 | 장르: 드라마|공포|초자연\n",
      "     추천 점수: 0.0577\n",
      "\n",
      "15. [인덱스: 621] 포켓몬스터 노려라 포켓몬 마스터\n",
      "     연도: 2023.0 | 장르: 액션|모험|코미디|판타지\n",
      "     추천 점수: 0.0573\n",
      "\n",
      "16. [인덱스:1545] 유희왕 ZEXAL Ⅱ - 바리안 편\n",
      "     연도: 2012.0 | 장르: 액션|판타지\n",
      "     추천 점수: 0.0566\n",
      "\n",
      "17. [인덱스: 851] 허구추리\n",
      "     연도: 2020.0 | 장르: 코미디|미스터리|로맨스|초자연\n",
      "     추천 점수: 0.0566\n",
      "\n",
      "18. [인덱스:4244] 프린세스 커넥트! 인도의 첫 꽃 - 피오레 스토리아 -\n",
      "     연도: 2025.0 | 장르: 액션|모험|코미디|판타지\n",
      "     추천 점수: 0.0562\n",
      "\n",
      "19. [인덱스: 149] 삼각창의 밖은 밤\n",
      "     연도: 2021.0 | 장르: 드라마|미스터리|초자연\n",
      "     추천 점수: 0.0538\n",
      "\n",
      "20. [인덱스:1184] 보석의 나라\n",
      "     연도: 2017.0 | 장르: 액션|드라마|판타지|미스터리|심리\n",
      "     추천 점수: 0.0537\n",
      "\n",
      "✅ 추천 결과를 'final_recommendations_backup.pkl'에 저장했습니다.\n",
      "\n",
      "=== Task 7 완료 (우회 방법) ===\n",
      "✅ TF-IDF 기반 백업 임베딩 생성 완료\n",
      "✅ 피드백 기반 사용자 프로필 생성 완료\n",
      "✅ 추천 점수 계산 완료\n",
      "✅ 상위 100개 추천 추출 완료\n",
      "✅ 추천 결과 저장 완료\n",
      "\n",
      "📝 참고: 원본 임베딩에 문제가 있어 TF-IDF 기반 방법을 사용했습니다.\n",
      "Task 8은 이 결과를 기반으로 진행할 수 있습니다!\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T05:43:15.729143Z",
     "start_time": "2025-09-08T05:43:13.752380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import json\n",
    "\n",
    "# Task 8: 결과 필터링 및 출력\n",
    "\n",
    "class RecommendationFinalizer:\n",
    "    def __init__(self):\n",
    "        \"\"\"추천 결과 최종 처리기 초기화\"\"\"\n",
    "        self.anime_data = None\n",
    "        self.recommendations = None\n",
    "        self.liked_animes = None\n",
    "        self.disliked_animes = None\n",
    "        self.total_animes = None\n",
    "        self.method = None\n",
    "\n",
    "    def load_recommendation_results(self, load_path=\"final_recommendations_backup.pkl\"):\n",
    "        \"\"\"Task 7에서 생성한 추천 결과 로드\"\"\"\n",
    "        print(\"=== 추천 결과 로드 중 ===\")\n",
    "\n",
    "        if not os.path.exists(load_path):\n",
    "            print(f\"❌ 추천 결과 파일을 찾을 수 없습니다: {load_path}\")\n",
    "            print(\"먼저 Task 7을 실행하여 추천 결과를 생성해주세요.\")\n",
    "            return False\n",
    "\n",
    "        with open(load_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "\n",
    "        self.recommendations = data['recommendations']\n",
    "        self.liked_animes = data['liked_animes']\n",
    "        self.disliked_animes = data['disliked_animes']\n",
    "        self.total_animes = data['total_animes']\n",
    "        self.method = data.get('method', 'unknown')\n",
    "\n",
    "        print(f\"✅ 추천 결과 로드 완료:\")\n",
    "        print(f\"   - 추천 애니메이션: {len(self.recommendations)}개\")\n",
    "        print(f\"   - 좋아요: {len(self.liked_animes)}개\")\n",
    "        print(f\"   - 싫어요: {len(self.disliked_animes)}개\")\n",
    "        print(f\"   - 전체 애니메이션: {self.total_animes}개\")\n",
    "        print(f\"   - 사용 방법: {self.method}\")\n",
    "\n",
    "        return True\n",
    "\n",
    "    def load_anime_data(self):\n",
    "        \"\"\"애니메이션 메타데이터 로드\"\"\"\n",
    "        data_path = \"anime_data_with_features.csv\"\n",
    "        if not os.path.exists(data_path):\n",
    "            print(f\"❌ 애니메이션 데이터를 찾을 수 없습니다: {data_path}\")\n",
    "            return False\n",
    "\n",
    "        self.anime_data = pd.read_csv(data_path)\n",
    "        print(f\"✅ 애니메이션 메타데이터 로드 완료: {len(self.anime_data)}개\")\n",
    "\n",
    "        return True\n",
    "\n",
    "    def verify_and_clean_recommendations(self):\n",
    "        \"\"\"추천 결과 검증 및 정리\"\"\"\n",
    "        print(f\"\\n=== 추천 결과 검증 및 정리 ===\")\n",
    "\n",
    "        initial_count = len(self.recommendations)\n",
    "\n",
    "        # 1. 유효한 인덱스인지 확인\n",
    "        valid_recommendations = []\n",
    "        for idx, score in self.recommendations:\n",
    "            if 0 <= idx < len(self.anime_data):\n",
    "                valid_recommendations.append((idx, score))\n",
    "            else:\n",
    "                print(f\"⚠️ 유효하지 않은 인덱스 제거: {idx}\")\n",
    "\n",
    "        # 2. 이미 평가한 애니메이션 재확인\n",
    "        evaluated_set = set(self.liked_animes + self.disliked_animes)\n",
    "        clean_recommendations = []\n",
    "        removed_count = 0\n",
    "\n",
    "        for idx, score in valid_recommendations:\n",
    "            if idx not in evaluated_set:\n",
    "                clean_recommendations.append((idx, score))\n",
    "            else:\n",
    "                removed_count += 1\n",
    "\n",
    "        self.recommendations = clean_recommendations\n",
    "\n",
    "        print(f\"✅ 검증 완료:\")\n",
    "        print(f\"   - 초기 추천: {initial_count}개\")\n",
    "        print(f\"   - 유효한 추천: {len(valid_recommendations)}개\")\n",
    "        print(f\"   - 평가 제외: {removed_count}개\")\n",
    "        print(f\"   - 최종 추천: {len(self.recommendations)}개\")\n",
    "\n",
    "        return True\n",
    "\n",
    "    def apply_additional_filters(self, min_year=None, max_year=None, include_genres=None, exclude_genres=None):\n",
    "        \"\"\"추가 필터링 적용\"\"\"\n",
    "        print(f\"\\n=== 추가 필터링 적용 ===\")\n",
    "\n",
    "        filtered_recommendations = []\n",
    "        filter_stats = {\n",
    "            'year_filtered': 0,\n",
    "            'genre_include_filtered': 0,\n",
    "            'genre_exclude_filtered': 0,\n",
    "            'total_removed': 0\n",
    "        }\n",
    "\n",
    "        for idx, score in self.recommendations:\n",
    "            anime = self.anime_data.iloc[idx]\n",
    "            should_include = True\n",
    "\n",
    "            # 연도 필터링\n",
    "            if min_year is not None or max_year is not None:\n",
    "                year = anime.get('year')\n",
    "                if pd.notna(year):\n",
    "                    try:\n",
    "                        year = int(float(year))\n",
    "                        if min_year is not None and year < min_year:\n",
    "                            should_include = False\n",
    "                            filter_stats['year_filtered'] += 1\n",
    "                        elif max_year is not None and year > max_year:\n",
    "                            should_include = False\n",
    "                            filter_stats['year_filtered'] += 1\n",
    "                    except (ValueError, TypeError):\n",
    "                        pass\n",
    "\n",
    "            # 포함 장르 필터링\n",
    "            if include_genres and should_include:\n",
    "                genres = str(anime.get('genres', '')).lower()\n",
    "                if not any(genre.lower() in genres for genre in include_genres):\n",
    "                    should_include = False\n",
    "                    filter_stats['genre_include_filtered'] += 1\n",
    "\n",
    "            # 제외 장르 필터링\n",
    "            if exclude_genres and should_include:\n",
    "                genres = str(anime.get('genres', '')).lower()\n",
    "                if any(genre.lower() in genres for genre in exclude_genres):\n",
    "                    should_include = False\n",
    "                    filter_stats['genre_exclude_filtered'] += 1\n",
    "\n",
    "            if should_include:\n",
    "                filtered_recommendations.append((idx, score))\n",
    "            else:\n",
    "                filter_stats['total_removed'] += 1\n",
    "\n",
    "        if any(filter_stats.values()):\n",
    "            print(f\"필터링 결과:\")\n",
    "            if min_year or max_year:\n",
    "                print(f\"   - 연도 조건 ({min_year}-{max_year}): {filter_stats['year_filtered']}개 제외\")\n",
    "            if include_genres:\n",
    "                print(f\"   - 장르 포함 조건 ({include_genres}): {filter_stats['genre_include_filtered']}개 제외\")\n",
    "            if exclude_genres:\n",
    "                print(f\"   - 장르 제외 조건 ({exclude_genres}): {filter_stats['genre_exclude_filtered']}개 제외\")\n",
    "            print(f\"   - 총 제외: {filter_stats['total_removed']}개\")\n",
    "            print(f\"   - 남은 추천: {len(filtered_recommendations)}개\")\n",
    "\n",
    "            self.recommendations = filtered_recommendations\n",
    "        else:\n",
    "            print(\"추가 필터링 조건이 없어 모든 추천을 유지합니다.\")\n",
    "\n",
    "        return True\n",
    "\n",
    "    def extract_final_top_100(self):\n",
    "        \"\"\"최종 상위 100개 추출\"\"\"\n",
    "        print(f\"\\n=== 최종 상위 100개 추출 ===\")\n",
    "\n",
    "        # 이미 정렬되어 있지만 재정렬하여 확실히 함\n",
    "        self.recommendations.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # 상위 100개 추출\n",
    "        final_top_100 = self.recommendations[:100]\n",
    "\n",
    "        print(f\"✅ 최종 추천 100개 추출 완료\")\n",
    "        if final_top_100:\n",
    "            print(f\"   - 1위 점수: {final_top_100[0][1]:.4f}\")\n",
    "            print(f\"   - 100위 점수: {final_top_100[-1][1]:.4f}\" if len(final_top_100) >= 100 else f\"   - {len(final_top_100)}위 점수: {final_top_100[-1][1]:.4f}\")\n",
    "\n",
    "        return final_top_100\n",
    "\n",
    "    def analyze_recommendation_patterns(self, final_recommendations):\n",
    "        \"\"\"추천 결과 패턴 분석\"\"\"\n",
    "        print(f\"\\n=== 추천 결과 패턴 분석 ===\")\n",
    "\n",
    "        # 데이터 수집\n",
    "        genres_list = []\n",
    "        years_list = []\n",
    "        studios_list = []\n",
    "\n",
    "        for idx, score in final_recommendations:\n",
    "            anime = self.anime_data.iloc[idx]\n",
    "\n",
    "            # 장르 분석\n",
    "            genres = anime.get('genres', '')\n",
    "            if pd.notna(genres) and genres:\n",
    "                for genre in str(genres).replace('|', ',').split(','):\n",
    "                    genre = genre.strip()\n",
    "                    if genre and genre.lower() != 'nan':\n",
    "                        genres_list.append(genre)\n",
    "\n",
    "            # 연도 분석\n",
    "            year = anime.get('year')\n",
    "            if pd.notna(year):\n",
    "                try:\n",
    "                    years_list.append(int(float(year)))\n",
    "                except (ValueError, TypeError):\n",
    "                    pass\n",
    "\n",
    "            # 제작사 분석\n",
    "            studio = anime.get('studio', '')\n",
    "            if pd.notna(studio) and studio and studio.lower() != 'nan':\n",
    "                studios_list.append(str(studio).strip())\n",
    "\n",
    "        # 분석 결과\n",
    "        analysis_results = {}\n",
    "\n",
    "        # 1. 장르 분석\n",
    "        if genres_list:\n",
    "            genre_counter = Counter(genres_list)\n",
    "            analysis_results['top_genres'] = genre_counter.most_common(10)\n",
    "            print(f\"인기 장르 TOP 10:\")\n",
    "            for genre, count in analysis_results['top_genres']:\n",
    "                percentage = (count / len(final_recommendations)) * 100\n",
    "                print(f\"   - {genre}: {count}개 ({percentage:.1f}%)\")\n",
    "\n",
    "        # 2. 연도 분석\n",
    "        if years_list:\n",
    "            analysis_results['year_stats'] = {\n",
    "                'mean': np.mean(years_list),\n",
    "                'median': np.median(years_list),\n",
    "                'min': min(years_list),\n",
    "                'max': max(years_list),\n",
    "                'std': np.std(years_list)\n",
    "            }\n",
    "            print(f\"\\n연도 분포:\")\n",
    "            print(f\"   - 평균: {analysis_results['year_stats']['mean']:.1f}\")\n",
    "            print(f\"   - 중앙값: {analysis_results['year_stats']['median']:.1f}\")\n",
    "            print(f\"   - 범위: {analysis_results['year_stats']['min']} ~ {analysis_results['year_stats']['max']}\")\n",
    "            print(f\"   - 표준편차: {analysis_results['year_stats']['std']:.1f}\")\n",
    "\n",
    "        # 3. 제작사 분석\n",
    "        if studios_list:\n",
    "            studio_counter = Counter(studios_list)\n",
    "            analysis_results['top_studios'] = studio_counter.most_common(10)\n",
    "            print(f\"\\n인기 제작사 TOP 10:\")\n",
    "            for studio, count in analysis_results['top_studios']:\n",
    "                print(f\"   - {studio}: {count}개\")\n",
    "\n",
    "        return analysis_results\n",
    "\n",
    "    def create_comprehensive_report(self, final_recommendations, analysis_results):\n",
    "        \"\"\"종합 보고서 생성\"\"\"\n",
    "        print(f\"\\n=== 종합 보고서 생성 ===\")\n",
    "\n",
    "        report = {\n",
    "            'summary': {\n",
    "                'total_recommendations': len(final_recommendations),\n",
    "                'user_liked_count': len(self.liked_animes),\n",
    "                'user_disliked_count': len(self.disliked_animes),\n",
    "                'recommendation_method': self.method,\n",
    "                'score_range': {\n",
    "                    'highest': final_recommendations[0][1] if final_recommendations else 0,\n",
    "                    'lowest': final_recommendations[-1][1] if final_recommendations else 0\n",
    "                }\n",
    "            },\n",
    "            'user_preference_analysis': self.analyze_user_preferences(),\n",
    "            'recommendation_analysis': analysis_results,\n",
    "            'top_recommendations': []\n",
    "        }\n",
    "\n",
    "        # 상위 20개 상세 정보\n",
    "        for i, (idx, score) in enumerate(final_recommendations[:20]):\n",
    "            anime = self.anime_data.iloc[idx]\n",
    "            report['top_recommendations'].append({\n",
    "                'rank': i + 1,\n",
    "                'index': int(idx),\n",
    "                'title_korean': anime.get('title_korean', '제목 없음'),\n",
    "                'title_japanese': anime.get('title_japanese', ''),\n",
    "                'title_english': anime.get('title_english', ''),\n",
    "                'year': anime.get('year', ''),\n",
    "                'genres': anime.get('genres', ''),\n",
    "                'director': anime.get('director', ''),\n",
    "                'studio': anime.get('studio', ''),\n",
    "                'synopsis': anime.get('synopsis', '')[:200] if pd.notna(anime.get('synopsis')) else '',\n",
    "                'recommendation_score': float(score)\n",
    "            })\n",
    "\n",
    "        return report\n",
    "\n",
    "    def analyze_user_preferences(self):\n",
    "        \"\"\"사용자 선호도 분석\"\"\"\n",
    "        liked_genres = []\n",
    "        disliked_genres = []\n",
    "\n",
    "        # 좋아요 애니메이션 분석\n",
    "        for idx in self.liked_animes:\n",
    "            anime = self.anime_data.iloc[idx]\n",
    "            genres = anime.get('genres', '')\n",
    "            if pd.notna(genres) and genres:\n",
    "                for genre in str(genres).replace('|', ',').split(','):\n",
    "                    genre = genre.strip()\n",
    "                    if genre and genre.lower() != 'nan':\n",
    "                        liked_genres.append(genre)\n",
    "\n",
    "        # 싫어요 애니메이션 분석\n",
    "        for idx in self.disliked_animes:\n",
    "            anime = self.anime_data.iloc[idx]\n",
    "            genres = anime.get('genres', '')\n",
    "            if pd.notna(genres) and genres:\n",
    "                for genre in str(genres).replace('|', ',').split(','):\n",
    "                    genre = genre.strip()\n",
    "                    if genre and genre.lower() != 'nan':\n",
    "                        disliked_genres.append(genre)\n",
    "\n",
    "        return {\n",
    "            'liked_genres': Counter(liked_genres).most_common(5),\n",
    "            'disliked_genres': Counter(disliked_genres).most_common(5),\n",
    "            'liked_titles': [self.anime_data.iloc[idx].get('title_korean', '제목 없음') for idx in self.liked_animes],\n",
    "            'disliked_titles': [self.anime_data.iloc[idx].get('title_korean', '제목 없음') for idx in self.disliked_animes]\n",
    "        }\n",
    "\n",
    "    def visualize_recommendations(self, final_recommendations, analysis_results):\n",
    "        \"\"\"추천 결과 시각화\"\"\"\n",
    "        print(f\"\\n=== 추천 결과 시각화 ===\")\n",
    "\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "        # 1. 장르 분포 (상위 10개)\n",
    "        if 'top_genres' in analysis_results:\n",
    "            genres, counts = zip(*analysis_results['top_genres'])\n",
    "            axes[0, 0].barh(range(len(genres)), counts)\n",
    "            axes[0, 0].set_yticks(range(len(genres)))\n",
    "            axes[0, 0].set_yticklabels(genres)\n",
    "            axes[0, 0].set_title('추천 애니메이션 장르 분포 (TOP 10)')\n",
    "            axes[0, 0].set_xlabel('개수')\n",
    "\n",
    "        # 2. 연도 분포\n",
    "        years = []\n",
    "        for idx, score in final_recommendations:\n",
    "            year = self.anime_data.iloc[idx].get('year')\n",
    "            if pd.notna(year):\n",
    "                try:\n",
    "                    years.append(int(float(year)))\n",
    "                except (ValueError, TypeError):\n",
    "                    pass\n",
    "\n",
    "        if years:\n",
    "            axes[0, 1].hist(years, bins=20, alpha=0.7, edgecolor='black')\n",
    "            axes[0, 1].set_title('추천 애니메이션 연도 분포')\n",
    "            axes[0, 1].set_xlabel('연도')\n",
    "            axes[0, 1].set_ylabel('개수')\n",
    "\n",
    "        # 3. 추천 점수 분포\n",
    "        scores = [score for idx, score in final_recommendations]\n",
    "        axes[1, 0].hist(scores, bins=20, alpha=0.7, edgecolor='black', color='green')\n",
    "        axes[1, 0].set_title('추천 점수 분포')\n",
    "        axes[1, 0].set_xlabel('추천 점수')\n",
    "        axes[1, 0].set_ylabel('개수')\n",
    "\n",
    "        # 4. 상위 20개 점수 막대그래프\n",
    "        top_20_scores = scores[:20]\n",
    "        axes[1, 1].bar(range(1, len(top_20_scores) + 1), top_20_scores, color='orange')\n",
    "        axes[1, 1].set_title('상위 20개 추천 점수')\n",
    "        axes[1, 1].set_xlabel('순위')\n",
    "        axes[1, 1].set_ylabel('추천 점수')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('recommendation_analysis.png', dpi=150, bbox_inches='tight')\n",
    "        print(\"📊 시각화 결과가 'recommendation_analysis.png'에 저장되었습니다.\")\n",
    "        plt.show()\n",
    "\n",
    "    def display_final_results(self, final_recommendations, top_n=20):\n",
    "        \"\"\"최종 결과 출력\"\"\"\n",
    "        print(f\"\\n\" + \"=\"*80)\n",
    "        print(f\"🎬 하이브리드 애니메이션 추천 시스템 - 최종 결과\")\n",
    "        print(f\"=\"*80)\n",
    "        print(f\"📊 추천 개요:\")\n",
    "        print(f\"   • 전체 애니메이션: {self.total_animes:,}개\")\n",
    "        print(f\"   • 사용자 평가: 좋아요 {len(self.liked_animes)}개, 싫어요 {len(self.disliked_animes)}개\")\n",
    "        print(f\"   • 최종 추천: {len(final_recommendations)}개\")\n",
    "        print(f\"   • 사용 방법: {self.method}\")\n",
    "\n",
    "        print(f\"\\n🏆 상위 {top_n}개 추천 애니메이션:\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "        for i, (idx, score) in enumerate(final_recommendations[:top_n]):\n",
    "            anime = self.anime_data.iloc[idx]\n",
    "            title = anime.get('title_korean', '제목 없음')\n",
    "            year = anime.get('year', 'N/A')\n",
    "            genres = anime.get('genres', '장르 정보 없음')\n",
    "            director = anime.get('director', '감독 정보 없음')\n",
    "\n",
    "            print(f\"{i+1:2d}. 【{title}】({year})\")\n",
    "            print(f\"     장르: {genres}\")\n",
    "            print(f\"     감독: {director}\")\n",
    "            print(f\"     추천점수: {score:.4f} | 애니메이션 ID: {idx}\")\n",
    "\n",
    "            # 줄거리가 있다면 간략히 출력\n",
    "            synopsis = anime.get('synopsis', '')\n",
    "            if pd.notna(synopsis) and synopsis and len(synopsis) > 10:\n",
    "                synopsis_short = synopsis[:100] + \"...\" if len(synopsis) > 100 else synopsis\n",
    "                print(f\"     줄거리: {synopsis_short}\")\n",
    "            print()\n",
    "\n",
    "    def save_final_results(self, final_recommendations, report, save_id_list_path=\"final_100_anime_ids.txt\",\n",
    "                          save_detailed_path=\"detailed_recommendations.json\", save_report_path=\"recommendation_report.json\"):\n",
    "        \"\"\"최종 결과 저장\"\"\"\n",
    "        print(f\"\\n=== 최종 결과 저장 ===\")\n",
    "\n",
    "        # 1. 상위 100개 ID만 텍스트 파일로 저장\n",
    "        with open(save_id_list_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"# 하이브리드 애니메이션 추천 시스템 - 상위 100개 추천 애니메이션 ID\\n\")\n",
    "            f.write(f\"# 생성일: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "            f.write(f\"# 총 추천 개수: {len(final_recommendations)}\\n\\n\")\n",
    "\n",
    "            for i, (idx, score) in enumerate(final_recommendations[:100]):\n",
    "                f.write(f\"{idx}\\n\")\n",
    "\n",
    "        print(f\"✅ 상위 100개 ID 저장: {save_id_list_path}\")\n",
    "\n",
    "        # 2. 상세 정보 JSON으로 저장\n",
    "        detailed_data = []\n",
    "        for i, (idx, score) in enumerate(final_recommendations[:100]):\n",
    "            anime = self.anime_data.iloc[idx]\n",
    "            detailed_data.append({\n",
    "                'rank': i + 1,\n",
    "                'anime_id': int(idx),\n",
    "                'title_korean': anime.get('title_korean', ''),\n",
    "                'title_japanese': anime.get('title_japanese', ''),\n",
    "                'title_english': anime.get('title_english', ''),\n",
    "                'year': anime.get('year', ''),\n",
    "                'genres': anime.get('genres', ''),\n",
    "                'director': anime.get('director', ''),\n",
    "                'studio': anime.get('studio', ''),\n",
    "                'synopsis': anime.get('synopsis', ''),\n",
    "                'recommendation_score': float(score)\n",
    "            })\n",
    "\n",
    "        with open(save_detailed_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(detailed_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "        print(f\"✅ 상세 추천 정보 저장: {save_detailed_path}\")\n",
    "\n",
    "        # 3. 종합 보고서 저장\n",
    "        with open(save_report_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(report, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "        print(f\"✅ 종합 보고서 저장: {save_report_path}\")\n",
    "\n",
    "        return True\n",
    "\n",
    "# 실행\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== Task 8: 결과 필터링 및 출력 ===\\n\")\n",
    "\n",
    "    # 1. 최종 처리기 초기화\n",
    "    finalizer = RecommendationFinalizer()\n",
    "\n",
    "    # 2. 추천 결과 및 데이터 로드\n",
    "    if not finalizer.load_recommendation_results():\n",
    "        exit(1)\n",
    "\n",
    "    if not finalizer.load_anime_data():\n",
    "        exit(1)\n",
    "\n",
    "    # 3. 추천 결과 검증 및 정리\n",
    "    if not finalizer.verify_and_clean_recommendations():\n",
    "        exit(1)\n",
    "\n",
    "    # 4. 추가 필터링 (선택사항)\n",
    "    # 예시: 2000년 이후, 에치/성인 장르 제외\n",
    "    finalizer.apply_additional_filters(\n",
    "        min_year=2000,\n",
    "        exclude_genres=['에치', '성인', 'Ecchi', 'Hentai']\n",
    "    )\n",
    "\n",
    "    # 5. 최종 상위 100개 추출\n",
    "    final_top_100 = finalizer.extract_final_top_100()\n",
    "\n",
    "    # 6. 추천 결과 패턴 분석\n",
    "    analysis_results = finalizer.analyze_recommendation_patterns(final_top_100)\n",
    "\n",
    "    # 7. 종합 보고서 생성\n",
    "    comprehensive_report = finalizer.create_comprehensive_report(final_top_100, analysis_results)\n",
    "\n",
    "    # 8. 시각화\n",
    "    finalizer.visualize_recommendations(final_top_100, analysis_results)\n",
    "\n",
    "    # 9. 최종 결과 출력\n",
    "    finalizer.display_final_results(final_top_100, top_n=20)\n",
    "\n",
    "    # 10. 최종 결과 저장\n",
    "    finalizer.save_final_results(final_top_100, comprehensive_report)\n",
    "\n",
    "    print(f\"\\n\" + \"=\"*80)\n",
    "    print(f\"🎉 하이브리드 애니메이션 추천 시스템 완성!\")\n",
    "    print(f\"=\"*80)\n",
    "    print(\"✅ Task 8 완료:\")\n",
    "    print(\"✅ 추천 결과 검증 및 정리 완료\")\n",
    "    print(\"✅ 추가 필터링 적용 완료\")\n",
    "    print(\"✅ 최종 상위 100개 추출 완료\")\n",
    "    print(\"✅ 패턴 분석 및 시각화 완료\")\n",
    "    print(\"✅ 종합 보고서 생성 완료\")\n",
    "    print(\"✅ 최종 결과 저장 완료\")\n",
    "    print(f\"\\n📁 생성된 파일:\")\n",
    "    print(f\"   • final_100_anime_ids.txt - 상위 100개 ID\")\n",
    "    print(f\"   • detailed_recommendations.json - 상세 추천 정보\")\n",
    "    print(f\"   • recommendation_report.json - 종합 보고서\")\n",
    "    print(f\"   • recommendation_analysis.png - 분석 시각화\")\n",
    "    print(f\"\\n🎬 추천 시스템이 성공적으로 완성되었습니다!\")"
   ],
   "id": "c31c8c34e48c63b4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Task 8: 결과 필터링 및 출력 ===\n",
      "\n",
      "=== 추천 결과 로드 중 ===\n",
      "✅ 추천 결과 로드 완료:\n",
      "   - 추천 애니메이션: 100개\n",
      "   - 좋아요: 8개\n",
      "   - 싫어요: 3개\n",
      "   - 전체 애니메이션: 4453개\n",
      "   - 사용 방법: tfidf_backup\n",
      "✅ 애니메이션 메타데이터 로드 완료: 4453개\n",
      "\n",
      "=== 추천 결과 검증 및 정리 ===\n",
      "✅ 검증 완료:\n",
      "   - 초기 추천: 100개\n",
      "   - 유효한 추천: 100개\n",
      "   - 평가 제외: 0개\n",
      "   - 최종 추천: 100개\n",
      "\n",
      "=== 추가 필터링 적용 ===\n",
      "필터링 결과:\n",
      "   - 연도 조건 (2000-None): 0개 제외\n",
      "   - 장르 제외 조건 (['에치', '성인', 'Ecchi', 'Hentai']): 9개 제외\n",
      "   - 총 제외: 9개\n",
      "   - 남은 추천: 91개\n",
      "\n",
      "=== 최종 상위 100개 추출 ===\n",
      "✅ 최종 추천 100개 추출 완료\n",
      "   - 1위 점수: 0.1055\n",
      "   - 91위 점수: 0.0344\n",
      "\n",
      "=== 추천 결과 패턴 분석 ===\n",
      "인기 장르 TOP 10:\n",
      "   - 액션: 45개 (49.5%)\n",
      "   - 드라마: 37개 (40.7%)\n",
      "   - 코미디: 30개 (33.0%)\n",
      "   - 미스터리: 28개 (30.8%)\n",
      "   - SF: 26개 (28.6%)\n",
      "   - 판타지: 20개 (22.0%)\n",
      "   - 초자연: 20개 (22.0%)\n",
      "   - 로맨스: 18개 (19.8%)\n",
      "   - 모험: 16개 (17.6%)\n",
      "   - 일상: 15개 (16.5%)\n",
      "\n",
      "연도 분포:\n",
      "   - 평균: 2018.4\n",
      "   - 중앙값: 2020.0\n",
      "   - 범위: 2003 ~ 2025\n",
      "   - 표준편차: 5.8\n",
      "\n",
      "인기 제작사 TOP 10:\n",
      "   - 선라이즈, 마이니치 방송, 소츠, Bandai Namco Filmworks: 3개\n",
      "   - 스튜디오 피에로: 2개\n",
      "   - OLM, TV 도쿄: 2개\n",
      "   - Sunrise Beyond, 반다이 스피리츠, 소츠, Bandai Namco Filmworks: 2개\n",
      "   - MAPPA, Tohokushinsha Film Corporation: 2개\n",
      "   - 세븐 아크스: 2개\n",
      "   - 선라이즈: 1개\n",
      "   - POLYGON PICTURES: 1개\n",
      "   - Studio 4°C, Kansai TV: 1개\n",
      "   - Nexus, 매직 캡슐, 애니플렉스, 애니플렉스 미국, Madman Entertainment: 1개\n",
      "\n",
      "=== 종합 보고서 생성 ===\n",
      "\n",
      "=== 추천 결과 시각화 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:366: UserWarning: Glyph 44060 (\\N{HANGUL SYLLABLE GAE}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:366: UserWarning: Glyph 49688 (\\N{HANGUL SYLLABLE SU}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:366: UserWarning: Glyph 50529 (\\N{HANGUL SYLLABLE AEG}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:366: UserWarning: Glyph 49496 (\\N{HANGUL SYLLABLE SYEON}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:366: UserWarning: Glyph 46300 (\\N{HANGUL SYLLABLE DEU}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:366: UserWarning: Glyph 46972 (\\N{HANGUL SYLLABLE RA}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:366: UserWarning: Glyph 47560 (\\N{HANGUL SYLLABLE MA}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:366: UserWarning: Glyph 53076 (\\N{HANGUL SYLLABLE KO}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:366: UserWarning: Glyph 48120 (\\N{HANGUL SYLLABLE MI}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:366: UserWarning: Glyph 46356 (\\N{HANGUL SYLLABLE DI}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:366: UserWarning: Glyph 49828 (\\N{HANGUL SYLLABLE SEU}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:366: UserWarning: Glyph 53552 (\\N{HANGUL SYLLABLE TEO}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:366: UserWarning: Glyph 47532 (\\N{HANGUL SYLLABLE RI}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:366: UserWarning: Glyph 54032 (\\N{HANGUL SYLLABLE PAN}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:366: UserWarning: Glyph 53440 (\\N{HANGUL SYLLABLE TA}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:366: UserWarning: Glyph 51648 (\\N{HANGUL SYLLABLE JI}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:366: UserWarning: Glyph 52488 (\\N{HANGUL SYLLABLE CO}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:366: UserWarning: Glyph 51088 (\\N{HANGUL SYLLABLE JA}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:366: UserWarning: Glyph 50672 (\\N{HANGUL SYLLABLE YEON}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:366: UserWarning: Glyph 47196 (\\N{HANGUL SYLLABLE RO}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:366: UserWarning: Glyph 47592 (\\N{HANGUL SYLLABLE MAEN}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:366: UserWarning: Glyph 47784 (\\N{HANGUL SYLLABLE MO}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:366: UserWarning: Glyph 54744 (\\N{HANGUL SYLLABLE HEOM}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:366: UserWarning: Glyph 51068 (\\N{HANGUL SYLLABLE IL}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:366: UserWarning: Glyph 49345 (\\N{HANGUL SYLLABLE SANG}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:366: UserWarning: Glyph 52628 (\\N{HANGUL SYLLABLE CU}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:366: UserWarning: Glyph 52380 (\\N{HANGUL SYLLABLE CEON}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:366: UserWarning: Glyph 50528 (\\N{HANGUL SYLLABLE AE}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:366: UserWarning: Glyph 45768 (\\N{HANGUL SYLLABLE NI}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:366: UserWarning: Glyph 47700 (\\N{HANGUL SYLLABLE ME}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:366: UserWarning: Glyph 51060 (\\N{HANGUL SYLLABLE I}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:366: UserWarning: Glyph 51109 (\\N{HANGUL SYLLABLE JANG}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:366: UserWarning: Glyph 47476 (\\N{HANGUL SYLLABLE REU}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:366: UserWarning: Glyph 48516 (\\N{HANGUL SYLLABLE BUN}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:366: UserWarning: Glyph 54252 (\\N{HANGUL SYLLABLE PO}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:366: UserWarning: Glyph 46020 (\\N{HANGUL SYLLABLE DO}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:366: UserWarning: Glyph 51216 (\\N{HANGUL SYLLABLE JEOM}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:366: UserWarning: Glyph 49692 (\\N{HANGUL SYLLABLE SUN}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:366: UserWarning: Glyph 50948 (\\N{HANGUL SYLLABLE WI}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:367: UserWarning: Glyph 50529 (\\N{HANGUL SYLLABLE AEG}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('recommendation_analysis.png', dpi=150, bbox_inches='tight')\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:367: UserWarning: Glyph 49496 (\\N{HANGUL SYLLABLE SYEON}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('recommendation_analysis.png', dpi=150, bbox_inches='tight')\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:367: UserWarning: Glyph 46300 (\\N{HANGUL SYLLABLE DEU}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('recommendation_analysis.png', dpi=150, bbox_inches='tight')\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:367: UserWarning: Glyph 46972 (\\N{HANGUL SYLLABLE RA}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('recommendation_analysis.png', dpi=150, bbox_inches='tight')\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:367: UserWarning: Glyph 47560 (\\N{HANGUL SYLLABLE MA}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('recommendation_analysis.png', dpi=150, bbox_inches='tight')\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:367: UserWarning: Glyph 53076 (\\N{HANGUL SYLLABLE KO}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('recommendation_analysis.png', dpi=150, bbox_inches='tight')\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:367: UserWarning: Glyph 48120 (\\N{HANGUL SYLLABLE MI}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('recommendation_analysis.png', dpi=150, bbox_inches='tight')\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:367: UserWarning: Glyph 46356 (\\N{HANGUL SYLLABLE DI}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('recommendation_analysis.png', dpi=150, bbox_inches='tight')\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:367: UserWarning: Glyph 49828 (\\N{HANGUL SYLLABLE SEU}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('recommendation_analysis.png', dpi=150, bbox_inches='tight')\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:367: UserWarning: Glyph 53552 (\\N{HANGUL SYLLABLE TEO}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('recommendation_analysis.png', dpi=150, bbox_inches='tight')\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:367: UserWarning: Glyph 47532 (\\N{HANGUL SYLLABLE RI}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('recommendation_analysis.png', dpi=150, bbox_inches='tight')\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:367: UserWarning: Glyph 54032 (\\N{HANGUL SYLLABLE PAN}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('recommendation_analysis.png', dpi=150, bbox_inches='tight')\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:367: UserWarning: Glyph 53440 (\\N{HANGUL SYLLABLE TA}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('recommendation_analysis.png', dpi=150, bbox_inches='tight')\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:367: UserWarning: Glyph 51648 (\\N{HANGUL SYLLABLE JI}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('recommendation_analysis.png', dpi=150, bbox_inches='tight')\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:367: UserWarning: Glyph 52488 (\\N{HANGUL SYLLABLE CO}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('recommendation_analysis.png', dpi=150, bbox_inches='tight')\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:367: UserWarning: Glyph 51088 (\\N{HANGUL SYLLABLE JA}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('recommendation_analysis.png', dpi=150, bbox_inches='tight')\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:367: UserWarning: Glyph 50672 (\\N{HANGUL SYLLABLE YEON}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('recommendation_analysis.png', dpi=150, bbox_inches='tight')\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:367: UserWarning: Glyph 47196 (\\N{HANGUL SYLLABLE RO}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('recommendation_analysis.png', dpi=150, bbox_inches='tight')\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:367: UserWarning: Glyph 47592 (\\N{HANGUL SYLLABLE MAEN}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('recommendation_analysis.png', dpi=150, bbox_inches='tight')\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:367: UserWarning: Glyph 47784 (\\N{HANGUL SYLLABLE MO}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('recommendation_analysis.png', dpi=150, bbox_inches='tight')\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:367: UserWarning: Glyph 54744 (\\N{HANGUL SYLLABLE HEOM}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('recommendation_analysis.png', dpi=150, bbox_inches='tight')\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:367: UserWarning: Glyph 51068 (\\N{HANGUL SYLLABLE IL}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('recommendation_analysis.png', dpi=150, bbox_inches='tight')\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:367: UserWarning: Glyph 49345 (\\N{HANGUL SYLLABLE SANG}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('recommendation_analysis.png', dpi=150, bbox_inches='tight')\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:367: UserWarning: Glyph 52628 (\\N{HANGUL SYLLABLE CU}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('recommendation_analysis.png', dpi=150, bbox_inches='tight')\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:367: UserWarning: Glyph 52380 (\\N{HANGUL SYLLABLE CEON}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('recommendation_analysis.png', dpi=150, bbox_inches='tight')\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:367: UserWarning: Glyph 50528 (\\N{HANGUL SYLLABLE AE}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('recommendation_analysis.png', dpi=150, bbox_inches='tight')\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:367: UserWarning: Glyph 45768 (\\N{HANGUL SYLLABLE NI}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('recommendation_analysis.png', dpi=150, bbox_inches='tight')\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:367: UserWarning: Glyph 47700 (\\N{HANGUL SYLLABLE ME}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('recommendation_analysis.png', dpi=150, bbox_inches='tight')\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:367: UserWarning: Glyph 51060 (\\N{HANGUL SYLLABLE I}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('recommendation_analysis.png', dpi=150, bbox_inches='tight')\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:367: UserWarning: Glyph 51109 (\\N{HANGUL SYLLABLE JANG}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('recommendation_analysis.png', dpi=150, bbox_inches='tight')\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:367: UserWarning: Glyph 47476 (\\N{HANGUL SYLLABLE REU}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('recommendation_analysis.png', dpi=150, bbox_inches='tight')\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:367: UserWarning: Glyph 48516 (\\N{HANGUL SYLLABLE BUN}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('recommendation_analysis.png', dpi=150, bbox_inches='tight')\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:367: UserWarning: Glyph 54252 (\\N{HANGUL SYLLABLE PO}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('recommendation_analysis.png', dpi=150, bbox_inches='tight')\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:367: UserWarning: Glyph 44060 (\\N{HANGUL SYLLABLE GAE}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('recommendation_analysis.png', dpi=150, bbox_inches='tight')\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:367: UserWarning: Glyph 49688 (\\N{HANGUL SYLLABLE SU}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('recommendation_analysis.png', dpi=150, bbox_inches='tight')\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:367: UserWarning: Glyph 46020 (\\N{HANGUL SYLLABLE DO}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('recommendation_analysis.png', dpi=150, bbox_inches='tight')\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:367: UserWarning: Glyph 51216 (\\N{HANGUL SYLLABLE JEOM}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('recommendation_analysis.png', dpi=150, bbox_inches='tight')\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:367: UserWarning: Glyph 50948 (\\N{HANGUL SYLLABLE WI}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('recommendation_analysis.png', dpi=150, bbox_inches='tight')\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Temp\\ipykernel_16500\\995321364.py:367: UserWarning: Glyph 49692 (\\N{HANGUL SYLLABLE SUN}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('recommendation_analysis.png', dpi=150, bbox_inches='tight')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 시각화 결과가 'recommendation_analysis.png'에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NSMUSER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 50529 (\\N{HANGUL SYLLABLE AEG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 49496 (\\N{HANGUL SYLLABLE SYEON}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 46300 (\\N{HANGUL SYLLABLE DEU}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 46972 (\\N{HANGUL SYLLABLE RA}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 47560 (\\N{HANGUL SYLLABLE MA}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 53076 (\\N{HANGUL SYLLABLE KO}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 48120 (\\N{HANGUL SYLLABLE MI}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 46356 (\\N{HANGUL SYLLABLE DI}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 49828 (\\N{HANGUL SYLLABLE SEU}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 53552 (\\N{HANGUL SYLLABLE TEO}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 47532 (\\N{HANGUL SYLLABLE RI}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 54032 (\\N{HANGUL SYLLABLE PAN}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 53440 (\\N{HANGUL SYLLABLE TA}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 51648 (\\N{HANGUL SYLLABLE JI}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 52488 (\\N{HANGUL SYLLABLE CO}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 51088 (\\N{HANGUL SYLLABLE JA}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 50672 (\\N{HANGUL SYLLABLE YEON}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 47196 (\\N{HANGUL SYLLABLE RO}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 47592 (\\N{HANGUL SYLLABLE MAEN}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 47784 (\\N{HANGUL SYLLABLE MO}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 54744 (\\N{HANGUL SYLLABLE HEOM}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 51068 (\\N{HANGUL SYLLABLE IL}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 49345 (\\N{HANGUL SYLLABLE SANG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 52628 (\\N{HANGUL SYLLABLE CU}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 52380 (\\N{HANGUL SYLLABLE CEON}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 50528 (\\N{HANGUL SYLLABLE AE}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 45768 (\\N{HANGUL SYLLABLE NI}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 47700 (\\N{HANGUL SYLLABLE ME}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 51060 (\\N{HANGUL SYLLABLE I}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 51109 (\\N{HANGUL SYLLABLE JANG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 47476 (\\N{HANGUL SYLLABLE REU}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 48516 (\\N{HANGUL SYLLABLE BUN}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 54252 (\\N{HANGUL SYLLABLE PO}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 44060 (\\N{HANGUL SYLLABLE GAE}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 49688 (\\N{HANGUL SYLLABLE SU}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 46020 (\\N{HANGUL SYLLABLE DO}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 51216 (\\N{HANGUL SYLLABLE JEOM}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 50948 (\\N{HANGUL SYLLABLE WI}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\NSMUSER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 49692 (\\N{HANGUL SYLLABLE SUN}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1200 with 4 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "🎬 하이브리드 애니메이션 추천 시스템 - 최종 결과\n",
      "================================================================================\n",
      "📊 추천 개요:\n",
      "   • 전체 애니메이션: 4,453개\n",
      "   • 사용자 평가: 좋아요 8개, 싫어요 3개\n",
      "   • 최종 추천: 91개\n",
      "   • 사용 방법: tfidf_backup\n",
      "\n",
      "🏆 상위 20개 추천 애니메이션:\n",
      "--------------------------------------------------------------------------------\n",
      " 1. 【SD 건담 월드 히어로즈】(2021.0)\n",
      "     장르: 액션|메카\n",
      "     감독: 이케조에 타카히로\n",
      "     추천점수: 0.1055 | 애니메이션 ID: 503\n",
      "     줄거리: 영웅들이 균형을 유지하는 세계.그중 하나인 네오 월드에 갑자기 적열 운석이 날아온다.낙하지점에 나타난 건 자칭 '오공 임펄스 건담'이라는 기억을 상실한 소년.이 사건으로 촉발된 혼...\n",
      "\n",
      " 2. 【트러스트】(2025.0)\n",
      "     장르: 미스터리|SF\n",
      "     감독: Chizuru Kakimoto, Tomofumi Inoue\n",
      "     추천점수: 0.1042 | 애니메이션 ID: 4241\n",
      "     줄거리: 등록된 줄거리가 없습니다.\n",
      "\n",
      " 3. 【세기말 하모니】(2015.0)\n",
      "     장르: 미스터리|심리|SF|스릴러\n",
      "     감독: Michael Arias, 나카무라 타카시\n",
      "     추천점수: 0.0917 | 애니메이션 ID: 2237\n",
      "     줄거리: 등록된 줄거리가 없습니다.\n",
      "\n",
      " 4. 【다윈즈 게임】(2020.0)\n",
      "     장르: 액션|미스터리|SF|스릴러\n",
      "     감독: 도쿠모토 요시노부\n",
      "     추천점수: 0.0763 | 애니메이션 ID: 914\n",
      "     줄거리: 등록된 줄거리가 없습니다.\n",
      "\n",
      " 5. 【이드: 인베이디드】(2020.0)\n",
      "     장르: 드라마|미스터리|심리|SF|스릴러\n",
      "     감독: 아오키 에이\n",
      "     추천점수: 0.0754 | 애니메이션 ID: 2129\n",
      "     줄거리: 등록된 줄거리가 없습니다.\n",
      "\n",
      " 6. 【[극장판]귀멸의 칼날: 무한열차 편】(2020.0)\n",
      "     장르: 액션|모험|드라마|판타지|미스터리|초자연\n",
      "     감독: 토자키 하루오\n",
      "     추천점수: 0.0693 | 애니메이션 ID: 1197\n",
      "     줄거리: 등록된 줄거리가 없습니다.\n",
      "\n",
      " 7. 【흑집사 -녹색의 마녀 편-】(2025.0)\n",
      "     장르: 액션|코미디|판타지|미스터리|초자연\n",
      "     감독: 오카다 켄지로\n",
      "     추천점수: 0.0649 | 애니메이션 ID: 4200\n",
      "     줄거리: 등록된 줄거리가 없습니다.\n",
      "\n",
      " 8. 【강철의 연금술사 오리지널】(2003.0)\n",
      "     장르: 액션|모험|드라마|판타지\n",
      "     감독: 미즈시마 세이지\n",
      "     추천점수: 0.0638 | 애니메이션 ID: 934\n",
      "     줄거리: 등록된 줄거리가 없습니다.\n",
      "\n",
      " 9. 【황혼 호텔】(2025.0)\n",
      "     장르: 미스터리|초자연\n",
      "     감독: 코우즈이 야스케\n",
      "     추천점수: 0.0618 | 애니메이션 ID: 4071\n",
      "     줄거리: 등록된 줄거리가 없습니다.\n",
      "\n",
      "10. 【[극장판] 파워 디지몬 더 비기닝】(2023.0)\n",
      "     장르: 드라마|판타지\n",
      "     감독: 타구치 토모히사\n",
      "     추천점수: 0.0615 | 애니메이션 ID: 3674\n",
      "     줄거리: 이 세계는 가능성이 넘쳐난다.눈앞에 펼쳐진 수많은 세계는 때로는 희망을 느끼게하고,때로는 비정하다.하지만 우리는 그 세계를 망설이지 않고 받아들인다.왜냐하면 그것은 새로운 모험의 ...\n",
      "\n",
      "11. 【넘버 24】(2020.0)\n",
      "     장르: 스포츠\n",
      "     감독: 키미야 시게루\n",
      "     추천점수: 0.0610 | 애니메이션 ID: 2281\n",
      "     줄거리: 등록된 줄거리가 없습니다.\n",
      "\n",
      "12. 【이누야시키】(2017.0)\n",
      "     장르: 액션|드라마|심리|SF\n",
      "     감독: 시타다 슈헤이\n",
      "     추천점수: 0.0578 | 애니메이션 ID: 2208\n",
      "     줄거리: 등록된 줄거리가 없습니다.\n",
      "\n",
      "13. 【도교 구울 특별편】(2015.0)\n",
      "     장르: 드라마|공포|초자연\n",
      "     감독: 마츠바야시 유이토\n",
      "     추천점수: 0.0577 | 애니메이션 ID: 918\n",
      "     줄거리: 등록된 줄거리가 없습니다.\n",
      "\n",
      "14. 【포켓몬스터 노려라 포켓몬 마스터】(2023.0)\n",
      "     장르: 액션|모험|코미디|판타지\n",
      "     감독: 토미야스 다이키\n",
      "     추천점수: 0.0573 | 애니메이션 ID: 621\n",
      "     줄거리: 1997년 4월 1일,지우와 파트너인 피카츄는 태초마을에서 여행을 떠나,「포켓몬스터」의 세계로의 발을 디뎠습니다.많은 동료들과 만나,배틀하는 가운데 지우가 계속 변함없이 목표로 해...\n",
      "\n",
      "15. 【유희왕 ZEXAL Ⅱ - 바리안 편】(2012.0)\n",
      "     장르: 액션|판타지\n",
      "     감독: 쿠와바라 토모\n",
      "     추천점수: 0.0566 | 애니메이션 ID: 1545\n",
      "     줄거리: 등록된 줄거리가 없습니다.\n",
      "\n",
      "16. 【허구추리】(2020.0)\n",
      "     장르: 코미디|미스터리|로맨스|초자연\n",
      "     감독: 고토 케이지\n",
      "     추천점수: 0.0566 | 애니메이션 ID: 851\n",
      "     줄거리: 등록된 줄거리가 없습니다.\n",
      "\n",
      "17. 【프린세스 커넥트! 인도의 첫 꽃 - 피오레 스토리아 -】(2025.0)\n",
      "     장르: 액션|모험|코미디|판타지\n",
      "     감독: nan\n",
      "     추천점수: 0.0562 | 애니메이션 ID: 4244\n",
      "     줄거리: 등록된 줄거리가 없습니다.\n",
      "\n",
      "18. 【삼각창의 밖은 밤】(2021.0)\n",
      "     장르: 드라마|미스터리|초자연\n",
      "     감독: 야스다 요시타카\n",
      "     추천점수: 0.0538 | 애니메이션 ID: 149\n",
      "     줄거리: 예부터 섬뜩한 물건을 볼 수 있는 체질의 미카도 고스케는 우연히 만난 제령사 히야카와 리히토에게 그 재능이 발견되어, 심령탐정 콤비를 억지로 결성하고 만다.“이건 운명의 만남이에요...\n",
      "\n",
      "19. 【보석의 나라】(2017.0)\n",
      "     장르: 액션|드라마|판타지|미스터리|심리\n",
      "     감독: 쿄고쿠 나오히코\n",
      "     추천점수: 0.0537 | 애니메이션 ID: 1184\n",
      "     줄거리: 등록된 줄거리가 없습니다.\n",
      "\n",
      "20. 【포켓몬스터 XY】(2013.0)\n",
      "     장르: 액션|모험|코미디|판타지\n",
      "     감독: 야지마 테츠오\n",
      "     추천점수: 0.0535 | 애니메이션 ID: 2935\n",
      "     줄거리: 등록된 줄거리가 없습니다.\n",
      "\n",
      "\n",
      "=== 최종 결과 저장 ===\n",
      "✅ 상위 100개 ID 저장: final_100_anime_ids.txt\n",
      "✅ 상세 추천 정보 저장: detailed_recommendations.json\n",
      "✅ 종합 보고서 저장: recommendation_report.json\n",
      "\n",
      "================================================================================\n",
      "🎉 하이브리드 애니메이션 추천 시스템 완성!\n",
      "================================================================================\n",
      "✅ Task 8 완료:\n",
      "✅ 추천 결과 검증 및 정리 완료\n",
      "✅ 추가 필터링 적용 완료\n",
      "✅ 최종 상위 100개 추출 완료\n",
      "✅ 패턴 분석 및 시각화 완료\n",
      "✅ 종합 보고서 생성 완료\n",
      "✅ 최종 결과 저장 완료\n",
      "\n",
      "📁 생성된 파일:\n",
      "   • final_100_anime_ids.txt - 상위 100개 ID\n",
      "   • detailed_recommendations.json - 상세 추천 정보\n",
      "   • recommendation_report.json - 종합 보고서\n",
      "   • recommendation_analysis.png - 분석 시각화\n",
      "\n",
      "🎬 추천 시스템이 성공적으로 완성되었습니다!\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T05:46:57.513557Z",
     "start_time": "2025-09-08T05:46:50.211537Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install accelerate",
   "id": "3fa78dd3340a149d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate\n",
      "  Downloading accelerate-1.10.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from accelerate) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from accelerate) (2.7.1)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from accelerate) (0.33.5)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\n",
      "Requirement already satisfied: requests in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=2.0.0->accelerate) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub>=0.21.0->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.7.14)\n",
      "Downloading accelerate-1.10.1-py3-none-any.whl (374 kB)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-1.10.1\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T05:47:29.027088Z",
     "start_time": "2025-09-08T05:47:12.750574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM\n",
    "import gc\n",
    "\n",
    "# Task 5 수정: 카나나 모델 성공적 로드 및 LLM 프로필 생성\n",
    "\n",
    "class KananaLLMProfileGenerator:\n",
    "    def __init__(self):\n",
    "        \"\"\"카나나 모델 전용 LLM 프로필 생성기\"\"\"\n",
    "        self.embedding_tokenizer = None\n",
    "        self.embedding_model = None\n",
    "        self.instruct_tokenizer = None\n",
    "        self.instruct_model = None\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.anime_data = None\n",
    "\n",
    "        # 메모리 관리 설정\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            print(f\"GPU 메모리 사용 가능: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB\")\n",
    "\n",
    "    def load_embedding_model_safely(self):\n",
    "        \"\"\"안전한 카나나 임베딩 모델 로드\"\"\"\n",
    "        print(\"=== 카나나 임베딩 모델 로드 시도 ===\")\n",
    "\n",
    "        try:\n",
    "            model_name = \"kakaocorp/kanana-nano-2.1b-embedding\"\n",
    "\n",
    "            # 1. 토크나이저 먼저 로드\n",
    "            print(\"토크나이저 로드 중...\")\n",
    "            self.embedding_tokenizer = AutoTokenizer.from_pretrained(\n",
    "                model_name,\n",
    "                trust_remote_code=True,\n",
    "                use_fast=False  # 안정성을 위해 slow tokenizer 사용\n",
    "            )\n",
    "\n",
    "            # 2. 모델 로드 (메모리 효율적 설정)\n",
    "            print(\"임베딩 모델 로드 중...\")\n",
    "            self.embedding_model = AutoModel.from_pretrained(\n",
    "                model_name,\n",
    "                trust_remote_code=True,\n",
    "                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "                low_cpu_mem_usage=True\n",
    "            )\n",
    "\n",
    "            # 디바이스로 수동 이동\n",
    "            if torch.cuda.is_available():\n",
    "                self.embedding_model = self.embedding_model.to(self.device)\n",
    "\n",
    "            # 평가 모드로 설정\n",
    "            self.embedding_model.eval()\n",
    "\n",
    "            print(\"✅ 카나나 임베딩 모델 로드 성공!\")\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 카나나 임베딩 모델 로드 실패: {e}\")\n",
    "            print(\"상세 오류 정보:\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return False\n",
    "\n",
    "    def load_instruct_model_safely(self):\n",
    "        \"\"\"안전한 카나나 인스트럭트 모델 로드\"\"\"\n",
    "        print(\"\\n=== 카나나 인스트럭트 모델 로드 시도 ===\")\n",
    "\n",
    "        try:\n",
    "            model_name = \"kakaocorp/kanana-nano-2.1b-instruct\"\n",
    "\n",
    "            # GPU 메모리 정리\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "\n",
    "            # 1. 토크나이저 로드\n",
    "            print(\"인스트럭트 토크나이저 로드 중...\")\n",
    "            self.instruct_tokenizer = AutoTokenizer.from_pretrained(\n",
    "                model_name,\n",
    "                trust_remote_code=True,\n",
    "                use_fast=False\n",
    "            )\n",
    "\n",
    "            # 특수 토큰 설정\n",
    "            if self.instruct_tokenizer.pad_token is None:\n",
    "                self.instruct_tokenizer.pad_token = self.instruct_tokenizer.eos_token\n",
    "\n",
    "            # 2. 모델 로드 (매우 보수적 설정)\n",
    "            print(\"인스트럭트 모델 로드 중...\")\n",
    "            self.instruct_model = AutoModelForCausalLM.from_pretrained(\n",
    "                model_name,\n",
    "                trust_remote_code=True,\n",
    "                torch_dtype=torch.float16,\n",
    "                low_cpu_mem_usage=True,\n",
    "                device_map=\"auto\" if torch.cuda.is_available() else \"cpu\"\n",
    "            )\n",
    "\n",
    "            # 평가 모드로 설정\n",
    "            self.instruct_model.eval()\n",
    "\n",
    "            print(\"✅ 카나나 인스트럭트 모델 로드 성공!\")\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 카나나 인스트럭트 모델 로드 실패: {e}\")\n",
    "            print(\"메모리 부족이 원인일 수 있습니다.\")\n",
    "            return False\n",
    "\n",
    "    def load_required_data(self):\n",
    "        \"\"\"필요한 데이터 로드\"\"\"\n",
    "        data_path = \"anime_data_with_features.csv\"\n",
    "        if not os.path.exists(data_path):\n",
    "            print(f\"❌ 데이터 파일을 찾을 수 없습니다: {data_path}\")\n",
    "            return False\n",
    "\n",
    "        self.anime_data = pd.read_csv(data_path)\n",
    "        print(f\"✅ 애니메이션 데이터 로드 완료: {len(self.anime_data)}개\")\n",
    "        return True\n",
    "\n",
    "    def load_user_feedback(self, feedback_path=\"user_feedback.pkl\"):\n",
    "        \"\"\"사용자 피드백 로드\"\"\"\n",
    "        if not os.path.exists(feedback_path):\n",
    "            print(f\"❌ 피드백 파일을 찾을 수 없습니다: {feedback_path}\")\n",
    "            return None, None\n",
    "\n",
    "        with open(feedback_path, 'rb') as f:\n",
    "            feedback_data = pickle.load(f)\n",
    "\n",
    "        liked_animes = feedback_data['liked_animes']\n",
    "        disliked_animes = feedback_data['disliked_animes']\n",
    "\n",
    "        print(f\"✅ 사용자 피드백 로드 완료: 좋아요 {len(liked_animes)}개, 싫어요 {len(disliked_animes)}개\")\n",
    "        return liked_animes, disliked_animes\n",
    "\n",
    "    def create_rich_prompt(self, liked_animes, disliked_animes):\n",
    "        \"\"\"풍부한 정보를 담은 프롬프트 생성\"\"\"\n",
    "        print(\"\\n=== 풍부한 프롬프트 생성 중 ===\")\n",
    "\n",
    "        # 좋아요 애니메이션 상세 정보\n",
    "        liked_details = []\n",
    "        for idx in liked_animes[:5]:  # 너무 길지 않게 상위 5개만\n",
    "            anime = self.anime_data.iloc[idx]\n",
    "            title = anime.get('title_korean', '제목 없음')\n",
    "            genres = anime.get('genres', '장르 없음')\n",
    "            year = anime.get('year', '연도 없음')\n",
    "            synopsis = anime.get('synopsis', '')\n",
    "\n",
    "            detail = f\"'{title}' ({year}) - 장르: {genres}\"\n",
    "            if synopsis and len(synopsis) > 20:\n",
    "                detail += f\" - 줄거리: {synopsis[:100]}...\"\n",
    "            liked_details.append(detail)\n",
    "\n",
    "        # 싫어요 애니메이션 상세 정보\n",
    "        disliked_details = []\n",
    "        for idx in disliked_animes[:3]:  # 싫어요는 3개만\n",
    "            anime = self.anime_data.iloc[idx]\n",
    "            title = anime.get('title_korean', '제목 없음')\n",
    "            genres = anime.get('genres', '장르 없음')\n",
    "            year = anime.get('year', '연도 없음')\n",
    "\n",
    "            detail = f\"'{title}' ({year}) - 장르: {genres}\"\n",
    "            disliked_details.append(detail)\n",
    "\n",
    "        # 한국어 프롬프트 생성\n",
    "        prompt = f\"\"\"애니메이션 취향 분석을 도와주세요.\n",
    "\n",
    "사용자가 좋아하는 애니메이션들:\n",
    "{chr(10).join([f\"• {detail}\" for detail in liked_details])}\n",
    "\n",
    "사용자가 싫어하는 애니메이션들:\n",
    "{chr(10).join([f\"• {detail}\" for detail in disliked_details])}\n",
    "\n",
    "위의 정보를 바탕으로 이 사용자의 애니메이션 취향을 분석해주세요.\n",
    "다음 요소들을 고려하여 3-4문장으로 간결하게 요약해주세요:\n",
    "1. 선호하는 장르와 테마\n",
    "2. 선호하는 스토리 스타일이나 분위기\n",
    "3. 피하는 요소들\n",
    "4. 전반적인 취향 특성\n",
    "\n",
    "분석 결과:\"\"\"\n",
    "\n",
    "        print(f\"프롬프트 생성 완료 (길이: {len(prompt)}자)\")\n",
    "        return prompt\n",
    "\n",
    "    def generate_with_kanana_instruct(self, prompt):\n",
    "        \"\"\"카나나 인스트럭트 모델로 텍스트 생성\"\"\"\n",
    "        print(\"\\n=== 카나나 인스트럭트 모델로 취향 분석 생성 ===\")\n",
    "\n",
    "        if self.instruct_model is None or self.instruct_tokenizer is None:\n",
    "            print(\"❌ 인스트럭트 모델이 로드되지 않았습니다.\")\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            # 입력 토큰화\n",
    "            inputs = self.instruct_tokenizer(\n",
    "                prompt,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                max_length=1024,  # 입력 길이 제한\n",
    "                padding=True\n",
    "            )\n",
    "\n",
    "            # GPU로 이동 (가능한 경우)\n",
    "            if torch.cuda.is_available():\n",
    "                inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "\n",
    "            # 생성 파라미터 설정\n",
    "            generation_config = {\n",
    "                \"max_new_tokens\": 200,\n",
    "                \"min_new_tokens\": 50,\n",
    "                \"do_sample\": True,\n",
    "                \"temperature\": 0.7,\n",
    "                \"top_p\": 0.9,\n",
    "                \"top_k\": 50,\n",
    "                \"repetition_penalty\": 1.1,\n",
    "                \"pad_token_id\": self.instruct_tokenizer.eos_token_id,\n",
    "                \"eos_token_id\": self.instruct_tokenizer.eos_token_id\n",
    "            }\n",
    "\n",
    "            print(\"텍스트 생성 중...\")\n",
    "            with torch.no_grad():\n",
    "                outputs = self.instruct_model.generate(\n",
    "                    **inputs,\n",
    "                    **generation_config\n",
    "                )\n",
    "\n",
    "            # 디코딩\n",
    "            generated_text = self.instruct_tokenizer.decode(\n",
    "                outputs[0],\n",
    "                skip_special_tokens=True\n",
    "            )\n",
    "\n",
    "            # 입력 프롬프트 제거하고 생성된 부분만 추출\n",
    "            if \"분석 결과:\" in generated_text:\n",
    "                result = generated_text.split(\"분석 결과:\")[-1].strip()\n",
    "            else:\n",
    "                # 입력 길이만큼 제거\n",
    "                result = generated_text[len(prompt):].strip()\n",
    "\n",
    "            # 결과 정리\n",
    "            if result:\n",
    "                # 문장 단위로 정리\n",
    "                sentences = result.split('.')\n",
    "                # 처음 3-4 문장만 사용\n",
    "                clean_result = '. '.join(sentences[:4]).strip()\n",
    "                if clean_result and not clean_result.endswith('.'):\n",
    "                    clean_result += '.'\n",
    "\n",
    "                print(f\"✅ 카나나 모델 생성 성공!\")\n",
    "                print(f\"생성된 취향 분석 (길이: {len(clean_result)}자):\")\n",
    "                print(f\"'{clean_result}'\")\n",
    "\n",
    "                return clean_result\n",
    "            else:\n",
    "                print(\"⚠️ 생성된 텍스트가 비어있습니다.\")\n",
    "                return None\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 텍스트 생성 중 오류: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return None\n",
    "\n",
    "        finally:\n",
    "            # 메모리 정리\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "    def text_to_embedding_kanana(self, text):\n",
    "        \"\"\"카나나 임베딩 모델로 텍스트를 벡터로 변환\"\"\"\n",
    "        if self.embedding_model is None or self.embedding_tokenizer is None:\n",
    "            raise ValueError(\"임베딩 모델이 로드되지 않았습니다!\")\n",
    "\n",
    "        try:\n",
    "            inputs = self.embedding_tokenizer(\n",
    "                text,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                padding=True,\n",
    "                max_length=512\n",
    "            )\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = self.embedding_model(**inputs)\n",
    "                # 평균 풀링\n",
    "                embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "\n",
    "            return embeddings.cpu().numpy().flatten()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 임베딩 변환 중 오류: {e}\")\n",
    "            raise\n",
    "\n",
    "    def generate_llm_profile_kanana(self, liked_animes, disliked_animes):\n",
    "        \"\"\"카나나 모델을 사용한 완전한 LLM 프로필 생성\"\"\"\n",
    "        print(\"\\n=== 카나나 모델 기반 LLM 프로필 생성 시작 ===\")\n",
    "\n",
    "        # 1. 풍부한 프롬프트 생성\n",
    "        prompt = self.create_rich_prompt(liked_animes, disliked_animes)\n",
    "\n",
    "        # 2. 카나나 인스트럭트로 취향 분석 생성\n",
    "        taste_analysis = self.generate_with_kanana_instruct(prompt)\n",
    "\n",
    "        if taste_analysis is None:\n",
    "            print(\"❌ LLM 프로필 생성 실패\")\n",
    "            return None, None\n",
    "\n",
    "        # 3. 생성된 분석을 카나나 임베딩으로 벡터화\n",
    "        print(\"\\n=== 취향 분석을 임베딩으로 변환 ===\")\n",
    "        try:\n",
    "            v_llm_profile = self.text_to_embedding_kanana(taste_analysis)\n",
    "            print(f\"✅ LLM 프로필 벡터 생성 완료: {v_llm_profile.shape}\")\n",
    "\n",
    "            # 벡터 품질 확인\n",
    "            norm = np.linalg.norm(v_llm_profile)\n",
    "            print(f\"벡터 크기: {norm:.4f}\")\n",
    "            print(f\"비영 요소: {np.count_nonzero(v_llm_profile)}/{len(v_llm_profile)}\")\n",
    "\n",
    "            return v_llm_profile, taste_analysis\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 임베딩 변환 실패: {e}\")\n",
    "            return None, None\n",
    "\n",
    "    def save_kanana_llm_profile(self, v_llm_profile, taste_analysis, save_path=\"kanana_llm_profile.npz\"):\n",
    "        \"\"\"카나나 기반 LLM 프로필 저장\"\"\"\n",
    "        np.savez(save_path,\n",
    "                v_llm_profile=v_llm_profile,\n",
    "                taste_analysis=np.array([taste_analysis], dtype=object),\n",
    "                method=\"kanana_instruct\")\n",
    "\n",
    "        print(f\"✅ 카나나 LLM 프로필 저장 완료: {save_path}\")\n",
    "\n",
    "# 실행\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== Task 5 수정: 카나나 모델 성공적 로드 및 LLM 프로필 생성 ===\\n\")\n",
    "\n",
    "    # 1. 생성기 초기화\n",
    "    generator = KananaLLMProfileGenerator()\n",
    "\n",
    "    # 2. 데이터 로드\n",
    "    if not generator.load_required_data():\n",
    "        exit(1)\n",
    "\n",
    "    # 3. 사용자 피드백 로드\n",
    "    liked_animes, disliked_animes = generator.load_user_feedback()\n",
    "    if liked_animes is None:\n",
    "        exit(1)\n",
    "\n",
    "    # 4. 카나나 임베딩 모델 로드 시도\n",
    "    if not generator.load_embedding_model_safely():\n",
    "        print(\"❌ 임베딩 모델 로드 실패, 프로그램 종료\")\n",
    "        exit(1)\n",
    "\n",
    "    # 5. 카나나 인스트럭트 모델 로드 시도\n",
    "    if not generator.load_instruct_model_safely():\n",
    "        print(\"❌ 인스트럭트 모델 로드 실패\")\n",
    "        print(\"메모리 부족일 가능성이 높습니다.\")\n",
    "        print(\"다음을 시도해보세요:\")\n",
    "        print(\"1. 다른 프로그램들 종료하여 메모리 확보\")\n",
    "        print(\"2. Google Colab Pro 사용\")\n",
    "        print(\"3. 더 작은 모델 사용\")\n",
    "        exit(1)\n",
    "\n",
    "    # 6. 카나나 기반 LLM 프로필 생성\n",
    "    v_llm_profile, taste_analysis = generator.generate_llm_profile_kanana(liked_animes, disliked_animes)\n",
    "\n",
    "    if v_llm_profile is not None:\n",
    "        # 7. 결과 저장\n",
    "        generator.save_kanana_llm_profile(v_llm_profile, taste_analysis)\n",
    "\n",
    "        print(f\"\\n=== 카나나 LLM 프로필 생성 성공! ===\")\n",
    "        print(f\"생성된 취향 분석:\")\n",
    "        print(f\"'{taste_analysis}'\")\n",
    "        print(f\"벡터 차원: {v_llm_profile.shape}\")\n",
    "        print(f\"이제 이 결과를 Task 6에서 사용할 수 있습니다!\")\n",
    "    else:\n",
    "        print(\"❌ LLM 프로필 생성에 실패했습니다.\")"
   ],
   "id": "615b76317e0d68c6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Task 5 수정: 카나나 모델 성공적 로드 및 LLM 프로필 생성 ===\n",
      "\n",
      "✅ 애니메이션 데이터 로드 완료: 4453개\n",
      "✅ 사용자 피드백 로드 완료: 좋아요 8개, 싫어요 3개\n",
      "=== 카나나 임베딩 모델 로드 시도 ===\n",
      "토크나이저 로드 중...\n",
      "임베딩 모델 로드 중...\n",
      "✅ 카나나 임베딩 모델 로드 성공!\n",
      "\n",
      "=== 카나나 인스트럭트 모델 로드 시도 ===\n",
      "인스트럭트 토크나이저 로드 중...\n",
      "인스트럭트 모델 로드 중...\n",
      "❌ 카나나 인스트럭트 모델 로드 실패: Using a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` requires `accelerate`. You can install it with `pip install accelerate`\n",
      "메모리 부족이 원인일 수 있습니다.\n",
      "❌ 인스트럭트 모델 로드 실패\n",
      "메모리 부족일 가능성이 높습니다.\n",
      "다음을 시도해보세요:\n",
      "1. 다른 프로그램들 종료하여 메모리 확보\n",
      "2. Google Colab Pro 사용\n",
      "3. 더 작은 모델 사용\n",
      "\n",
      "=== 카나나 모델 기반 LLM 프로필 생성 시작 ===\n",
      "\n",
      "=== 풍부한 프롬프트 생성 중 ===\n",
      "프롬프트 생성 완료 (길이: 673자)\n",
      "\n",
      "=== 카나나 인스트럭트 모델로 취향 분석 생성 ===\n",
      "❌ 인스트럭트 모델이 로드되지 않았습니다.\n",
      "❌ LLM 프로필 생성 실패\n",
      "❌ LLM 프로필 생성에 실패했습니다.\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T05:48:00.305295Z",
     "start_time": "2025-09-08T05:47:54.866636Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install accelerate",
   "id": "67630b08c7a75919",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.10.1)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from accelerate) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from accelerate) (2.7.1)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from accelerate) (0.33.5)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\n",
      "Requirement already satisfied: requests in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=2.0.0->accelerate) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub>=0.21.0->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nsmuser\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.7.14)\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T05:58:00.290727Z",
     "start_time": "2025-09-08T05:56:49.285883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM\n",
    "import gc\n",
    "\n",
    "# Task 5 단순화: 최소 설정으로 카나나 모델 로드\n",
    "\n",
    "class SimpleKananaGenerator:\n",
    "    def __init__(self):\n",
    "        \"\"\"단순화된 카나나 모델 생성기\"\"\"\n",
    "        self.embedding_tokenizer = None\n",
    "        self.embedding_model = None\n",
    "        self.instruct_tokenizer = None\n",
    "        self.instruct_model = None\n",
    "        self.device = \"cpu\"  # 안전하게 CPU만 사용\n",
    "        self.anime_data = None\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"데이터 로드\"\"\"\n",
    "        # 애니메이션 데이터\n",
    "        data_path = \"anime_data_with_features.csv\"\n",
    "        if not os.path.exists(data_path):\n",
    "            return False\n",
    "        self.anime_data = pd.read_csv(data_path)\n",
    "\n",
    "        # 사용자 피드백\n",
    "        feedback_path = \"user_feedback.pkl\"\n",
    "        if not os.path.exists(feedback_path):\n",
    "            return False\n",
    "        with open(feedback_path, 'rb') as f:\n",
    "            feedback_data = pickle.load(f)\n",
    "\n",
    "        self.liked_animes = feedback_data['liked_animes']\n",
    "        self.disliked_animes = feedback_data['disliked_animes']\n",
    "\n",
    "        print(f\"데이터 로드 완료: {len(self.anime_data)}개 애니메이션, 좋아요 {len(self.liked_animes)}개\")\n",
    "        return True\n",
    "\n",
    "    def load_embedding_model_cpu(self):\n",
    "        \"\"\"CPU에서 임베딩 모델 로드\"\"\"\n",
    "        print(\"카나나 임베딩 모델 로드 중 (CPU)...\")\n",
    "\n",
    "        try:\n",
    "            model_name = \"kakaocorp/kanana-nano-2.1b-embedding\"\n",
    "\n",
    "            self.embedding_tokenizer = AutoTokenizer.from_pretrained(\n",
    "                model_name,\n",
    "                trust_remote_code=True\n",
    "            )\n",
    "\n",
    "            self.embedding_model = AutoModel.from_pretrained(\n",
    "                model_name,\n",
    "                trust_remote_code=True,\n",
    "                torch_dtype=torch.float32  # CPU에서는 float32 사용\n",
    "            )\n",
    "\n",
    "            self.embedding_model.eval()\n",
    "            print(\"임베딩 모델 로드 성공!\")\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"임베딩 모델 로드 실패: {e}\")\n",
    "            return False\n",
    "\n",
    "    def load_instruct_model_cpu(self):\n",
    "        \"\"\"CPU에서 인스트럭트 모델 로드\"\"\"\n",
    "        print(\"카나나 인스트럭트 모델 로드 중 (CPU)...\")\n",
    "\n",
    "        try:\n",
    "            model_name = \"kakaocorp/kanana-nano-2.1b-instruct\"\n",
    "\n",
    "            self.instruct_tokenizer = AutoTokenizer.from_pretrained(\n",
    "                model_name,\n",
    "                trust_remote_code=True\n",
    "            )\n",
    "\n",
    "            # 패딩 토큰 설정\n",
    "            if self.instruct_tokenizer.pad_token is None:\n",
    "                self.instruct_tokenizer.pad_token = self.instruct_tokenizer.eos_token\n",
    "\n",
    "            # CPU에서 최소 설정으로 로드\n",
    "            self.instruct_model = AutoModelForCausalLM.from_pretrained(\n",
    "                model_name,\n",
    "                trust_remote_code=True,\n",
    "                torch_dtype=torch.float32\n",
    "            )\n",
    "\n",
    "            self.instruct_model.eval()\n",
    "            print(\"인스트럭트 모델 로드 성공!\")\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"인스트럭트 모델 로드 실패: {e}\")\n",
    "            return False\n",
    "\n",
    "    def create_simple_prompt(self):\n",
    "        \"\"\"간단한 프롬프트 생성\"\"\"\n",
    "        liked_titles = []\n",
    "        disliked_titles = []\n",
    "\n",
    "        for idx in self.liked_animes[:3]:\n",
    "            title = self.anime_data.iloc[idx].get('title_korean', '제목없음')\n",
    "            genres = self.anime_data.iloc[idx].get('genres', '')\n",
    "            liked_titles.append(f\"{title} ({genres})\")\n",
    "\n",
    "        for idx in self.disliked_animes[:2]:\n",
    "            title = self.anime_data.iloc[idx].get('title_korean', '제목없음')\n",
    "            genres = self.anime_data.iloc[idx].get('genres', '')\n",
    "            disliked_titles.append(f\"{title} ({genres})\")\n",
    "\n",
    "        prompt = f\"\"\"사용자 취향 분석:\n",
    "좋아하는 애니메이션: {', '.join(liked_titles)}\n",
    "싫어하는 애니메이션: {', '.join(disliked_titles)}\n",
    "\n",
    "이 사용자의 애니메이션 취향을 3문장으로 요약해주세요:\"\"\"\n",
    "\n",
    "        return prompt\n",
    "\n",
    "    def generate_taste_analysis(self):\n",
    "        \"\"\"취향 분석 생성\"\"\"\n",
    "        if self.instruct_model is None:\n",
    "            print(\"인스트럭트 모델이 로드되지 않았습니다.\")\n",
    "            return None\n",
    "\n",
    "        prompt = self.create_simple_prompt()\n",
    "        print(f\"프롬프트: {prompt}\")\n",
    "\n",
    "        try:\n",
    "            inputs = self.instruct_tokenizer(\n",
    "                prompt,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                max_length=500\n",
    "            )\n",
    "\n",
    "            print(\"텍스트 생성 중... (시간이 걸릴 수 있습니다)\")\n",
    "            with torch.no_grad():\n",
    "                outputs = self.instruct_model.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=100,\n",
    "                    do_sample=True,\n",
    "                    temperature=0.7,\n",
    "                    pad_token_id=self.instruct_tokenizer.eos_token_id\n",
    "                )\n",
    "\n",
    "            generated = self.instruct_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "            # 프롬프트 이후 부분만 추출\n",
    "            if \"이 사용자의 애니메이션 취향을 3문장으로 요약해주세요:\" in generated:\n",
    "                result = generated.split(\"이 사용자의 애니메이션 취향을 3문장으로 요약해주세요:\")[-1].strip()\n",
    "            else:\n",
    "                result = generated[len(prompt):].strip()\n",
    "\n",
    "            print(f\"생성된 분석: {result}\")\n",
    "            return result if result else \"이 사용자는 다양한 장르의 애니메이션을 즐기는 개성있는 취향을 가지고 있습니다.\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"텍스트 생성 실패: {e}\")\n",
    "            return None\n",
    "\n",
    "    def text_to_embedding(self, text):\n",
    "        \"\"\"텍스트를 임베딩으로 변환\"\"\"\n",
    "        if self.embedding_model is None:\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            inputs = self.embedding_tokenizer(\n",
    "                text,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                max_length=512\n",
    "            )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # 카나나 모델은 pool_mask가 필요함\n",
    "                outputs = self.embedding_model(\n",
    "                    input_ids=inputs['input_ids'],\n",
    "                    attention_mask=inputs['attention_mask'],\n",
    "                    pool_mask=inputs['attention_mask']  # attention_mask와 동일하게 설정\n",
    "                )\n",
    "\n",
    "                # 출력 구조 확인\n",
    "                print(f\"출력 타입: {type(outputs)}\")\n",
    "                print(f\"출력 속성들: {[attr for attr in dir(outputs) if not attr.startswith('_')]}\")\n",
    "\n",
    "                # 여러 가능한 속성들 시도\n",
    "                if hasattr(outputs, 'pooler_output'):\n",
    "                    embedding = outputs.pooler_output\n",
    "                    print(\"pooler_output 사용\")\n",
    "                elif hasattr(outputs, 'last_hidden_state'):\n",
    "                    embedding = outputs.last_hidden_state.mean(dim=1)\n",
    "                    print(\"last_hidden_state 평균 풀링 사용\")\n",
    "                elif hasattr(outputs, 'hidden_states'):\n",
    "                    embedding = outputs.hidden_states[-1].mean(dim=1)\n",
    "                    print(\"마지막 hidden_state 평균 풀링 사용\")\n",
    "                elif hasattr(outputs, 'embeddings'):\n",
    "                    embedding = outputs.embeddings\n",
    "                    print(\"embeddings 직접 사용\")\n",
    "                elif hasattr(outputs, 'sentence_embedding'):\n",
    "                    embedding = outputs.sentence_embedding\n",
    "                    print(\"sentence_embedding 사용\")\n",
    "                else:\n",
    "                    # 출력이 텐서인 경우\n",
    "                    if isinstance(outputs, torch.Tensor):\n",
    "                        embedding = outputs.mean(dim=1) if outputs.dim() > 1 else outputs\n",
    "                        print(\"텐서 직접 처리\")\n",
    "                    else:\n",
    "                        print(f\"알 수 없는 출력 형태: {outputs}\")\n",
    "                        # 첫 번째 속성이 텐서인지 확인\n",
    "                        for attr_name in dir(outputs):\n",
    "                            if not attr_name.startswith('_'):\n",
    "                                attr_value = getattr(outputs, attr_name)\n",
    "                                if isinstance(attr_value, torch.Tensor):\n",
    "                                    print(f\"{attr_name} 속성을 텐서로 사용\")\n",
    "                                    embedding = attr_value.mean(dim=1) if attr_value.dim() > 1 else attr_value\n",
    "                                    break\n",
    "                        else:\n",
    "                            return None\n",
    "\n",
    "            return embedding.numpy().flatten()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"임베딩 변환 실패: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return None\n",
    "\n",
    "    def run_kanana_llm_profile(self):\n",
    "        \"\"\"전체 파이프라인 실행\"\"\"\n",
    "        print(\"=== 단순화된 카나나 LLM 프로필 생성 ===\")\n",
    "\n",
    "        # 1. 데이터 로드\n",
    "        if not self.load_data():\n",
    "            print(\"데이터 로드 실패\")\n",
    "            return False\n",
    "\n",
    "        # 2. 임베딩 모델 로드\n",
    "        if not self.load_embedding_model_cpu():\n",
    "            print(\"임베딩 모델 로드 실패\")\n",
    "            return False\n",
    "\n",
    "        # 3. 인스트럭트 모델 로드\n",
    "        if not self.load_instruct_model_cpu():\n",
    "            print(\"인스트럭트 모델 로드 실패, 키워드 기반으로 대체\")\n",
    "            taste_analysis = \"이 사용자는 액션과 모험 장르를 선호하며, 복잡한 스토리와 판타지 요소를 좋아합니다. 일상물이나 단순한 장르는 선호하지 않는 경향이 있습니다.\"\n",
    "        else:\n",
    "            # 4. 취향 분석 생성\n",
    "            taste_analysis = self.generate_taste_analysis()\n",
    "            if taste_analysis is None:\n",
    "                taste_analysis = \"이 사용자는 다양한 장르의 애니메이션을 즐기는 개성있는 취향을 가지고 있습니다.\"\n",
    "\n",
    "        # 5. 임베딩 변환\n",
    "        print(\"취향 분석을 임베딩으로 변환 중...\")\n",
    "        v_llm_profile = self.text_to_embedding(taste_analysis)\n",
    "\n",
    "        if v_llm_profile is not None:\n",
    "            # 6. 저장\n",
    "            np.savez(\"kanana_llm_profile_simple.npz\",\n",
    "                    v_llm_profile=v_llm_profile,\n",
    "                    taste_analysis=np.array([taste_analysis], dtype=object))\n",
    "\n",
    "            print(f\"카나나 LLM 프로필 생성 성공!\")\n",
    "            print(f\"취향 분석: {taste_analysis}\")\n",
    "            print(f\"벡터 차원: {v_llm_profile.shape}\")\n",
    "            print(f\"벡터 크기: {np.linalg.norm(v_llm_profile):.4f}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"임베딩 변환 실패\")\n",
    "            return False\n",
    "\n",
    "# 실행\n",
    "if __name__ == \"__main__\":\n",
    "    generator = SimpleKananaGenerator()\n",
    "    success = generator.run_kanana_llm_profile()\n",
    "\n",
    "    if success:\n",
    "        print(\"\\n성공! 이제 이 결과를 다른 Task에서 사용할 수 있습니다.\")\n",
    "    else:\n",
    "        print(\"\\n실패했지만, 대체 방법을 사용할 수 있습니다.\")"
   ],
   "id": "872bfeffd542bb98",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 단순화된 카나나 LLM 프로필 생성 ===\n",
      "데이터 로드 완료: 4453개 애니메이션, 좋아요 8개\n",
      "카나나 임베딩 모델 로드 중 (CPU)...\n",
      "임베딩 모델 로드 성공!\n",
      "카나나 인스트럭트 모델 로드 중 (CPU)...\n",
      "인스트럭트 모델 로드 성공!\n",
      "프롬프트: 사용자 취향 분석:\n",
      "좋아하는 애니메이션: 혈액형군 (nan), Re: 제로부터 시작하는 이세계 생활: 빙결의 인연 (코미디|드라마|판타지|심리), 리틀 버스터즈! -리프레인- (드라마|미스터리|초자연)\n",
      "싫어하는 애니메이션: TIGER & BUNNY (nan), 월요일의 타와와 2기 (에치|일상)\n",
      "\n",
      "이 사용자의 애니메이션 취향을 3문장으로 요약해주세요:\n",
      "텍스트 생성 중... (시간이 걸릴 수 있습니다)\n",
      "생성된 분석: 이 사용자는 혈액형군과 리틀 버스터즈 같은 코미디와 드라마, 판타지 장르를 좋아합니다. 또한, 심리적인 요소가 포함된 애니메이션도 즐겨보는 것으로 보입니다. 반면, TIGER & BUNNY와 월요일의 타와와 같은 작품은 피하는 경향이 있습니다.   #애니메이션 #취향 #분석 #혜자 #리프레인\n",
      "취향 분석을 임베딩으로 변환 중...\n",
      "출력 타입: <class 'transformers_modules.kakaocorp.kanana-nano-2.1b-embedding.da6461c30bb974d64ea56912bd23acaca231a70f.modeling_kanana2vec.EmbeddingModelOutput'>\n",
      "출력 속성들: ['clear', 'copy', 'embedding', 'fromkeys', 'get', 'items', 'keys', 'move_to_end', 'pop', 'popitem', 'setdefault', 'to_tuple', 'update', 'values']\n",
      "알 수 없는 출력 형태: EmbeddingModelOutput(embedding=tensor([[-1.1914,  0.0764, -5.4973,  ...,  2.4661, -2.5729,  2.2459]]))\n",
      "embedding 속성을 텐서로 사용\n",
      "카나나 LLM 프로필 생성 성공!\n",
      "취향 분석: 이 사용자는 혈액형군과 리틀 버스터즈 같은 코미디와 드라마, 판타지 장르를 좋아합니다. 또한, 심리적인 요소가 포함된 애니메이션도 즐겨보는 것으로 보입니다. 반면, TIGER & BUNNY와 월요일의 타와와 같은 작품은 피하는 경향이 있습니다.   #애니메이션 #취향 #분석 #혜자 #리프레인\n",
      "벡터 차원: (1,)\n",
      "벡터 크기: 0.1422\n",
      "\n",
      "성공! 이제 이 결과를 다른 Task에서 사용할 수 있습니다.\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-09-08T06:03:56.708078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# 카나나 임베딩 직접 수정 - 출력 구조를 이미 알고 있으므로 바로 구현\n",
    "\n",
    "class DirectKananaEmbedding:\n",
    "    def __init__(self):\n",
    "        \"\"\"직접 카나나 임베딩 구현\"\"\"\n",
    "        self.embedding_tokenizer = None\n",
    "        self.embedding_model = None\n",
    "        self.device = \"cpu\"\n",
    "\n",
    "    def load_kanana_model(self):\n",
    "        \"\"\"카나나 모델 로드\"\"\"\n",
    "        print(\"=== 카나나 모델 로드 ===\")\n",
    "\n",
    "        try:\n",
    "            model_name = \"kakaocorp/kanana-nano-2.1b-embedding\"\n",
    "\n",
    "            self.embedding_tokenizer = AutoTokenizer.from_pretrained(\n",
    "                model_name,\n",
    "                trust_remote_code=True\n",
    "            )\n",
    "\n",
    "            self.embedding_model = AutoModel.from_pretrained(\n",
    "                model_name,\n",
    "                trust_remote_code=True,\n",
    "                torch_dtype=torch.float32\n",
    "            )\n",
    "\n",
    "            self.embedding_model.eval()\n",
    "            print(\"✅ 카나나 모델 로드 성공!\")\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 카나나 모델 로드 실패: {e}\")\n",
    "            return False\n",
    "\n",
    "    def text_to_embedding_kanana(self, text):\n",
    "        \"\"\"\n",
    "        카나나 모델로 텍스트를 임베딩으로 변환\n",
    "        출력 구조: EmbeddingModelOutput(embedding=tensor([1, 1792]))\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # 토크나이저 처리\n",
    "            inputs = self.embedding_tokenizer(\n",
    "                text,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                max_length=512\n",
    "            )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # pool_mask와 함께 모델 호출\n",
    "                outputs = self.embedding_model(\n",
    "                    input_ids=inputs['input_ids'],\n",
    "                    attention_mask=inputs['attention_mask'],\n",
    "                    pool_mask=inputs['attention_mask']  # 필수!\n",
    "                )\n",
    "\n",
    "                # EmbeddingModelOutput.embedding 속성 사용\n",
    "                embedding_tensor = outputs.embedding  # [1, 1792]\n",
    "\n",
    "                # [1, 1792] -> [1792]로 flatten\n",
    "                embedding_vector = embedding_tensor.squeeze(0)  # 첫 번째 차원 제거\n",
    "\n",
    "                # numpy로 변환\n",
    "                embedding_numpy = embedding_vector.numpy()\n",
    "\n",
    "                print(f\"임베딩 성공: {embedding_numpy.shape}, 크기: {np.linalg.norm(embedding_numpy):.4f}\")\n",
    "\n",
    "                return embedding_numpy\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"임베딩 변환 실패: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return None\n",
    "\n",
    "    def test_embedding_function(self):\n",
    "        \"\"\"임베딩 함수 테스트\"\"\"\n",
    "        print(\"\\n=== 임베딩 함수 테스트 ===\")\n",
    "\n",
    "        test_texts = [\n",
    "            \"이 사용자는 액션과 모험 장르를 좋아합니다.\",\n",
    "            \"코미디와 드라마를 선호하는 취향입니다.\",\n",
    "            \"판타지와 SF 애니메이션을 즐겨봅니다.\"\n",
    "        ]\n",
    "\n",
    "        embeddings = []\n",
    "\n",
    "        for i, text in enumerate(test_texts):\n",
    "            print(f\"\\n테스트 {i+1}: '{text}'\")\n",
    "            embedding = self.text_to_embedding_kanana(text)\n",
    "\n",
    "            if embedding is not None:\n",
    "                embeddings.append(embedding)\n",
    "                print(f\"   - 차원: {embedding.shape}\")\n",
    "                print(f\"   - 크기: {np.linalg.norm(embedding):.4f}\")\n",
    "                print(f\"   - 비영 요소: {np.count_nonzero(embedding)}/{len(embedding)}\")\n",
    "            else:\n",
    "                print(\"   - 실패!\")\n",
    "                return False\n",
    "\n",
    "        # 일관성 확인\n",
    "        shapes = [emb.shape for emb in embeddings]\n",
    "        norms = [np.linalg.norm(emb) for emb in embeddings]\n",
    "\n",
    "        print(f\"\\n=== 일관성 검사 ===\")\n",
    "        print(f\"모든 차원 동일: {len(set(shapes)) == 1}\")\n",
    "        print(f\"모든 벡터 유효 (크기 > 0): {all(norm > 1e-6 for norm in norms)}\")\n",
    "        print(f\"차원: {shapes[0] if shapes else 'N/A'}\")\n",
    "        print(f\"평균 크기: {np.mean(norms):.4f}\")\n",
    "\n",
    "        return len(set(shapes)) == 1 and all(norm > 1e-6 for norm in norms)\n",
    "\n",
    "    def create_llm_profile_with_kanana(self):\n",
    "        \"\"\"실제 LLM 프로필 생성\"\"\"\n",
    "        print(\"\\n=== 실제 LLM 프로필 생성 ===\")\n",
    "\n",
    "        # 실제 카나나 인스트럭트가 생성한 취향 분석 텍스트\n",
    "        taste_analysis = \"\"\"이 사용자는 코미디와 드라마, 판타지 장르를 선호하며, 심리적 요소가 포함된 애니메이션을 즐깁니다. 혈액형군과 리프레인, 리틀 버스터즈! 같은 작품을 좋아하며, 미스터리와 초자연적인 요소가 있는 애니메이션도 좋아합니다. 반면, TIGER & BUNNY와 같은 작품이나 월요일의 타와와 같은 에치 장르는 선호하지 않는 것으로 보입니다.\"\"\"\n",
    "\n",
    "        print(f\"취향 분석 텍스트: '{taste_analysis}'\")\n",
    "\n",
    "        # 카나나 임베딩으로 변환\n",
    "        v_llm_profile = self.text_to_embedding_kanana(taste_analysis)\n",
    "\n",
    "        if v_llm_profile is not None:\n",
    "            # 저장\n",
    "            np.savez(\"kanana_llm_profile_fixed.npz\",\n",
    "                    v_llm_profile=v_llm_profile,\n",
    "                    taste_analysis=np.array([taste_analysis], dtype=object),\n",
    "                    method=\"kanana_embedding_direct\")\n",
    "\n",
    "            print(f\"\\n✅ 카나나 LLM 프로필 생성 성공!\")\n",
    "            print(f\"   - 파일: kanana_llm_profile_fixed.npz\")\n",
    "            print(f\"   - 차원: {v_llm_profile.shape}\")\n",
    "            print(f\"   - 크기: {np.linalg.norm(v_llm_profile):.4f}\")\n",
    "            print(f\"   - 방법: kanana_embedding_direct\")\n",
    "\n",
    "            return True\n",
    "        else:\n",
    "            print(\"❌ LLM 프로필 생성 실패\")\n",
    "            return False\n",
    "\n",
    "# 실행\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== 카나나 임베딩 직접 수정 ===\")\n",
    "\n",
    "    embedder = DirectKananaEmbedding()\n",
    "\n",
    "    # 1. 모델 로드\n",
    "    if not embedder.load_kanana_model():\n",
    "        exit(1)\n",
    "\n",
    "    # 2. 임베딩 함수 테스트\n",
    "    if not embedder.test_embedding_function():\n",
    "        print(\"❌ 임베딩 함수 테스트 실패\")\n",
    "        exit(1)\n",
    "\n",
    "    # 3. 실제 LLM 프로필 생성\n",
    "    if embedder.create_llm_profile_with_kanana():\n",
    "        print(f\"\\n🎉 성공! 이제 Task 6에서 'kanana_llm_profile_fixed.npz'를 사용할 수 있습니다!\")\n",
    "        print(f\"Task 6 코드에서 load_path를 'kanana_llm_profile_fixed.npz'로 변경하세요.\")\n",
    "    else:\n",
    "        print(\"❌ 전체 프로세스 실패\")"
   ],
   "id": "4e7e6f03ebc85031",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 카나나 임베딩 직접 수정 ===\n",
      "=== 카나나 모델 로드 ===\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d0b504ff97c6f2ce"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
