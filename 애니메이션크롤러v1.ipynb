{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1) 라이브러리 설치 및 라이브러리 설명\n",
    "\n",
    "- beautifulsoup : BeautifulSoup는 HTML 및 XML 파일을 파싱(Parsing)하는 라이브러리입니다.\n",
    "- request : requests는 HTTP 요청을 보내는 것을 간편하게 만들어주는 라이브러리입니다. 웹 서버에 GET, POST 등의 요청을 보내서 HTML, 이미지, JSON 등의 데이터를 가져오는 데 사용됩니다.\n",
    "- lxml : lxml은 XML 및 HTML 파싱을 위한 빠르고 강력한 라이브러리입니다. BeautifulSoup의 파서(Parser) 중 하나로 자주 사용됩니다."
   ],
   "id": "25db48f8b7392669"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": "!pip -q install requests beautifulsoup4 lxml",
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**참고**: ```-q``` 옵션을 사용한 pip install: 오류나 경고가 발생하지 않는 한, 대부분의 메시지를 출력하지 않습니다. 설치가 완료된 후에는 아무런 메시지가 표시되지 않거나, 최소한의 정보만 출력됩니다.",
   "id": "372822cb6299344e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2) 가져오기",
   "id": "e5842efeb1125359"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "import pprint as pp\n"
   ],
   "id": "6f2a00f317759340",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 3) 대상 URL\n",
    "URL = \"https://anilife.app/content/6750/tab=info\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) StepByStepCrawler/0.1\",\n",
    "    \"Accept-Language\": \"ko-KR,ko;q=0.9,en-US;q=0.8\"\n",
    "}\n",
    "\n",
    "\n",
    "resp = requests.get(URL, headers=headers, timeout=20)\n",
    "print(\"응답 코드:\", resp.status_code)   # 200 나오면 성공\n",
    "print(\"응답 헤더:\")\n",
    "pprint.pprint(dict(resp.headers))\n",
    "print(\"컨텐츠 길이:\", len(resp.text))\n"
   ],
   "id": "7acb6851eb8accc4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "응답 코드는 웹 서버가 클라이언트(브라우저 등)의 요청에 대해 \"무슨 일이 있었는지\" 알려주는 세 자리 숫자입니다. 이 코드들은 첫째 자리에 따라 의미가 분류됩니다.\n",
    "\n",
    "### **1xx: 정보 (Informational)**\n",
    "요청을 받았고, 계속 처리 중이라는 의미입니다.\n",
    "\n",
    "* **100 Continue**: 요청의 일부를 받았고, 나머지도 보내라는 의미입니다.\n",
    "\n",
    "### **2xx: 성공 (Success)**\n",
    "요청이 성공적으로 처리되었음을 나타냅니다.\n",
    "\n",
    "* **200 OK**: **가장 일반적인 성공 코드.** 요청이 성공적으로 완료되었고, 서버가 데이터를 잘 보냈다는 의미입니다.\n",
    "* **201 Created**: 요청이 성공했고, 그 결과로 새로운 리소스(자원)가 생성되었습니다.\n",
    "* **204 No Content**: 요청은 성공했지만, 보낼 데이터가 없습니다. (예: 삭제 요청 후)\n",
    "\n",
    "### **3xx: 리다이렉션 (Redirection)**\n",
    "요청을 완료하려면 추가적인 조치가 필요하다는 의미입니다. 주로 다른 주소로 옮겨졌을 때 사용됩니다.\n",
    "\n",
    "* **301 Moved Permanently**: 요청한 페이지가 **영구적으로** 다른 주소로 옮겨졌습니다.\n",
    "* **304 Not Modified**: 요청한 파일이 변경되지 않았으므로, 캐시된 버전을 사용해도 됩니다.\n",
    "\n",
    "### **4xx: 클라이언트 오류 (Client Error)**\n",
    "클라이언트(요청을 보낸 쪽)의 잘못으로 인해 요청을 처리할 수 없다는 의미입니다.\n",
    "\n",
    "* **400 Bad Request**: 요청 문법이 잘못되었습니다.\n",
    "* **401 Unauthorized**: 인증되지 않은 사용자입니다. 로그인 등이 필요합니다.\n",
    "* **403 Forbidden**: 접근이 금지되었습니다. 권한이 없다는 뜻입니다.\n",
    "* **404 Not Found**: **가장 흔한 오류.** 요청한 페이지를 찾을 수 없습니다. (주소가 잘못되었을 때)\n",
    "* **429 Too Many Requests**: 정해진 시간 안에 너무 많은 요청을 보냈습니다.\n",
    "\n",
    "### **5xx: 서버 오류 (Server Error)**\n",
    "서버의 문제로 인해 요청을 처리할 수 없다는 의미입니다.\n",
    "\n",
    "* **500 Internal Server Error**: 서버에 알 수 없는 오류가 발생했습니다.\n",
    "* **503 Service Unavailable**: 서버가 일시적으로 요청을 처리할 수 없습니다. (서버 점검, 과부하 등)"
   ],
   "id": "5d83f3dfedc7e61d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 4) BeautifulSoup으로 파싱\n",
    "soup = BeautifulSoup(resp.text, \"lxml\")\n",
    "# 간단하게 설명하자면 html 코드를 lxml파서로 객체로 변환합니다"
   ],
   "id": "b9e948bf17700fd7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\n====== HTML 부분 =======\")\n",
    "pprint.pprint(resp.text)"
   ],
   "id": "812aac0d6f63e067",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "korean_title_tag = soup.find('h1', class_='fpUXWby')",
   "id": "4344beac76239db0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pp.pprint(korean_title_tag.text)",
   "id": "8a6bfb440501d797",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "8a581cf8c46dde0d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# japanese_title_section = soup.find('h2', class_='visually-hidden')",
   "id": "36b8555113c88b58",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1. <h2> 태그 안에서 모든 <span> 태그를 찾습니다.\n",
    "span_tags = japanese_title_section.find_all('span')\n",
    "\n",
    "# 2. 각 <span> 태그에서 .text를 사용해 텍스트만 추출합니다.\n",
    "#    List Comprehension을 사용하면 코드가 간결해집니다.\n",
    "titles = [span.text for span in span_tags]"
   ],
   "id": "b4be3699af7f1727",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pp.pprint(titles)",
   "id": "63329ca98245c51d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "japanese_title = titles[0]\n",
    "english_title = titles[1]"
   ],
   "id": "a090dd955fee1894",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"일본어 제목은:\", japanese_title)\n",
    "print(\"영어 제목은\", english_title)"
   ],
   "id": "7cb5c793d23b2410",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "quarter_info = soup.find('div', class_='nBnfiIh')",
   "id": "1ce7fad101b240ba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pp.pprint(quarter_info.text)",
   "id": "e82b2679c373e773",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "year = \"NULL\"\n",
    "quarter = \"NULL\"\n",
    "broadcast_format = \"NULL\"\n",
    "full_format = quarter_info.text.strip()\n",
    "print(full_format)\n",
    "\n",
    "# 매체부터 쪼개고\n",
    "parts = full_format.split(' · ')\n",
    "print(parts)\n",
    "#년도를 쪼개자\n",
    "\n",
    "season_info = parts[0].split(' ')\n",
    "year = season_info[0]\n",
    "print(year)\n",
    "\n",
    "quarter = season_info[1]\n",
    "print(quarter)\n",
    "\n"
   ],
   "id": "a196d0279222f3c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "genre_tags = soup.select('a[rel=\"genre\"]')\n",
   "id": "3bca171655f15e5b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "genre_list = [tag.text.strip() for tag in genre_tags]",
   "id": "9ede7dec5c869efa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pp.pprint(genre_list)",
   "id": "4e504564d459837b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "7b29c59153132731",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T07:33:04.037731Z",
     "start_time": "2025-09-05T07:33:03.199570Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 라이브러리 설치 및 가져오기\n",
    "# !pip -q install requests beautifulsoup4 lxml\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "from typing import Dict, List, Optional\n",
    "import pprint as pp\n",
    "\n",
    "class AnilifeScraper:\n",
    "    def __init__(self):\n",
    "        self.headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) StepByStepCrawler/0.1\",\n",
    "            \"Accept-Language\": \"ko-KR,ko;q=0.9,en-US;q=0.8\"\n",
    "        }\n",
    "\n",
    "    def scrape_anime_info(self, url: str) -> Dict:\n",
    "        \"\"\"애니메이션 정보를 크롤링하는 메인 함수\"\"\"\n",
    "        try:\n",
    "            # URL 정규화 - info 탭으로 변경\n",
    "            if \"tab=info\" not in url:\n",
    "                if \"?\" in url:\n",
    "                    url = url.split(\"?\")[0] + \"?tab=info\"\n",
    "                else:\n",
    "                    url = url + \"?tab=info\"\n",
    "\n",
    "            # 웹페이지 요청\n",
    "            resp = requests.get(url, headers=self.headers, timeout=20)\n",
    "            print(f\"응답 코드: {resp.status_code}\")\n",
    "            print(f\"최종 URL: {url}\")\n",
    "\n",
    "            if resp.status_code != 200:\n",
    "                return {\"error\": f\"HTTP {resp.status_code} 에러\"}\n",
    "\n",
    "            # BeautifulSoup으로 파싱\n",
    "            soup = BeautifulSoup(resp.text, \"lxml\")\n",
    "\n",
    "            # Nuxt.js 데이터 추출\n",
    "            nuxt_data = self.extract_nuxt_data(resp.text)\n",
    "\n",
    "            # 애니메이션 정보 추출\n",
    "            anime_info = {\n",
    "                \"title\": self.extract_titles(soup, nuxt_data),\n",
    "                \"basic_info\": self.extract_basic_info(soup, nuxt_data),\n",
    "                \"genres\": self.extract_genres(soup, nuxt_data),\n",
    "                \"tags\": self.extract_tags(soup, nuxt_data),\n",
    "                \"synopsis\": self.extract_synopsis(soup, nuxt_data),\n",
    "                \"characters_voice_actors\": self.extract_characters_and_voice_actors(soup, nuxt_data),\n",
    "                \"production_info\": self.extract_production_info(soup, nuxt_data)\n",
    "            }\n",
    "\n",
    "            return anime_info\n",
    "\n",
    "        except requests.RequestException as e:\n",
    "            return {\"error\": f\"요청 에러: {str(e)}\"}\n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"파싱 에러: {str(e)}\"}\n",
    "\n",
    "    def extract_nuxt_data(self, html_content: str) -> Dict:\n",
    "        \"\"\"HTML에서 Nuxt.js __NUXT__ 데이터 추출\"\"\"\n",
    "        try:\n",
    "            # __NUXT__ 데이터가 있는 부분 찾기\n",
    "            pattern = r'window\\.__NUXT__=\\(function\\([^)]*\\)\\{return (.+?)\\}\\)\\([^)]+\\)'\n",
    "            match = re.search(pattern, html_content, re.DOTALL)\n",
    "\n",
    "            if match:\n",
    "                json_str = match.group(1)\n",
    "\n",
    "                # JavaScript 함수 매개변수를 실제 값으로 치환\n",
    "                # HTML에서 실제 사용되는 매개변수 값 확인\n",
    "                replacements = {\n",
    "                    r'\\ba\\b': 'false',\n",
    "                    r'\\bb\\b': '1',\n",
    "                    r'\\bc\\b': 'true',\n",
    "                    r'\\bd\\b': 'null',\n",
    "                    r'\\be\\b': '\"system\"',\n",
    "                    r'\\bf\\b': '\"https://anilife.app\"',\n",
    "                    r'\\bg\\b': '\"N/A\"'\n",
    "                }\n",
    "\n",
    "                for pattern, value in replacements.items():\n",
    "                    json_str = re.sub(pattern, value, json_str)\n",
    "\n",
    "                # JSON 파싱\n",
    "                data = json.loads(json_str)\n",
    "                return data\n",
    "\n",
    "            return {}\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Nuxt 데이터 추출 에러: {e}\")\n",
    "            return {}\n",
    "\n",
    "    def extract_titles(self, soup: BeautifulSoup, nuxt_data: Dict) -> Dict[str, str]:\n",
    "        \"\"\"제목들 추출 (한국어, 일본어, 영어)\"\"\"\n",
    "        titles = {\"korean\": \"\", \"japanese\": \"\", \"english\": \"\"}\n",
    "\n",
    "        # Nuxt 데이터에서 우선 추출 (더 정확함)\n",
    "        try:\n",
    "            content_detail = nuxt_data.get('pinia', {}).get('content', {}).get('contentDetail', {})\n",
    "            name_data = content_detail.get('name', {})\n",
    "\n",
    "            if name_data.get('kr'):\n",
    "                titles[\"korean\"] = name_data['kr']\n",
    "            if name_data.get('jp'):\n",
    "                titles[\"japanese\"] = name_data['jp']\n",
    "            if name_data.get('en'):\n",
    "                titles[\"english\"] = name_data['en']\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # HTML에서도 확인\n",
    "        if not titles[\"korean\"]:\n",
    "            korean_title_tag = soup.find('h1', class_='fpUXWby')\n",
    "            if korean_title_tag:\n",
    "                titles[\"korean\"] = korean_title_tag.get_text(strip=True).replace(\" 에피소드\", \"\").replace(\"정보\", \"\")\n",
    "\n",
    "        if not titles[\"japanese\"] or not titles[\"english\"]:\n",
    "            japanese_title_section = soup.find('h2', class_='visually-hidden')\n",
    "            if japanese_title_section:\n",
    "                span_tags = japanese_title_section.find_all('span')\n",
    "                if len(span_tags) >= 2:\n",
    "                    if not titles[\"japanese\"]:\n",
    "                        titles[\"japanese\"] = span_tags[0].get_text(strip=True)\n",
    "                    if not titles[\"english\"]:\n",
    "                        titles[\"english\"] = span_tags[1].get_text(strip=True)\n",
    "\n",
    "        return titles\n",
    "\n",
    "    def extract_basic_info(self, soup: BeautifulSoup, nuxt_data: Dict) -> Dict[str, str]:\n",
    "        \"\"\"기본 정보 추출 (방영 시기, 포맷 등)\"\"\"\n",
    "        basic_info = {}\n",
    "\n",
    "        # Nuxt 데이터에서 우선 추출\n",
    "        try:\n",
    "            content_detail = nuxt_data.get('pinia', {}).get('content', {}).get('contentDetail', {})\n",
    "\n",
    "            if content_detail.get('format'):\n",
    "                basic_info[\"format\"] = content_detail['format']\n",
    "\n",
    "            if content_detail.get('status'):\n",
    "                basic_info[\"status\"] = content_detail['status']\n",
    "\n",
    "            season_data = content_detail.get('season', {})\n",
    "            if season_data:\n",
    "                basic_info[\"year\"] = str(season_data.get('year', ''))\n",
    "                basic_info[\"quarter\"] = f\"{season_data.get('quarter', '')}분기\"\n",
    "\n",
    "            if content_detail.get('startDate'):\n",
    "                basic_info[\"start_date\"] = content_detail['startDate']\n",
    "\n",
    "            if content_detail.get('endDate') and content_detail['endDate'] != \"null\":\n",
    "                basic_info[\"end_date\"] = content_detail['endDate']\n",
    "\n",
    "            if content_detail.get('totalEpisode') and content_detail['totalEpisode'] != \"N/A\":\n",
    "                basic_info[\"total_episodes\"] = str(content_detail['totalEpisode'])\n",
    "\n",
    "            if content_detail.get('duration') and content_detail['duration'] != \"N/A\":\n",
    "                basic_info[\"duration\"] = str(content_detail['duration'])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Nuxt 기본 정보 추출 에러: {e}\")\n",
    "\n",
    "        # HTML에서 방영 시기 정보 (Nuxt에서 못 찾은 경우)\n",
    "        if not basic_info.get('year') or not basic_info.get('quarter'):\n",
    "            quarter_info = soup.find('div', class_='nBnfiIh')\n",
    "            if quarter_info:\n",
    "                full_format = quarter_info.get_text(strip=True)\n",
    "                parts = full_format.split(' · ')\n",
    "\n",
    "                if len(parts) >= 2:\n",
    "                    if not basic_info.get('format'):\n",
    "                        basic_info[\"format\"] = parts[1]\n",
    "\n",
    "                    season_info = parts[0].split(' ')\n",
    "                    if len(season_info) >= 2:\n",
    "                        if not basic_info.get('year'):\n",
    "                            basic_info[\"year\"] = season_info[0]\n",
    "                        if not basic_info.get('quarter'):\n",
    "                            basic_info[\"quarter\"] = season_info[1]\n",
    "\n",
    "        return basic_info\n",
    "\n",
    "    def extract_genres(self, soup: BeautifulSoup, nuxt_data: Dict) -> List[str]:\n",
    "        \"\"\"장르 정보 추출\"\"\"\n",
    "        genres = []\n",
    "\n",
    "        # Nuxt 데이터에서 우선 추출\n",
    "        try:\n",
    "            content_detail = nuxt_data.get('pinia', {}).get('content', {}).get('contentDetail', {})\n",
    "            nuxt_genres = content_detail.get('genre', [])\n",
    "            if nuxt_genres:\n",
    "                genres = nuxt_genres\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # HTML에서도 확인 (Nuxt에서 못 찾은 경우)\n",
    "        if not genres:\n",
    "            genre_tags = soup.select('a[rel=\"genre\"]')\n",
    "            genres = [tag.get_text(strip=True) for tag in genre_tags]\n",
    "\n",
    "        return genres\n",
    "\n",
    "    def extract_tags(self, soup: BeautifulSoup, nuxt_data: Dict) -> List[str]:\n",
    "        \"\"\"태그 정보 추출\"\"\"\n",
    "        tags = []\n",
    "\n",
    "        # Nuxt 데이터에서 우선 추출\n",
    "        try:\n",
    "            content_detail = nuxt_data.get('pinia', {}).get('content', {}).get('contentDetail', {})\n",
    "            tag_data = content_detail.get('tag', [])\n",
    "\n",
    "            for tag_item in tag_data:\n",
    "                if isinstance(tag_item, dict) and tag_item.get('name'):\n",
    "                    tag_name = tag_item['name']\n",
    "                    if tag_item.get('spoiler'):\n",
    "                        tag_name += \" (스포일러)\"\n",
    "                    tags.append(tag_name)\n",
    "                elif isinstance(tag_item, str):\n",
    "                    tags.append(tag_item)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Nuxt 태그 추출 에러: {e}\")\n",
    "\n",
    "        # HTML에서도 확인 - 실제 HTML 구조에 맞게 수정\n",
    "        if not tags:\n",
    "            # 작품 태그 섹션 찾기\n",
    "            tag_section = None\n",
    "\n",
    "            # 방법 1: h2 텍스트로 섹션 찾기\n",
    "            for h2 in soup.find_all('h2', class_='wXeFmvm'):\n",
    "                if '작품 태그' in h2.get_text():\n",
    "                    tag_section = h2.find_parent('section')\n",
    "                    break\n",
    "\n",
    "            if tag_section:\n",
    "                # 태그 컨테이너 찾기\n",
    "                tag_container = tag_section.find('div', class_='-mMZ9fV')\n",
    "                if tag_container:\n",
    "                    # a 태그들 찾기\n",
    "                    tag_links = tag_container.find_all('a', class_='MbHceQh')\n",
    "                    for link in tag_links:\n",
    "                        span = link.find('span')\n",
    "                        if span:\n",
    "                            tag_text = span.get_text(strip=True).replace('#', '')\n",
    "                            # 스포일러 태그 확인 (class에 iYz6NWc가 있으면 스포일러)\n",
    "                            if 'iYz6NWc' in span.get('class', []):\n",
    "                                tag_text += \" (스포일러)\"\n",
    "                            tags.append(tag_text)\n",
    "\n",
    "        return tags\n",
    "\n",
    "    def extract_synopsis(self, soup: BeautifulSoup, nuxt_data: Dict) -> str:\n",
    "        \"\"\"줄거리 추출\"\"\"\n",
    "        # Nuxt 데이터에서 우선 추출\n",
    "        try:\n",
    "            content_detail = nuxt_data.get('pinia', {}).get('content', {}).get('contentDetail', {})\n",
    "            description = content_detail.get('description', '')\n",
    "            if description and description != \"등록된 줄거리가 없습니다.\":\n",
    "                return description\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # HTML에서 줄거리\n",
    "        description_div = soup.find('div', class_='bnHDzeE')\n",
    "        if description_div:\n",
    "            synopsis = description_div.get_text(strip=True)\n",
    "            if synopsis and synopsis != \"등록된 줄거리가 없습니다.\":\n",
    "                return synopsis\n",
    "\n",
    "        return \"등록된 줄거리가 없습니다.\"\n",
    "\n",
    "    def extract_characters_and_voice_actors(self, soup: BeautifulSoup, nuxt_data: Dict) -> List[Dict]:\n",
    "        \"\"\"캐릭터 및 성우 정보 추출\"\"\"\n",
    "        characters = []\n",
    "\n",
    "        # HTML에서 캐릭터 카드 찾기\n",
    "        character_cards = soup.find_all('div', class_='otjBFjd')\n",
    "\n",
    "        for card in character_cards:\n",
    "            # 캐릭터 정보 (왼쪽)\n",
    "            character_div = card.find('div', class_='OuXf8uf')\n",
    "            # 성우 정보 (오른쪽)\n",
    "            voice_actor_link = card.find('a')\n",
    "\n",
    "            character_info = {}\n",
    "\n",
    "            # 캐릭터 이름과 역할 추출\n",
    "            if character_div:\n",
    "                name_elem = character_div.find('div', class_='iO6bs1d')\n",
    "                role_elem = character_div.find('div', class_='_99DZmqJ')\n",
    "\n",
    "                if name_elem:\n",
    "                    character_info['character_name'] = name_elem.get_text(strip=True)\n",
    "                if role_elem:\n",
    "                    character_info['character_role'] = role_elem.get_text(strip=True)\n",
    "\n",
    "                # data-original-title 속성도 확인\n",
    "                if character_div.get('data-original-title'):\n",
    "                    if not character_info.get('character_name'):\n",
    "                        character_info['character_name'] = character_div['data-original-title']\n",
    "\n",
    "            # 성우 이름 추출\n",
    "            if voice_actor_link:\n",
    "                voice_actor_div = voice_actor_link.find('div', class_='_0fu6hck')\n",
    "                if voice_actor_div:\n",
    "                    voice_name_elem = voice_actor_div.find('div', class_='iO6bs1d')\n",
    "                    if voice_name_elem:\n",
    "                        character_info['voice_actor'] = voice_name_elem.get_text(strip=True)\n",
    "\n",
    "                    # title 속성도 확인\n",
    "                    if voice_actor_div.get('title'):\n",
    "                        if not character_info.get('voice_actor'):\n",
    "                            character_info['voice_actor'] = voice_actor_div['title']\n",
    "\n",
    "            if character_info:\n",
    "                characters.append(character_info)\n",
    "\n",
    "        return characters\n",
    "\n",
    "    def extract_production_info(self, soup: BeautifulSoup, nuxt_data: Dict) -> Dict[str, str]:\n",
    "        \"\"\"제작 정보 추출\"\"\"\n",
    "        production_info = {}\n",
    "\n",
    "        # HTML에서 제작 정보 추출\n",
    "        production_section = soup.find('div', class_='_1coMKET -HW4ChD')\n",
    "\n",
    "        if production_section:\n",
    "            # 제작진 링크들 찾기\n",
    "            production_links = production_section.find_all('a', class_='_2hRLd-G')\n",
    "\n",
    "            for link in production_links:\n",
    "                staff_div = link.find('div', class_='OuXf8uf')\n",
    "\n",
    "                if staff_div:\n",
    "                    name_elem = staff_div.find('div', class_='iO6bs1d')\n",
    "                    role_elem = staff_div.find('div', class_='_99DZmqJ')\n",
    "\n",
    "                    if name_elem and role_elem:\n",
    "                        name = name_elem.get_text(strip=True)\n",
    "                        role = role_elem.get_text(strip=True)\n",
    "\n",
    "                        # 역할별로 정리\n",
    "                        if role not in production_info:\n",
    "                            production_info[role] = []\n",
    "\n",
    "                        if isinstance(production_info[role], list):\n",
    "                            production_info[role].append(name)\n",
    "                        else:\n",
    "                            production_info[role] = [production_info[role], name]\n",
    "\n",
    "                    # title 속성도 확인\n",
    "                    if staff_div.get('title'):\n",
    "                        if not name_elem:\n",
    "                            name = staff_div['title']\n",
    "                            if role_elem:\n",
    "                                role = role_elem.get_text(strip=True)\n",
    "                                if role not in production_info:\n",
    "                                    production_info[role] = name\n",
    "\n",
    "        # 리스트를 문자열로 변환\n",
    "        for role, names in production_info.items():\n",
    "            if isinstance(names, list):\n",
    "                production_info[role] = ', '.join(names)\n",
    "\n",
    "        return production_info\n",
    "\n",
    "    def print_results(self, anime_info: Dict):\n",
    "        \"\"\"결과를 보기 좋게 출력\"\"\"\n",
    "        print(\"=\" * 80)\n",
    "        print(\"🎬 애니메이션 정보 크롤링 결과\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "        # 제목 정보\n",
    "        titles = anime_info.get('title', {})\n",
    "        print(f\"\\n📺 제목:\")\n",
    "        if titles.get('korean'):\n",
    "            print(f\"  • 한국어: {titles['korean']}\")\n",
    "        if titles.get('japanese'):\n",
    "            print(f\"  • 일본어: {titles['japanese']}\")\n",
    "        if titles.get('english'):\n",
    "            print(f\"  • 영어: {titles['english']}\")\n",
    "\n",
    "        # 기본 정보\n",
    "        basic_info = anime_info.get('basic_info', {})\n",
    "        if basic_info:\n",
    "            print(f\"\\n📋 기본 정보:\")\n",
    "            for key, value in basic_info.items():\n",
    "                print(f\"  • {key}: {value}\")\n",
    "\n",
    "        # 장르\n",
    "        genres = anime_info.get('genres', [])\n",
    "        if genres:\n",
    "            print(f\"\\n🎭 장르: {', '.join(genres)}\")\n",
    "\n",
    "        # 태그\n",
    "        tags = anime_info.get('tags', [])\n",
    "        if tags:\n",
    "            print(f\"\\n🏷️ 태그:\")\n",
    "            for tag in tags[:10]:  # 처음 10개만 표시\n",
    "                print(f\"  • {tag}\")\n",
    "            if len(tags) > 10:\n",
    "                print(f\"  • ... 총 {len(tags)}개 태그\")\n",
    "\n",
    "        # 줄거리\n",
    "        synopsis = anime_info.get('synopsis', '')\n",
    "        if synopsis:\n",
    "            print(f\"\\n📖 줄거리:\\n{synopsis}\")\n",
    "\n",
    "        # 캐릭터 & 성우\n",
    "        characters = anime_info.get('characters_voice_actors', [])\n",
    "        if characters:\n",
    "            print(f\"\\n🎭 캐릭터 & 성우:\")\n",
    "            for char in characters:\n",
    "                char_name = char.get('character_name', 'N/A')\n",
    "                char_role = char.get('character_role', 'N/A')\n",
    "                voice_actor = char.get('voice_actor', '')\n",
    "\n",
    "                if voice_actor:\n",
    "                    print(f\"  • {char_name} ({char_role}) - 성우: {voice_actor}\")\n",
    "                else:\n",
    "                    print(f\"  • {char_name} - {char_role}\")\n",
    "\n",
    "        # 제작 정보\n",
    "        production = anime_info.get('production_info', {})\n",
    "        if production:\n",
    "            print(f\"\\n🏭 제작 정보:\")\n",
    "            for key, value in production.items():\n",
    "                print(f\"  • {key}: {value}\")\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# 사용 예제\n",
    "if __name__ == \"__main__\":\n",
    "    scraper = AnilifeScraper()\n",
    "\n",
    "    # 대상 URL들 (작품 정보 탭으로 확실히 이동)\n",
    "    urls = [\n",
    "        \"https://anilife.app/content/101?tab=info\"\n",
    "    ]\n",
    "\n",
    "    for url in urls:\n",
    "        print(f\"\\n크롤링 시작: {url}\")\n",
    "        anime_data = scraper.scrape_anime_info(url)\n",
    "\n",
    "        if \"error\" in anime_data:\n",
    "            print(f\"에러 발생: {anime_data['error']}\")\n",
    "        else:\n",
    "            scraper.print_results(anime_data)\n",
    "\n",
    "            # JSON 형태로도 출력\n",
    "            print(f\"\\nJSON 데이터:\")\n",
    "            pp.pprint(anime_data)\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 50 + \"\\n\")"
   ],
   "id": "f57ad4c47dbfebe8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "크롤링 시작: https://anilife.app/content/101?tab=info\n",
      "응답 코드: 200\n",
      "최종 URL: https://anilife.app/content/101?tab=info\n",
      "================================================================================\n",
      "🎬 애니메이션 정보 크롤링 결과\n",
      "================================================================================\n",
      "\n",
      "📺 제목:\n",
      "  • 한국어: 원피스\n",
      "  • 일본어: ONE PIECE\n",
      "  • 영어: ONE PIECE\n",
      "\n",
      "🎭 장르: 액션, 모험, 코미디, 드라마, 판타지\n",
      "\n",
      "🏷️ 태그:\n",
      "  • 해적\n",
      "  • 여행\n",
      "  • 앙상블 캐스트\n",
      "  • 소년 만화\n",
      "  • 슈퍼 파워\n",
      "  • 찾은 가족\n",
      "  • 남성 주인공\n",
      "  • 때림 개그\n",
      "  • 비극\n",
      "  • 음모\n",
      "  • ... 총 71개 태그\n",
      "\n",
      "📖 줄거리:\n",
      "부-명성-힘⋯. 한때 이 세상의 모든 것을 손에 넣은 사나이. 「해적왕 골드 로저」그가 죽음을 앞두고 남긴 한마디는⋯ 전세계 사람들을 바다로 향하게 만들었다.\"내 보물 말이냐? 원한다면 주도록 하지. 잘 찾아봐. 이 세상의 모든 것을 거기에 두고 왔으니까.\"세상은 대해적시대를 맞는다.\n",
      "\n",
      "🎭 캐릭터 & 성우:\n",
      "  • 몽키 D. 루피 (주연) - 성우: 타나카 마유미\n",
      "  • 니코 로빈 (주연) - 성우: 야마구치 유리코\n",
      "  • 롤로노아 조로 (주연) - 성우: 나카이 카즈야\n",
      "  • 롤로노아 조로 (주연) - 성우: 우라와 메구미\n",
      "  • 프랑키 (주연) - 성우: 야오 이치키\n",
      "  • 상디 (주연) - 성우: 히라타 히로아키\n",
      "\n",
      "🏭 제작 정보:\n",
      "  • 원작자: 오다 에이치로\n",
      "  • 애니메이션 제작: 토에이 애니메이션, TAP, 매직 버스, 무시 프로덕션, 스튜디오 거츠, 아사히 프로덕션, 퍼니메이션, 후지 TV, 4키즈 엔터테인먼트, 아사츠 DK, 에이벡스 픽처스\n",
      "  • 각본가: 나카야마 토모히로, 무카미 준키, 타나카 히토시, 야마구치 료우타, 스가 요시유키, 시마다 미츠루\n",
      "\n",
      "================================================================================\n",
      "\n",
      "JSON 데이터:\n",
      "{'basic_info': {},\n",
      " 'characters_voice_actors': [{'character_name': '몽키 D. 루피',\n",
      "                              'character_role': '주연',\n",
      "                              'voice_actor': '타나카 마유미'},\n",
      "                             {'character_name': '니코 로빈',\n",
      "                              'character_role': '주연',\n",
      "                              'voice_actor': '야마구치 유리코'},\n",
      "                             {'character_name': '롤로노아 조로',\n",
      "                              'character_role': '주연',\n",
      "                              'voice_actor': '나카이 카즈야'},\n",
      "                             {'character_name': '롤로노아 조로',\n",
      "                              'character_role': '주연',\n",
      "                              'voice_actor': '우라와 메구미'},\n",
      "                             {'character_name': '프랑키',\n",
      "                              'character_role': '주연',\n",
      "                              'voice_actor': '야오 이치키'},\n",
      "                             {'character_name': '상디',\n",
      "                              'character_role': '주연',\n",
      "                              'voice_actor': '히라타 히로아키'}],\n",
      " 'genres': ['액션', '모험', '코미디', '드라마', '판타지'],\n",
      " 'production_info': {'각본가': '나카야마 토모히로, 무카미 준키, 타나카 히토시, 야마구치 료우타, 스가 요시유키, '\n",
      "                            '시마다 미츠루',\n",
      "                     '애니메이션 제작': '토에이 애니메이션, TAP, 매직 버스, 무시 프로덕션, 스튜디오 거츠, 아사히 '\n",
      "                                 '프로덕션, 퍼니메이션, 후지 TV, 4키즈 엔터테인먼트, 아사츠 DK, 에이벡스 '\n",
      "                                 '픽처스',\n",
      "                     '원작자': '오다 에이치로'},\n",
      " 'synopsis': '부-명성-힘⋯. 한때 이 세상의 모든 것을 손에 넣은 사나이. 「해적왕 골드 로저」그가 죽음을 앞두고 남긴 '\n",
      "             '한마디는⋯ 전세계 사람들을 바다로 향하게 만들었다.\"내 보물 말이냐? 원한다면 주도록 하지. 잘 찾아봐. 이 세상의 '\n",
      "             '모든 것을 거기에 두고 왔으니까.\"세상은 대해적시대를 맞는다.',\n",
      " 'tags': ['해적',\n",
      "          '여행',\n",
      "          '앙상블 캐스트',\n",
      "          '소년 만화',\n",
      "          '슈퍼 파워',\n",
      "          '찾은 가족',\n",
      "          '남성 주인공',\n",
      "          '때림 개그',\n",
      "          '비극',\n",
      "          '음모',\n",
      "          '선박',\n",
      "          '시간 건너뛰기',\n",
      "          '노예 제도',\n",
      "          '정치',\n",
      "          '범죄',\n",
      "          '도망자',\n",
      "          '전쟁',\n",
      "          '디스토피아',\n",
      "          '신들',\n",
      "          '잃어버린 문명',\n",
      "          '검술',\n",
      "          '음식',\n",
      "          '의학',\n",
      "          '감옥',\n",
      "          '사무라이',\n",
      "          '변신',\n",
      "          '괴물 소년',\n",
      "          '사이보그',\n",
      "          '로봇',\n",
      "          '변신',\n",
      "          '인공 지능',\n",
      "          '주로 어른 캐스트',\n",
      "          '동물',\n",
      "          '안티 히어로',\n",
      "          '성장기',\n",
      "          '총',\n",
      "          '사막',\n",
      "          '스켈레톤',\n",
      "          '기차',\n",
      "          '시대착오성',\n",
      "          '결혼',\n",
      "          '포스트 아포칼립틱',\n",
      "          '인간화',\n",
      "          '용',\n",
      "          '간첩',\n",
      "          '요정',\n",
      "          '괴물 소녀',\n",
      "          '철학',\n",
      "          '마약',\n",
      "          '무성애',\n",
      "          '암살자',\n",
      "          '클론',\n",
      "          '여성 주인공',\n",
      "          '쿠데레',\n",
      "          '입양',\n",
      "          '성별 변환',\n",
      "          '닌자',\n",
      "          '복수',\n",
      "          '천사',\n",
      "          '인어',\n",
      "          '배틀 로얄',\n",
      "          'CGI',\n",
      "          '시간 조작',\n",
      "          '뮤지컬',\n",
      "          'LGBTQ+ 주제',\n",
      "          '여성 하렘',\n",
      "          '신체 교환',\n",
      "          '좀비',\n",
      "          '짝사랑',\n",
      "          '무채색',\n",
      "          '연기'],\n",
      " 'title': {'english': 'ONE PIECE', 'japanese': 'ONE PIECE', 'korean': '원피스'}}\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T07:41:21.162128Z",
     "start_time": "2025-09-05T07:36:26.064154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "import csv\n",
    "import time\n",
    "from typing import Dict, List, Optional\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from threading import Lock\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# 로깅 설정\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('anilife_scraping.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "class AnilifeScraper:\n",
    "    def __init__(self):\n",
    "        self.headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) StepByStepCrawler/0.1\",\n",
    "            \"Accept-Language\": \"ko-KR,ko;q=0.9,en-US;q=0.8\"\n",
    "        }\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update(self.headers)\n",
    "\n",
    "    def scrape_anime_info(self, url: str) -> Dict:\n",
    "        \"\"\"애니메이션 정보를 크롤링하는 메인 함수\"\"\"\n",
    "        try:\n",
    "            # URL 정규화 - info 탭으로 변경\n",
    "            if \"tab=info\" not in url:\n",
    "                if \"?\" in url:\n",
    "                    url = url.split(\"?\")[0] + \"?tab=info\"\n",
    "                else:\n",
    "                    url = url + \"?tab=info\"\n",
    "\n",
    "            # 웹페이지 요청\n",
    "            resp = self.session.get(url, timeout=20)\n",
    "\n",
    "            if resp.status_code != 200:\n",
    "                return {\"error\": f\"HTTP {resp.status_code} 에러\", \"url\": url}\n",
    "\n",
    "            # BeautifulSoup으로 파싱\n",
    "            soup = BeautifulSoup(resp.text, \"lxml\")\n",
    "\n",
    "            # Nuxt.js 데이터 추출\n",
    "            nuxt_data = self.extract_nuxt_data(resp.text)\n",
    "\n",
    "            # 애니메이션 정보 추출\n",
    "            anime_info = {\n",
    "                \"url\": url,\n",
    "                \"id\": int(re.search(r'/content/(\\d+)', url).group(1)),\n",
    "                \"title\": self.extract_titles(soup, nuxt_data),\n",
    "                \"basic_info\": self.extract_basic_info(soup, nuxt_data),\n",
    "                \"genres\": self.extract_genres(soup, nuxt_data),\n",
    "                \"tags\": self.extract_tags(soup, nuxt_data),\n",
    "                \"synopsis\": self.extract_synopsis(soup, nuxt_data),\n",
    "                \"characters_voice_actors\": self.extract_characters_and_voice_actors(soup, nuxt_data),\n",
    "                \"production_info\": self.extract_production_info(soup, nuxt_data)\n",
    "            }\n",
    "\n",
    "            return anime_info\n",
    "\n",
    "        except requests.RequestException as e:\n",
    "            return {\"error\": f\"요청 에러: {str(e)}\", \"url\": url}\n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"파싱 에러: {str(e)}\", \"url\": url}\n",
    "\n",
    "    def extract_nuxt_data(self, html_content: str) -> Dict:\n",
    "        \"\"\"HTML에서 Nuxt.js __NUXT__ 데이터 추출\"\"\"\n",
    "        try:\n",
    "            pattern = r'window\\.__NUXT__=\\(function\\([^)]*\\)\\{return (.+?)\\}\\)\\([^)]+\\)'\n",
    "            match = re.search(pattern, html_content, re.DOTALL)\n",
    "\n",
    "            if match:\n",
    "                json_str = match.group(1)\n",
    "\n",
    "                replacements = {\n",
    "                    r'\\ba\\b': 'false',\n",
    "                    r'\\bb\\b': '1',\n",
    "                    r'\\bc\\b': 'true',\n",
    "                    r'\\bd\\b': 'null',\n",
    "                    r'\\be\\b': '\"system\"',\n",
    "                    r'\\bf\\b': '\"https://anilife.app\"',\n",
    "                    r'\\bg\\b': '\"N/A\"'\n",
    "                }\n",
    "\n",
    "                for pattern, value in replacements.items():\n",
    "                    json_str = re.sub(pattern, value, json_str)\n",
    "\n",
    "                data = json.loads(json_str)\n",
    "                return data\n",
    "\n",
    "            return {}\n",
    "\n",
    "        except Exception:\n",
    "            return {}\n",
    "\n",
    "    def extract_titles(self, soup: BeautifulSoup, nuxt_data: Dict) -> Dict[str, str]:\n",
    "        \"\"\"제목들 추출 (한국어, 일본어, 영어)\"\"\"\n",
    "        titles = {\"korean\": \"\", \"japanese\": \"\", \"english\": \"\"}\n",
    "\n",
    "        try:\n",
    "            content_detail = nuxt_data.get('pinia', {}).get('content', {}).get('contentDetail', {})\n",
    "            name_data = content_detail.get('name', {})\n",
    "\n",
    "            if name_data.get('kr'):\n",
    "                titles[\"korean\"] = name_data['kr']\n",
    "            if name_data.get('jp'):\n",
    "                titles[\"japanese\"] = name_data['jp']\n",
    "            if name_data.get('en'):\n",
    "                titles[\"english\"] = name_data['en']\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        if not titles[\"korean\"]:\n",
    "            korean_title_tag = soup.find('h1', class_='fpUXWby')\n",
    "            if korean_title_tag:\n",
    "                titles[\"korean\"] = korean_title_tag.get_text(strip=True).replace(\" 에피소드\", \"\").replace(\"정보\", \"\")\n",
    "\n",
    "        if not titles[\"japanese\"] or not titles[\"english\"]:\n",
    "            japanese_title_section = soup.find('h2', class_='visually-hidden')\n",
    "            if japanese_title_section:\n",
    "                span_tags = japanese_title_section.find_all('span')\n",
    "                if len(span_tags) >= 2:\n",
    "                    if not titles[\"japanese\"]:\n",
    "                        titles[\"japanese\"] = span_tags[0].get_text(strip=True)\n",
    "                    if not titles[\"english\"]:\n",
    "                        titles[\"english\"] = span_tags[1].get_text(strip=True)\n",
    "\n",
    "        return titles\n",
    "\n",
    "    def extract_basic_info(self, soup: BeautifulSoup, nuxt_data: Dict) -> Dict[str, str]:\n",
    "        \"\"\"기본 정보 추출\"\"\"\n",
    "        basic_info = {}\n",
    "\n",
    "        try:\n",
    "            content_detail = nuxt_data.get('pinia', {}).get('content', {}).get('contentDetail', {})\n",
    "\n",
    "            if content_detail.get('format'):\n",
    "                basic_info[\"format\"] = content_detail['format']\n",
    "\n",
    "            if content_detail.get('status'):\n",
    "                basic_info[\"status\"] = content_detail['status']\n",
    "\n",
    "            season_data = content_detail.get('season', {})\n",
    "            if season_data:\n",
    "                basic_info[\"year\"] = str(season_data.get('year', ''))\n",
    "                basic_info[\"quarter\"] = f\"{season_data.get('quarter', '')}분기\"\n",
    "\n",
    "            if content_detail.get('startDate'):\n",
    "                basic_info[\"start_date\"] = content_detail['startDate']\n",
    "\n",
    "            if content_detail.get('endDate') and content_detail['endDate'] != \"null\":\n",
    "                basic_info[\"end_date\"] = content_detail['endDate']\n",
    "\n",
    "            if content_detail.get('totalEpisode') and content_detail['totalEpisode'] != \"N/A\":\n",
    "                basic_info[\"total_episodes\"] = str(content_detail['totalEpisode'])\n",
    "\n",
    "            if content_detail.get('duration') and content_detail['duration'] != \"N/A\":\n",
    "                basic_info[\"duration\"] = str(content_detail['duration'])\n",
    "\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        if not basic_info.get('year') or not basic_info.get('quarter'):\n",
    "            quarter_info = soup.find('div', class_='nBnfiIh')\n",
    "            if quarter_info:\n",
    "                full_format = quarter_info.get_text(strip=True)\n",
    "                parts = full_format.split(' · ')\n",
    "\n",
    "                if len(parts) >= 2:\n",
    "                    if not basic_info.get('format'):\n",
    "                        basic_info[\"format\"] = parts[1]\n",
    "\n",
    "                    season_info = parts[0].split(' ')\n",
    "                    if len(season_info) >= 2:\n",
    "                        if not basic_info.get('year'):\n",
    "                            basic_info[\"year\"] = season_info[0]\n",
    "                        if not basic_info.get('quarter'):\n",
    "                            basic_info[\"quarter\"] = season_info[1]\n",
    "\n",
    "        return basic_info\n",
    "\n",
    "    def extract_genres(self, soup: BeautifulSoup, nuxt_data: Dict) -> List[str]:\n",
    "        \"\"\"장르 정보 추출\"\"\"\n",
    "        genres = []\n",
    "\n",
    "        try:\n",
    "            content_detail = nuxt_data.get('pinia', {}).get('content', {}).get('contentDetail', {})\n",
    "            nuxt_genres = content_detail.get('genre', [])\n",
    "            if nuxt_genres:\n",
    "                genres = nuxt_genres\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        if not genres:\n",
    "            genre_tags = soup.select('a[rel=\"genre\"]')\n",
    "            genres = [tag.get_text(strip=True) for tag in genre_tags]\n",
    "\n",
    "        return genres\n",
    "\n",
    "    def extract_tags(self, soup: BeautifulSoup, nuxt_data: Dict) -> List[str]:\n",
    "        \"\"\"태그 정보 추출\"\"\"\n",
    "        tags = []\n",
    "\n",
    "        try:\n",
    "            content_detail = nuxt_data.get('pinia', {}).get('content', {}).get('contentDetail', {})\n",
    "            tag_data = content_detail.get('tag', [])\n",
    "\n",
    "            for tag_item in tag_data:\n",
    "                if isinstance(tag_item, dict) and tag_item.get('name'):\n",
    "                    tag_name = tag_item['name']\n",
    "                    if tag_item.get('spoiler'):\n",
    "                        tag_name += \" (스포일러)\"\n",
    "                    tags.append(tag_name)\n",
    "                elif isinstance(tag_item, str):\n",
    "                    tags.append(tag_item)\n",
    "\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        if not tags:\n",
    "            tag_section = None\n",
    "            for h2 in soup.find_all('h2', class_='wXeFmvm'):\n",
    "                if '작품 태그' in h2.get_text():\n",
    "                    tag_section = h2.find_parent('section')\n",
    "                    break\n",
    "\n",
    "            if tag_section:\n",
    "                tag_container = tag_section.find('div', class_='-mMZ9fV')\n",
    "                if tag_container:\n",
    "                    tag_links = tag_container.find_all('a', class_='MbHceQh')\n",
    "                    for link in tag_links:\n",
    "                        span = link.find('span')\n",
    "                        if span:\n",
    "                            tag_text = span.get_text(strip=True).replace('#', '')\n",
    "                            if 'iYz6NWc' in span.get('class', []):\n",
    "                                tag_text += \" (스포일러)\"\n",
    "                            tags.append(tag_text)\n",
    "\n",
    "        return tags\n",
    "\n",
    "    def extract_synopsis(self, soup: BeautifulSoup, nuxt_data: Dict) -> str:\n",
    "        \"\"\"줄거리 추출\"\"\"\n",
    "        try:\n",
    "            content_detail = nuxt_data.get('pinia', {}).get('content', {}).get('contentDetail', {})\n",
    "            description = content_detail.get('description', '')\n",
    "            if description and description != \"등록된 줄거리가 없습니다.\":\n",
    "                return description\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        description_div = soup.find('div', class_='bnHDzeE')\n",
    "        if description_div:\n",
    "            synopsis = description_div.get_text(strip=True)\n",
    "            if synopsis and synopsis != \"등록된 줄거리가 없습니다.\":\n",
    "                return synopsis\n",
    "\n",
    "        return \"등록된 줄거리가 없습니다.\"\n",
    "\n",
    "    def extract_characters_and_voice_actors(self, soup: BeautifulSoup, nuxt_data: Dict) -> List[Dict]:\n",
    "        \"\"\"캐릭터 및 성우 정보 추출\"\"\"\n",
    "        characters = []\n",
    "        character_cards = soup.find_all('div', class_='otjBFjd')\n",
    "\n",
    "        for card in character_cards:\n",
    "            character_div = card.find('div', class_='OuXf8uf')\n",
    "            voice_actor_link = card.find('a')\n",
    "            character_info = {}\n",
    "\n",
    "            if character_div:\n",
    "                name_elem = character_div.find('div', class_='iO6bs1d')\n",
    "                role_elem = character_div.find('div', class_='_99DZmqJ')\n",
    "\n",
    "                if name_elem:\n",
    "                    character_info['character_name'] = name_elem.get_text(strip=True)\n",
    "                if role_elem:\n",
    "                    character_info['character_role'] = role_elem.get_text(strip=True)\n",
    "\n",
    "                if character_div.get('data-original-title'):\n",
    "                    if not character_info.get('character_name'):\n",
    "                        character_info['character_name'] = character_div['data-original-title']\n",
    "\n",
    "            if voice_actor_link:\n",
    "                voice_actor_div = voice_actor_link.find('div', class_='_0fu6hck')\n",
    "                if voice_actor_div:\n",
    "                    voice_name_elem = voice_actor_div.find('div', class_='iO6bs1d')\n",
    "                    if voice_name_elem:\n",
    "                        character_info['voice_actor'] = voice_name_elem.get_text(strip=True)\n",
    "\n",
    "                    if voice_actor_div.get('title'):\n",
    "                        if not character_info.get('voice_actor'):\n",
    "                            character_info['voice_actor'] = voice_actor_div['title']\n",
    "\n",
    "            if character_info:\n",
    "                characters.append(character_info)\n",
    "\n",
    "        return characters\n",
    "\n",
    "    def extract_production_info(self, soup: BeautifulSoup, nuxt_data: Dict) -> Dict[str, str]:\n",
    "        \"\"\"제작 정보 추출\"\"\"\n",
    "        production_info = {}\n",
    "        production_section = soup.find('div', class_='_1coMKET -HW4ChD')\n",
    "\n",
    "        if production_section:\n",
    "            production_links = production_section.find_all('a', class_='_2hRLd-G')\n",
    "\n",
    "            for link in production_links:\n",
    "                staff_div = link.find('div', class_='OuXf8uf')\n",
    "\n",
    "                if staff_div:\n",
    "                    name_elem = staff_div.find('div', class_='iO6bs1d')\n",
    "                    role_elem = staff_div.find('div', class_='_99DZmqJ')\n",
    "\n",
    "                    if name_elem and role_elem:\n",
    "                        name = name_elem.get_text(strip=True)\n",
    "                        role = role_elem.get_text(strip=True)\n",
    "\n",
    "                        if role not in production_info:\n",
    "                            production_info[role] = []\n",
    "\n",
    "                        if isinstance(production_info[role], list):\n",
    "                            production_info[role].append(name)\n",
    "                        else:\n",
    "                            production_info[role] = [production_info[role], name]\n",
    "\n",
    "                    if staff_div.get('title'):\n",
    "                        if not name_elem:\n",
    "                            name = staff_div['title']\n",
    "                            if role_elem:\n",
    "                                role = role_elem.get_text(strip=True)\n",
    "                                if role not in production_info:\n",
    "                                    production_info[role] = name\n",
    "\n",
    "        for role, names in production_info.items():\n",
    "            if isinstance(names, list):\n",
    "                production_info[role] = ', '.join(names)\n",
    "\n",
    "        return production_info\n",
    "\n",
    "\n",
    "class ParallelAnilifeScraper:\n",
    "    def __init__(self, max_workers=10):\n",
    "        self.max_workers = max_workers\n",
    "        self.results = []\n",
    "        self.errors = []\n",
    "        self.lock = Lock()\n",
    "        self.progress_lock = Lock()\n",
    "        self.completed_count = 0\n",
    "        self.total_count = 0\n",
    "\n",
    "    def scrape_single(self, anime_id: int) -> Dict:\n",
    "        \"\"\"단일 애니메이션 크롤링\"\"\"\n",
    "        url = f\"https://anilife.app/content/{anime_id}?tab=info\"\n",
    "        scraper = AnilifeScraper()\n",
    "\n",
    "        try:\n",
    "            result = scraper.scrape_anime_info(url)\n",
    "\n",
    "            with self.progress_lock:\n",
    "                self.completed_count += 1\n",
    "                if self.completed_count % 10 == 0:\n",
    "                    logging.info(f\"진행률: {self.completed_count}/{self.total_count} ({self.completed_count/self.total_count*100:.1f}%)\")\n",
    "\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            logging.error(f\"ID {anime_id} 크롤링 실패: {str(e)}\")\n",
    "            return {\"error\": str(e), \"id\": anime_id, \"url\": url}\n",
    "\n",
    "    def process_result(self, anime_data: Dict) -> Dict:\n",
    "        \"\"\"크롤링 결과를 CSV용 플랫 딕셔너리로 변환\"\"\"\n",
    "        if \"error\" in anime_data:\n",
    "            return {\"id\": anime_data.get(\"id\", \"\"), \"error\": anime_data[\"error\"]}\n",
    "\n",
    "        flat_data = {\n",
    "            \"id\": anime_data.get(\"id\", \"\"),\n",
    "            \"url\": anime_data.get(\"url\", \"\"),\n",
    "            \"title_korean\": anime_data.get(\"title\", {}).get(\"korean\", \"\"),\n",
    "            \"title_japanese\": anime_data.get(\"title\", {}).get(\"japanese\", \"\"),\n",
    "            \"title_english\": anime_data.get(\"title\", {}).get(\"english\", \"\"),\n",
    "            \"format\": anime_data.get(\"basic_info\", {}).get(\"format\", \"\"),\n",
    "            \"status\": anime_data.get(\"basic_info\", {}).get(\"status\", \"\"),\n",
    "            \"year\": anime_data.get(\"basic_info\", {}).get(\"year\", \"\"),\n",
    "            \"quarter\": anime_data.get(\"basic_info\", {}).get(\"quarter\", \"\"),\n",
    "            \"start_date\": anime_data.get(\"basic_info\", {}).get(\"start_date\", \"\"),\n",
    "            \"end_date\": anime_data.get(\"basic_info\", {}).get(\"end_date\", \"\"),\n",
    "            \"total_episodes\": anime_data.get(\"basic_info\", {}).get(\"total_episodes\", \"\"),\n",
    "            \"duration\": anime_data.get(\"basic_info\", {}).get(\"duration\", \"\"),\n",
    "            \"genres\": \"|\".join(anime_data.get(\"genres\", [])),\n",
    "            \"tags\": \"|\".join(anime_data.get(\"tags\", [])),\n",
    "            \"synopsis\": anime_data.get(\"synopsis\", \"\"),\n",
    "            \"num_characters\": len(anime_data.get(\"characters_voice_actors\", [])),\n",
    "            \"main_characters\": \"|\".join([\n",
    "                f\"{c.get('character_name', '')}({c.get('voice_actor', '')})\"\n",
    "                for c in anime_data.get(\"characters_voice_actors\", [])[:5]\n",
    "            ]),\n",
    "            \"director\": anime_data.get(\"production_info\", {}).get(\"감독\", \"\"),\n",
    "            \"studio\": anime_data.get(\"production_info\", {}).get(\"제작사\", \"\"),\n",
    "            \"original_work\": anime_data.get(\"production_info\", {}).get(\"원작\", \"\"),\n",
    "            \"error\": \"\"\n",
    "        }\n",
    "\n",
    "        return flat_data\n",
    "\n",
    "    def scrape_range(self, start_id: int, end_id: int, batch_size: int = 100):\n",
    "        \"\"\"지정된 범위의 애니메이션 병렬 크롤링\"\"\"\n",
    "        self.total_count = end_id - start_id + 1\n",
    "        self.completed_count = 0\n",
    "\n",
    "        logging.info(f\"크롤링 시작: ID {start_id}부터 {end_id}까지 (총 {self.total_count}개)\")\n",
    "\n",
    "        # 배치 단위로 처리\n",
    "        for batch_start in range(start_id, end_id + 1, batch_size):\n",
    "            batch_end = min(batch_start + batch_size - 1, end_id)\n",
    "            batch_ids = list(range(batch_start, batch_end + 1))\n",
    "\n",
    "            logging.info(f\"배치 처리 중: ID {batch_start} ~ {batch_end}\")\n",
    "\n",
    "            with ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n",
    "                futures = {executor.submit(self.scrape_single, anime_id): anime_id\n",
    "                          for anime_id in batch_ids}\n",
    "\n",
    "                for future in as_completed(futures):\n",
    "                    anime_id = futures[future]\n",
    "                    try:\n",
    "                        result = future.result(timeout=30)\n",
    "                        processed_result = self.process_result(result)\n",
    "\n",
    "                        with self.lock:\n",
    "                            if processed_result.get(\"error\"):\n",
    "                                self.errors.append(processed_result)\n",
    "                            else:\n",
    "                                self.results.append(processed_result)\n",
    "\n",
    "                    except Exception as e:\n",
    "                        logging.error(f\"ID {anime_id} 처리 실패: {str(e)}\")\n",
    "                        with self.lock:\n",
    "                            self.errors.append({\"id\": anime_id, \"error\": str(e)})\n",
    "\n",
    "            # 배치 간 대기 시간 (서버 부하 방지)\n",
    "            time.sleep(2)\n",
    "\n",
    "            # 중간 저장 (매 500개마다)\n",
    "            if len(self.results) % 500 == 0 and self.results:\n",
    "                self.save_intermediate_results()\n",
    "\n",
    "    def save_intermediate_results(self):\n",
    "        \"\"\"중간 결과 저장\"\"\"\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        filename = f\"anilife_intermediate_{timestamp}.csv\"\n",
    "\n",
    "        with self.lock:\n",
    "            if self.results:\n",
    "                self.save_to_csv(filename, self.results)\n",
    "                logging.info(f\"중간 결과 저장: {filename} ({len(self.results)}개 항목)\")\n",
    "\n",
    "    def save_to_csv(self, filename: str, data: List[Dict]):\n",
    "        \"\"\"결과를 CSV 파일로 저장\"\"\"\n",
    "        if not data:\n",
    "            logging.warning(\"저장할 데이터가 없습니다.\")\n",
    "            return\n",
    "\n",
    "        fieldnames = [\n",
    "            \"id\", \"url\", \"title_korean\", \"title_japanese\", \"title_english\",\n",
    "            \"format\", \"status\", \"year\", \"quarter\", \"start_date\", \"end_date\",\n",
    "            \"total_episodes\", \"duration\", \"genres\", \"tags\", \"synopsis\",\n",
    "            \"num_characters\", \"main_characters\", \"director\", \"studio\",\n",
    "            \"original_work\", \"error\"\n",
    "        ]\n",
    "\n",
    "        with open(filename, 'w', newline='', encoding='utf-8-sig') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(data)\n",
    "\n",
    "        logging.info(f\"CSV 파일 저장 완료: {filename}\")\n",
    "\n",
    "    def save_all_results(self):\n",
    "        \"\"\"모든 결과 저장\"\"\"\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "        # 성공 데이터 저장\n",
    "        if self.results:\n",
    "            success_filename = f\"anilife_data_{timestamp}.csv\"\n",
    "            self.save_to_csv(success_filename, self.results)\n",
    "            logging.info(f\"성공 데이터: {len(self.results)}개 항목\")\n",
    "\n",
    "        # 에러 데이터 저장\n",
    "        if self.errors:\n",
    "            error_filename = f\"anilife_errors_{timestamp}.csv\"\n",
    "            self.save_to_csv(error_filename, self.errors)\n",
    "            logging.info(f\"에러 데이터: {len(self.errors)}개 항목\")\n",
    "\n",
    "        # 통계 출력\n",
    "        total = len(self.results) + len(self.errors)\n",
    "        success_rate = (len(self.results) / total * 100) if total > 0 else 0\n",
    "\n",
    "        logging.info(f\"\\n크롤링 완료 통계:\")\n",
    "        logging.info(f\"- 전체: {total}개\")\n",
    "        logging.info(f\"- 성공: {len(self.results)}개\")\n",
    "        logging.info(f\"- 실패: {len(self.errors)}개\")\n",
    "        logging.info(f\"- 성공률: {success_rate:.1f}%\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"메인 실행 함수\"\"\"\n",
    "    # 설정\n",
    "    START_ID = 101\n",
    "    END_ID = 7000\n",
    "    MAX_WORKERS = 20  # 동시 실행 스레드 수 (서버 부하 고려하여 조정)\n",
    "    BATCH_SIZE = 100  # 한 번에 처리할 항목 수\n",
    "\n",
    "    # 스크래퍼 초기화\n",
    "    scraper = ParallelAnilifeScraper(max_workers=MAX_WORKERS)\n",
    "\n",
    "    # 시작 시간 기록\n",
    "    start_time = time.time()\n",
    "\n",
    "    try:\n",
    "        # 크롤링 실행\n",
    "        scraper.scrape_range(START_ID, END_ID, batch_size=BATCH_SIZE)\n",
    "\n",
    "        # 결과 저장\n",
    "        scraper.save_all_results()\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        logging.info(\"\\n크롤링이 사용자에 의해 중단되었습니다.\")\n",
    "        scraper.save_all_results()\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"크롤링 중 오류 발생: {str(e)}\")\n",
    "        scraper.save_all_results()\n",
    "\n",
    "    finally:\n",
    "        # 소요 시간 출력\n",
    "        elapsed_time = time.time() - start_time\n",
    "        hours = int(elapsed_time // 3600)\n",
    "        minutes = int((elapsed_time % 3600) // 60)\n",
    "        seconds = int(elapsed_time % 60)\n",
    "\n",
    "        logging.info(f\"\\n총 소요 시간: {hours}시간 {minutes}분 {seconds}초\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "17ed0e4b52bb532d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-05 16:36:26,094 - INFO - 크롤링 시작: ID 101부터 7000까지 (총 6900개)\n",
      "2025-09-05 16:36:26,096 - INFO - 배치 처리 중: ID 101 ~ 200\n",
      "2025-09-05 16:36:26,842 - INFO - 진행률: 10/6900 (0.1%)\n",
      "2025-09-05 16:36:27,198 - INFO - 진행률: 20/6900 (0.3%)\n",
      "2025-09-05 16:36:27,383 - INFO - 진행률: 30/6900 (0.4%)\n",
      "2025-09-05 16:36:27,630 - INFO - 진행률: 40/6900 (0.6%)\n",
      "2025-09-05 16:36:27,880 - INFO - 진행률: 50/6900 (0.7%)\n",
      "2025-09-05 16:36:28,080 - INFO - 진행률: 60/6900 (0.9%)\n",
      "2025-09-05 16:36:28,345 - INFO - 진행률: 70/6900 (1.0%)\n",
      "2025-09-05 16:36:28,644 - INFO - 진행률: 80/6900 (1.2%)\n",
      "2025-09-05 16:36:28,939 - INFO - 진행률: 90/6900 (1.3%)\n",
      "2025-09-05 16:36:29,224 - INFO - 진행률: 100/6900 (1.4%)\n",
      "2025-09-05 16:36:31,239 - INFO - 배치 처리 중: ID 201 ~ 300\n",
      "2025-09-05 16:36:31,771 - INFO - 진행률: 110/6900 (1.6%)\n",
      "2025-09-05 16:36:31,983 - INFO - 진행률: 120/6900 (1.7%)\n",
      "2025-09-05 16:36:32,134 - INFO - 진행률: 130/6900 (1.9%)\n",
      "2025-09-05 16:36:32,354 - INFO - 진행률: 140/6900 (2.0%)\n",
      "2025-09-05 16:36:32,742 - INFO - 진행률: 150/6900 (2.2%)\n",
      "2025-09-05 16:36:32,856 - INFO - 진행률: 160/6900 (2.3%)\n",
      "2025-09-05 16:36:33,068 - INFO - 진행률: 170/6900 (2.5%)\n",
      "2025-09-05 16:36:33,323 - INFO - 진행률: 180/6900 (2.6%)\n",
      "2025-09-05 16:36:33,576 - INFO - 진행률: 190/6900 (2.8%)\n",
      "2025-09-05 16:36:33,697 - INFO - 진행률: 200/6900 (2.9%)\n",
      "2025-09-05 16:36:35,699 - INFO - 배치 처리 중: ID 301 ~ 400\n",
      "2025-09-05 16:36:36,284 - INFO - 진행률: 210/6900 (3.0%)\n",
      "2025-09-05 16:36:36,436 - INFO - 진행률: 220/6900 (3.2%)\n",
      "2025-09-05 16:36:36,788 - INFO - 진행률: 230/6900 (3.3%)\n",
      "2025-09-05 16:36:36,932 - INFO - 진행률: 240/6900 (3.5%)\n",
      "2025-09-05 16:36:37,207 - INFO - 진행률: 250/6900 (3.6%)\n",
      "2025-09-05 16:36:37,372 - INFO - 진행률: 260/6900 (3.8%)\n",
      "2025-09-05 16:36:37,590 - INFO - 진행률: 270/6900 (3.9%)\n",
      "2025-09-05 16:36:37,779 - INFO - 진행률: 280/6900 (4.1%)\n",
      "2025-09-05 16:36:37,976 - INFO - 진행률: 290/6900 (4.2%)\n",
      "2025-09-05 16:36:38,153 - INFO - 진행률: 300/6900 (4.3%)\n",
      "2025-09-05 16:36:40,156 - INFO - 배치 처리 중: ID 401 ~ 500\n",
      "2025-09-05 16:36:40,609 - INFO - 진행률: 310/6900 (4.5%)\n",
      "2025-09-05 16:36:40,993 - INFO - 진행률: 320/6900 (4.6%)\n",
      "2025-09-05 16:36:41,189 - INFO - 진행률: 330/6900 (4.8%)\n",
      "2025-09-05 16:36:41,446 - INFO - 진행률: 340/6900 (4.9%)\n",
      "2025-09-05 16:36:41,669 - INFO - 진행률: 350/6900 (5.1%)\n",
      "2025-09-05 16:36:41,867 - INFO - 진행률: 360/6900 (5.2%)\n",
      "2025-09-05 16:36:42,068 - INFO - 진행률: 370/6900 (5.4%)\n",
      "2025-09-05 16:36:42,281 - INFO - 진행률: 380/6900 (5.5%)\n",
      "2025-09-05 16:36:42,532 - INFO - 진행률: 390/6900 (5.7%)\n",
      "2025-09-05 16:36:42,652 - INFO - 진행률: 400/6900 (5.8%)\n",
      "2025-09-05 16:36:44,655 - INFO - 배치 처리 중: ID 501 ~ 600\n",
      "2025-09-05 16:36:45,109 - INFO - 진행률: 410/6900 (5.9%)\n",
      "2025-09-05 16:36:45,288 - INFO - 진행률: 420/6900 (6.1%)\n",
      "2025-09-05 16:36:45,593 - INFO - 진행률: 430/6900 (6.2%)\n",
      "2025-09-05 16:36:45,823 - INFO - 진행률: 440/6900 (6.4%)\n",
      "2025-09-05 16:36:45,985 - INFO - 진행률: 450/6900 (6.5%)\n",
      "2025-09-05 16:36:46,207 - INFO - 진행률: 460/6900 (6.7%)\n",
      "2025-09-05 16:36:46,446 - INFO - 진행률: 470/6900 (6.8%)\n",
      "2025-09-05 16:36:46,755 - INFO - 진행률: 480/6900 (7.0%)\n",
      "2025-09-05 16:36:46,867 - INFO - 진행률: 490/6900 (7.1%)\n",
      "2025-09-05 16:36:47,152 - INFO - 진행률: 500/6900 (7.2%)\n",
      "2025-09-05 16:36:49,154 - INFO - 배치 처리 중: ID 601 ~ 700\n",
      "2025-09-05 16:36:49,771 - INFO - 진행률: 510/6900 (7.4%)\n",
      "2025-09-05 16:36:49,878 - INFO - 진행률: 520/6900 (7.5%)\n",
      "2025-09-05 16:36:50,179 - INFO - 진행률: 530/6900 (7.7%)\n",
      "2025-09-05 16:36:50,428 - INFO - 진행률: 540/6900 (7.8%)\n",
      "2025-09-05 16:36:50,626 - INFO - 진행률: 550/6900 (8.0%)\n",
      "2025-09-05 16:36:51,018 - INFO - 진행률: 560/6900 (8.1%)\n",
      "2025-09-05 16:36:51,148 - INFO - 진행률: 570/6900 (8.3%)\n",
      "2025-09-05 16:36:51,366 - INFO - 진행률: 580/6900 (8.4%)\n",
      "2025-09-05 16:36:51,567 - INFO - 진행률: 590/6900 (8.6%)\n",
      "2025-09-05 16:36:52,016 - INFO - 진행률: 600/6900 (8.7%)\n",
      "2025-09-05 16:36:54,019 - INFO - 배치 처리 중: ID 701 ~ 800\n",
      "2025-09-05 16:36:54,652 - INFO - 진행률: 610/6900 (8.8%)\n",
      "2025-09-05 16:36:54,836 - INFO - 진행률: 620/6900 (9.0%)\n",
      "2025-09-05 16:36:55,185 - INFO - 진행률: 630/6900 (9.1%)\n",
      "2025-09-05 16:36:55,463 - INFO - 진행률: 640/6900 (9.3%)\n",
      "2025-09-05 16:36:55,621 - INFO - 진행률: 650/6900 (9.4%)\n",
      "2025-09-05 16:36:55,878 - INFO - 진행률: 660/6900 (9.6%)\n",
      "2025-09-05 16:36:56,095 - INFO - 진행률: 670/6900 (9.7%)\n",
      "2025-09-05 16:36:56,272 - INFO - 진행률: 680/6900 (9.9%)\n",
      "2025-09-05 16:36:56,498 - INFO - 진행률: 690/6900 (10.0%)\n",
      "2025-09-05 16:36:56,667 - INFO - 진행률: 700/6900 (10.1%)\n",
      "2025-09-05 16:36:58,670 - INFO - 배치 처리 중: ID 801 ~ 900\n",
      "2025-09-05 16:36:59,388 - INFO - 진행률: 710/6900 (10.3%)\n",
      "2025-09-05 16:36:59,554 - INFO - 진행률: 720/6900 (10.4%)\n",
      "2025-09-05 16:36:59,759 - INFO - 진행률: 730/6900 (10.6%)\n",
      "2025-09-05 16:37:00,035 - INFO - 진행률: 740/6900 (10.7%)\n",
      "2025-09-05 16:37:00,179 - INFO - 진행률: 750/6900 (10.9%)\n",
      "2025-09-05 16:37:00,383 - INFO - 진행률: 760/6900 (11.0%)\n",
      "2025-09-05 16:37:00,615 - INFO - 진행률: 770/6900 (11.2%)\n",
      "2025-09-05 16:37:01,128 - INFO - 진행률: 780/6900 (11.3%)\n",
      "2025-09-05 16:37:01,228 - INFO - 진행률: 790/6900 (11.4%)\n",
      "2025-09-05 16:37:01,573 - INFO - 진행률: 800/6900 (11.6%)\n",
      "2025-09-05 16:37:03,575 - INFO - 배치 처리 중: ID 901 ~ 1000\n",
      "2025-09-05 16:37:04,164 - INFO - 진행률: 810/6900 (11.7%)\n",
      "2025-09-05 16:37:04,259 - INFO - 진행률: 820/6900 (11.9%)\n",
      "2025-09-05 16:37:04,540 - INFO - 진행률: 830/6900 (12.0%)\n",
      "2025-09-05 16:37:04,774 - INFO - 진행률: 840/6900 (12.2%)\n",
      "2025-09-05 16:37:04,959 - INFO - 진행률: 850/6900 (12.3%)\n",
      "2025-09-05 16:37:05,420 - INFO - 진행률: 860/6900 (12.5%)\n",
      "2025-09-05 16:37:05,552 - INFO - 진행률: 870/6900 (12.6%)\n",
      "2025-09-05 16:37:05,881 - INFO - 진행률: 880/6900 (12.8%)\n",
      "2025-09-05 16:37:06,042 - INFO - 진행률: 890/6900 (12.9%)\n",
      "2025-09-05 16:37:06,332 - INFO - 진행률: 900/6900 (13.0%)\n",
      "2025-09-05 16:37:08,342 - INFO - 배치 처리 중: ID 1001 ~ 1100\n",
      "2025-09-05 16:37:09,181 - INFO - 진행률: 910/6900 (13.2%)\n",
      "2025-09-05 16:37:09,381 - INFO - 진행률: 920/6900 (13.3%)\n",
      "2025-09-05 16:37:09,561 - INFO - 진행률: 930/6900 (13.5%)\n",
      "2025-09-05 16:37:09,966 - INFO - 진행률: 940/6900 (13.6%)\n",
      "2025-09-05 16:37:10,134 - INFO - 진행률: 950/6900 (13.8%)\n",
      "2025-09-05 16:37:10,376 - INFO - 진행률: 960/6900 (13.9%)\n",
      "2025-09-05 16:37:10,552 - INFO - 진행률: 970/6900 (14.1%)\n",
      "2025-09-05 16:37:10,754 - INFO - 진행률: 980/6900 (14.2%)\n",
      "2025-09-05 16:37:10,948 - INFO - 진행률: 990/6900 (14.3%)\n",
      "2025-09-05 16:37:11,227 - INFO - 진행률: 1000/6900 (14.5%)\n",
      "2025-09-05 16:37:13,230 - INFO - 배치 처리 중: ID 1101 ~ 1200\n",
      "2025-09-05 16:37:13,733 - INFO - 진행률: 1010/6900 (14.6%)\n",
      "2025-09-05 16:37:14,039 - INFO - 진행률: 1020/6900 (14.8%)\n",
      "2025-09-05 16:37:14,134 - INFO - 진행률: 1030/6900 (14.9%)\n",
      "2025-09-05 16:37:14,350 - INFO - 진행률: 1040/6900 (15.1%)\n",
      "2025-09-05 16:37:14,543 - INFO - 진행률: 1050/6900 (15.2%)\n",
      "2025-09-05 16:37:14,865 - INFO - 진행률: 1060/6900 (15.4%)\n",
      "2025-09-05 16:37:15,040 - INFO - 진행률: 1070/6900 (15.5%)\n",
      "2025-09-05 16:37:15,236 - INFO - 진행률: 1080/6900 (15.7%)\n",
      "2025-09-05 16:37:15,402 - INFO - 진행률: 1090/6900 (15.8%)\n",
      "2025-09-05 16:37:15,641 - INFO - 진행률: 1100/6900 (15.9%)\n",
      "2025-09-05 16:37:17,645 - INFO - 배치 처리 중: ID 1201 ~ 1300\n",
      "2025-09-05 16:37:18,375 - INFO - 진행률: 1110/6900 (16.1%)\n",
      "2025-09-05 16:37:18,515 - INFO - 진행률: 1120/6900 (16.2%)\n",
      "2025-09-05 16:37:18,770 - INFO - 진행률: 1130/6900 (16.4%)\n",
      "2025-09-05 16:37:18,948 - INFO - 진행률: 1140/6900 (16.5%)\n",
      "2025-09-05 16:37:19,194 - INFO - 진행률: 1150/6900 (16.7%)\n",
      "2025-09-05 16:37:19,342 - INFO - 진행률: 1160/6900 (16.8%)\n",
      "2025-09-05 16:37:19,601 - INFO - 진행률: 1170/6900 (17.0%)\n",
      "2025-09-05 16:37:19,815 - INFO - 진행률: 1180/6900 (17.1%)\n",
      "2025-09-05 16:37:20,214 - INFO - 진행률: 1190/6900 (17.2%)\n",
      "2025-09-05 16:37:20,353 - INFO - 진행률: 1200/6900 (17.4%)\n",
      "2025-09-05 16:37:22,355 - INFO - 배치 처리 중: ID 1301 ~ 1400\n",
      "2025-09-05 16:37:23,409 - INFO - 진행률: 1210/6900 (17.5%)\n",
      "2025-09-05 16:37:23,650 - INFO - 진행률: 1220/6900 (17.7%)\n",
      "2025-09-05 16:37:23,837 - INFO - 진행률: 1230/6900 (17.8%)\n",
      "2025-09-05 16:37:24,124 - INFO - 진행률: 1240/6900 (18.0%)\n",
      "2025-09-05 16:37:24,246 - INFO - 진행률: 1250/6900 (18.1%)\n",
      "2025-09-05 16:37:24,455 - INFO - 진행률: 1260/6900 (18.3%)\n",
      "2025-09-05 16:37:24,855 - INFO - 진행률: 1270/6900 (18.4%)\n",
      "2025-09-05 16:37:25,015 - INFO - 진행률: 1280/6900 (18.6%)\n",
      "2025-09-05 16:37:25,159 - INFO - 진행률: 1290/6900 (18.7%)\n",
      "2025-09-05 16:37:25,467 - INFO - 진행률: 1300/6900 (18.8%)\n",
      "2025-09-05 16:37:27,471 - INFO - 배치 처리 중: ID 1401 ~ 1500\n",
      "2025-09-05 16:37:28,232 - INFO - 진행률: 1310/6900 (19.0%)\n",
      "2025-09-05 16:37:28,368 - INFO - 진행률: 1320/6900 (19.1%)\n",
      "2025-09-05 16:37:28,665 - INFO - 진행률: 1330/6900 (19.3%)\n",
      "2025-09-05 16:37:28,895 - INFO - 진행률: 1340/6900 (19.4%)\n",
      "2025-09-05 16:37:29,157 - INFO - 진행률: 1350/6900 (19.6%)\n",
      "2025-09-05 16:37:29,399 - INFO - 진행률: 1360/6900 (19.7%)\n",
      "2025-09-05 16:37:29,591 - INFO - 진행률: 1370/6900 (19.9%)\n",
      "2025-09-05 16:37:29,828 - INFO - 진행률: 1380/6900 (20.0%)\n",
      "2025-09-05 16:37:30,037 - INFO - 진행률: 1390/6900 (20.1%)\n",
      "2025-09-05 16:37:30,266 - INFO - 진행률: 1400/6900 (20.3%)\n",
      "2025-09-05 16:37:32,270 - INFO - 배치 처리 중: ID 1501 ~ 1600\n",
      "2025-09-05 16:37:32,756 - INFO - 진행률: 1410/6900 (20.4%)\n",
      "2025-09-05 16:37:32,941 - INFO - 진행률: 1420/6900 (20.6%)\n",
      "2025-09-05 16:37:33,112 - INFO - 진행률: 1430/6900 (20.7%)\n",
      "2025-09-05 16:37:33,514 - INFO - 진행률: 1440/6900 (20.9%)\n",
      "2025-09-05 16:37:33,660 - INFO - 진행률: 1450/6900 (21.0%)\n",
      "2025-09-05 16:37:33,859 - INFO - 진행률: 1460/6900 (21.2%)\n",
      "2025-09-05 16:37:34,127 - INFO - 진행률: 1470/6900 (21.3%)\n",
      "2025-09-05 16:37:34,273 - INFO - 진행률: 1480/6900 (21.4%)\n",
      "2025-09-05 16:37:34,528 - INFO - 진행률: 1490/6900 (21.6%)\n",
      "2025-09-05 16:37:35,022 - INFO - 진행률: 1500/6900 (21.7%)\n",
      "2025-09-05 16:37:37,043 - INFO - 배치 처리 중: ID 1601 ~ 1700\n",
      "2025-09-05 16:37:38,107 - INFO - 진행률: 1510/6900 (21.9%)\n",
      "2025-09-05 16:37:38,365 - INFO - 진행률: 1520/6900 (22.0%)\n",
      "2025-09-05 16:37:38,623 - INFO - 진행률: 1530/6900 (22.2%)\n",
      "2025-09-05 16:37:38,920 - INFO - 진행률: 1540/6900 (22.3%)\n",
      "2025-09-05 16:37:39,104 - INFO - 진행률: 1550/6900 (22.5%)\n",
      "2025-09-05 16:37:39,323 - INFO - 진행률: 1560/6900 (22.6%)\n",
      "2025-09-05 16:37:39,495 - INFO - 진행률: 1570/6900 (22.8%)\n",
      "2025-09-05 16:37:39,726 - INFO - 진행률: 1580/6900 (22.9%)\n",
      "2025-09-05 16:37:40,284 - INFO - 진행률: 1590/6900 (23.0%)\n",
      "2025-09-05 16:37:40,849 - INFO - 진행률: 1600/6900 (23.2%)\n",
      "2025-09-05 16:37:42,854 - INFO - 배치 처리 중: ID 1701 ~ 1800\n",
      "2025-09-05 16:37:43,515 - INFO - 진행률: 1610/6900 (23.3%)\n",
      "2025-09-05 16:37:43,715 - INFO - 진행률: 1620/6900 (23.5%)\n",
      "2025-09-05 16:37:43,910 - INFO - 진행률: 1630/6900 (23.6%)\n",
      "2025-09-05 16:37:44,196 - INFO - 진행률: 1640/6900 (23.8%)\n",
      "2025-09-05 16:37:44,445 - INFO - 진행률: 1650/6900 (23.9%)\n",
      "2025-09-05 16:37:44,653 - INFO - 진행률: 1660/6900 (24.1%)\n",
      "2025-09-05 16:37:45,093 - INFO - 진행률: 1670/6900 (24.2%)\n",
      "2025-09-05 16:37:45,214 - INFO - 진행률: 1680/6900 (24.3%)\n",
      "2025-09-05 16:37:45,500 - INFO - 진행률: 1690/6900 (24.5%)\n",
      "2025-09-05 16:37:45,625 - INFO - 진행률: 1700/6900 (24.6%)\n",
      "2025-09-05 16:37:47,629 - INFO - 배치 처리 중: ID 1801 ~ 1900\n",
      "2025-09-05 16:37:48,236 - INFO - 진행률: 1710/6900 (24.8%)\n",
      "2025-09-05 16:37:48,351 - INFO - 진행률: 1720/6900 (24.9%)\n",
      "2025-09-05 16:37:48,678 - INFO - 진행률: 1730/6900 (25.1%)\n",
      "2025-09-05 16:37:48,873 - INFO - 진행률: 1740/6900 (25.2%)\n",
      "2025-09-05 16:37:49,213 - INFO - 진행률: 1750/6900 (25.4%)\n",
      "2025-09-05 16:37:49,417 - INFO - 진행률: 1760/6900 (25.5%)\n",
      "2025-09-05 16:37:49,640 - INFO - 진행률: 1770/6900 (25.7%)\n",
      "2025-09-05 16:37:49,874 - INFO - 진행률: 1780/6900 (25.8%)\n",
      "2025-09-05 16:37:50,109 - INFO - 진행률: 1790/6900 (25.9%)\n",
      "2025-09-05 16:37:50,333 - INFO - 진행률: 1800/6900 (26.1%)\n",
      "2025-09-05 16:37:52,337 - INFO - 배치 처리 중: ID 1901 ~ 2000\n",
      "2025-09-05 16:37:52,782 - INFO - 진행률: 1810/6900 (26.2%)\n",
      "2025-09-05 16:37:53,184 - INFO - 진행률: 1820/6900 (26.4%)\n",
      "2025-09-05 16:37:53,419 - INFO - 진행률: 1830/6900 (26.5%)\n",
      "2025-09-05 16:37:53,609 - INFO - 진행률: 1840/6900 (26.7%)\n",
      "2025-09-05 16:37:53,770 - INFO - 진행률: 1850/6900 (26.8%)\n",
      "2025-09-05 16:37:54,032 - INFO - 진행률: 1860/6900 (27.0%)\n",
      "2025-09-05 16:37:54,228 - INFO - 진행률: 1870/6900 (27.1%)\n",
      "2025-09-05 16:37:54,420 - INFO - 진행률: 1880/6900 (27.2%)\n",
      "2025-09-05 16:37:54,615 - INFO - 진행률: 1890/6900 (27.4%)\n",
      "2025-09-05 16:37:54,990 - INFO - 진행률: 1900/6900 (27.5%)\n",
      "2025-09-05 16:37:56,993 - INFO - 배치 처리 중: ID 2001 ~ 2100\n",
      "2025-09-05 16:37:57,529 - INFO - 진행률: 1910/6900 (27.7%)\n",
      "2025-09-05 16:37:57,672 - INFO - 진행률: 1920/6900 (27.8%)\n",
      "2025-09-05 16:37:57,913 - INFO - 진행률: 1930/6900 (28.0%)\n",
      "2025-09-05 16:37:58,149 - INFO - 진행률: 1940/6900 (28.1%)\n",
      "2025-09-05 16:37:58,345 - INFO - 진행률: 1950/6900 (28.3%)\n",
      "2025-09-05 16:37:58,566 - INFO - 진행률: 1960/6900 (28.4%)\n",
      "2025-09-05 16:37:58,744 - INFO - 진행률: 1970/6900 (28.6%)\n",
      "2025-09-05 16:37:59,146 - INFO - 진행률: 1980/6900 (28.7%)\n",
      "2025-09-05 16:37:59,289 - INFO - 진행률: 1990/6900 (28.8%)\n",
      "2025-09-05 16:37:59,553 - INFO - 진행률: 2000/6900 (29.0%)\n",
      "2025-09-05 16:38:01,558 - INFO - 배치 처리 중: ID 2101 ~ 2200\n",
      "2025-09-05 16:38:02,074 - INFO - 진행률: 2010/6900 (29.1%)\n",
      "2025-09-05 16:38:02,222 - INFO - 진행률: 2020/6900 (29.3%)\n",
      "2025-09-05 16:38:02,412 - INFO - 진행률: 2030/6900 (29.4%)\n",
      "2025-09-05 16:38:02,674 - INFO - 진행률: 2040/6900 (29.6%)\n",
      "2025-09-05 16:38:02,836 - INFO - 진행률: 2050/6900 (29.7%)\n",
      "2025-09-05 16:38:03,205 - INFO - 진행률: 2060/6900 (29.9%)\n",
      "2025-09-05 16:38:03,335 - INFO - 진행률: 2070/6900 (30.0%)\n",
      "2025-09-05 16:38:03,541 - INFO - 진행률: 2080/6900 (30.1%)\n",
      "2025-09-05 16:38:03,747 - INFO - 진행률: 2090/6900 (30.3%)\n",
      "2025-09-05 16:38:04,009 - INFO - 진행률: 2100/6900 (30.4%)\n",
      "2025-09-05 16:38:06,012 - INFO - 배치 처리 중: ID 2201 ~ 2300\n",
      "2025-09-05 16:38:06,580 - INFO - 진행률: 2110/6900 (30.6%)\n",
      "2025-09-05 16:38:06,689 - INFO - 진행률: 2120/6900 (30.7%)\n",
      "2025-09-05 16:38:06,943 - INFO - 진행률: 2130/6900 (30.9%)\n",
      "2025-09-05 16:38:07,126 - INFO - 진행률: 2140/6900 (31.0%)\n",
      "2025-09-05 16:38:07,529 - INFO - 진행률: 2150/6900 (31.2%)\n",
      "2025-09-05 16:38:07,657 - INFO - 진행률: 2160/6900 (31.3%)\n",
      "2025-09-05 16:38:07,902 - INFO - 진행률: 2170/6900 (31.4%)\n",
      "2025-09-05 16:38:08,161 - INFO - 진행률: 2180/6900 (31.6%)\n",
      "2025-09-05 16:38:08,295 - INFO - 진행률: 2190/6900 (31.7%)\n",
      "2025-09-05 16:38:08,473 - INFO - 진행률: 2200/6900 (31.9%)\n",
      "2025-09-05 16:38:10,476 - INFO - 배치 처리 중: ID 2301 ~ 2400\n",
      "2025-09-05 16:38:11,029 - INFO - 진행률: 2210/6900 (32.0%)\n",
      "2025-09-05 16:38:11,175 - INFO - 진행률: 2220/6900 (32.2%)\n",
      "2025-09-05 16:38:11,565 - INFO - 진행률: 2230/6900 (32.3%)\n",
      "2025-09-05 16:38:11,742 - INFO - 진행률: 2240/6900 (32.5%)\n",
      "2025-09-05 16:38:11,957 - INFO - 진행률: 2250/6900 (32.6%)\n",
      "2025-09-05 16:38:12,154 - INFO - 진행률: 2260/6900 (32.8%)\n",
      "2025-09-05 16:38:12,301 - INFO - 진행률: 2270/6900 (32.9%)\n",
      "2025-09-05 16:38:12,578 - INFO - 진행률: 2280/6900 (33.0%)\n",
      "2025-09-05 16:38:12,731 - INFO - 진행률: 2290/6900 (33.2%)\n",
      "2025-09-05 16:38:12,994 - INFO - 진행률: 2300/6900 (33.3%)\n",
      "2025-09-05 16:38:14,997 - INFO - 배치 처리 중: ID 2401 ~ 2500\n",
      "2025-09-05 16:38:15,619 - INFO - 진행률: 2310/6900 (33.5%)\n",
      "2025-09-05 16:38:15,762 - INFO - 진행률: 2320/6900 (33.6%)\n",
      "2025-09-05 16:38:15,971 - INFO - 진행률: 2330/6900 (33.8%)\n",
      "2025-09-05 16:38:16,209 - INFO - 진행률: 2340/6900 (33.9%)\n",
      "2025-09-05 16:38:16,379 - INFO - 진행률: 2350/6900 (34.1%)\n",
      "2025-09-05 16:38:16,564 - INFO - 진행률: 2360/6900 (34.2%)\n",
      "2025-09-05 16:38:16,785 - INFO - 진행률: 2370/6900 (34.3%)\n",
      "2025-09-05 16:38:17,012 - INFO - 진행률: 2380/6900 (34.5%)\n",
      "2025-09-05 16:38:17,158 - INFO - 진행률: 2390/6900 (34.6%)\n",
      "2025-09-05 16:38:17,510 - INFO - 진행률: 2400/6900 (34.8%)\n",
      "2025-09-05 16:38:19,512 - INFO - 배치 처리 중: ID 2501 ~ 2600\n",
      "2025-09-05 16:38:20,190 - INFO - 진행률: 2410/6900 (34.9%)\n",
      "2025-09-05 16:38:20,284 - INFO - 진행률: 2420/6900 (35.1%)\n",
      "2025-09-05 16:38:20,489 - INFO - 진행률: 2430/6900 (35.2%)\n",
      "2025-09-05 16:38:20,686 - INFO - 진행률: 2440/6900 (35.4%)\n",
      "2025-09-05 16:38:20,896 - INFO - 진행률: 2450/6900 (35.5%)\n",
      "2025-09-05 16:38:21,072 - INFO - 진행률: 2460/6900 (35.7%)\n",
      "2025-09-05 16:38:21,256 - INFO - 진행률: 2470/6900 (35.8%)\n",
      "2025-09-05 16:38:21,500 - INFO - 진행률: 2480/6900 (35.9%)\n",
      "2025-09-05 16:38:21,640 - INFO - 진행률: 2490/6900 (36.1%)\n",
      "2025-09-05 16:38:21,946 - INFO - 진행률: 2500/6900 (36.2%)\n",
      "2025-09-05 16:38:23,948 - INFO - 배치 처리 중: ID 2601 ~ 2700\n",
      "2025-09-05 16:38:24,911 - INFO - 진행률: 2510/6900 (36.4%)\n",
      "2025-09-05 16:38:25,054 - INFO - 진행률: 2520/6900 (36.5%)\n",
      "2025-09-05 16:38:25,254 - INFO - 진행률: 2530/6900 (36.7%)\n",
      "2025-09-05 16:38:25,387 - INFO - 진행률: 2540/6900 (36.8%)\n",
      "2025-09-05 16:38:25,567 - INFO - 진행률: 2550/6900 (37.0%)\n",
      "2025-09-05 16:38:25,741 - INFO - 진행률: 2560/6900 (37.1%)\n",
      "2025-09-05 16:38:25,902 - INFO - 진행률: 2570/6900 (37.2%)\n",
      "2025-09-05 16:38:26,059 - INFO - 진행률: 2580/6900 (37.4%)\n",
      "2025-09-05 16:38:26,259 - INFO - 진행률: 2590/6900 (37.5%)\n",
      "2025-09-05 16:38:27,270 - INFO - 진행률: 2600/6900 (37.7%)\n",
      "2025-09-05 16:38:29,274 - INFO - 배치 처리 중: ID 2701 ~ 2800\n",
      "2025-09-05 16:38:29,810 - INFO - 진행률: 2610/6900 (37.8%)\n",
      "2025-09-05 16:38:29,940 - INFO - 진행률: 2620/6900 (38.0%)\n",
      "2025-09-05 16:38:30,128 - INFO - 진행률: 2630/6900 (38.1%)\n",
      "2025-09-05 16:38:30,366 - INFO - 진행률: 2640/6900 (38.3%)\n",
      "2025-09-05 16:38:30,542 - INFO - 진행률: 2650/6900 (38.4%)\n",
      "2025-09-05 16:38:30,714 - INFO - 진행률: 2660/6900 (38.6%)\n",
      "2025-09-05 16:38:30,888 - INFO - 진행률: 2670/6900 (38.7%)\n",
      "2025-09-05 16:38:31,054 - INFO - 진행률: 2680/6900 (38.8%)\n",
      "2025-09-05 16:38:31,193 - INFO - 진행률: 2690/6900 (39.0%)\n",
      "2025-09-05 16:38:31,460 - INFO - 진행률: 2700/6900 (39.1%)\n",
      "2025-09-05 16:38:33,462 - INFO - 배치 처리 중: ID 2801 ~ 2900\n",
      "2025-09-05 16:38:33,819 - INFO - 진행률: 2710/6900 (39.3%)\n",
      "2025-09-05 16:38:34,049 - INFO - 진행률: 2720/6900 (39.4%)\n",
      "2025-09-05 16:38:34,241 - INFO - 진행률: 2730/6900 (39.6%)\n",
      "2025-09-05 16:38:34,400 - INFO - 진행률: 2740/6900 (39.7%)\n",
      "2025-09-05 16:38:34,557 - INFO - 진행률: 2750/6900 (39.9%)\n",
      "2025-09-05 16:38:34,670 - INFO - 진행률: 2760/6900 (40.0%)\n",
      "2025-09-05 16:38:34,837 - INFO - 진행률: 2770/6900 (40.1%)\n",
      "2025-09-05 16:38:35,030 - INFO - 진행률: 2780/6900 (40.3%)\n",
      "2025-09-05 16:38:35,157 - INFO - 진행률: 2790/6900 (40.4%)\n",
      "2025-09-05 16:38:35,353 - INFO - 진행률: 2800/6900 (40.6%)\n",
      "2025-09-05 16:38:37,356 - INFO - 배치 처리 중: ID 2901 ~ 3000\n",
      "2025-09-05 16:38:37,767 - INFO - 진행률: 2810/6900 (40.7%)\n",
      "2025-09-05 16:38:37,868 - INFO - 진행률: 2820/6900 (40.9%)\n",
      "2025-09-05 16:38:38,116 - INFO - 진행률: 2830/6900 (41.0%)\n",
      "2025-09-05 16:38:38,343 - INFO - 진행률: 2840/6900 (41.2%)\n",
      "2025-09-05 16:38:38,519 - INFO - 진행률: 2850/6900 (41.3%)\n",
      "2025-09-05 16:38:38,657 - INFO - 진행률: 2860/6900 (41.4%)\n",
      "2025-09-05 16:38:38,835 - INFO - 진행률: 2870/6900 (41.6%)\n",
      "2025-09-05 16:38:39,075 - INFO - 진행률: 2880/6900 (41.7%)\n",
      "2025-09-05 16:38:39,222 - INFO - 진행률: 2890/6900 (41.9%)\n",
      "2025-09-05 16:38:39,457 - INFO - 진행률: 2900/6900 (42.0%)\n",
      "2025-09-05 16:38:41,461 - INFO - 배치 처리 중: ID 3001 ~ 3100\n",
      "2025-09-05 16:38:41,873 - INFO - 진행률: 2910/6900 (42.2%)\n",
      "2025-09-05 16:38:41,994 - INFO - 진행률: 2920/6900 (42.3%)\n",
      "2025-09-05 16:38:42,217 - INFO - 진행률: 2930/6900 (42.5%)\n",
      "2025-09-05 16:38:42,537 - INFO - 진행률: 2940/6900 (42.6%)\n",
      "2025-09-05 16:38:42,634 - INFO - 진행률: 2950/6900 (42.8%)\n",
      "2025-09-05 16:38:42,893 - INFO - 진행률: 2960/6900 (42.9%)\n",
      "2025-09-05 16:38:43,084 - INFO - 진행률: 2970/6900 (43.0%)\n",
      "2025-09-05 16:38:43,243 - INFO - 진행률: 2980/6900 (43.2%)\n",
      "2025-09-05 16:38:43,388 - INFO - 진행률: 2990/6900 (43.3%)\n",
      "2025-09-05 16:38:43,584 - INFO - 진행률: 3000/6900 (43.5%)\n",
      "2025-09-05 16:38:45,588 - INFO - 배치 처리 중: ID 3101 ~ 3200\n",
      "2025-09-05 16:38:46,060 - INFO - 진행률: 3010/6900 (43.6%)\n",
      "2025-09-05 16:38:46,224 - INFO - 진행률: 3020/6900 (43.8%)\n",
      "2025-09-05 16:38:46,369 - INFO - 진행률: 3030/6900 (43.9%)\n",
      "2025-09-05 16:38:46,701 - INFO - 진행률: 3040/6900 (44.1%)\n",
      "2025-09-05 16:38:46,879 - INFO - 진행률: 3050/6900 (44.2%)\n",
      "2025-09-05 16:38:47,036 - INFO - 진행률: 3060/6900 (44.3%)\n",
      "2025-09-05 16:38:47,274 - INFO - 진행률: 3070/6900 (44.5%)\n",
      "2025-09-05 16:38:47,457 - INFO - 진행률: 3080/6900 (44.6%)\n",
      "2025-09-05 16:38:47,643 - INFO - 진행률: 3090/6900 (44.8%)\n",
      "2025-09-05 16:38:47,774 - INFO - 진행률: 3100/6900 (44.9%)\n",
      "2025-09-05 16:38:49,778 - INFO - 배치 처리 중: ID 3201 ~ 3300\n",
      "2025-09-05 16:38:50,168 - INFO - 진행률: 3110/6900 (45.1%)\n",
      "2025-09-05 16:38:50,293 - INFO - 진행률: 3120/6900 (45.2%)\n",
      "2025-09-05 16:38:50,481 - INFO - 진행률: 3130/6900 (45.4%)\n",
      "2025-09-05 16:38:50,606 - INFO - 진행률: 3140/6900 (45.5%)\n",
      "2025-09-05 16:38:50,782 - INFO - 진행률: 3150/6900 (45.7%)\n",
      "2025-09-05 16:38:50,944 - INFO - 진행률: 3160/6900 (45.8%)\n",
      "2025-09-05 16:38:51,265 - INFO - 진행률: 3170/6900 (45.9%)\n",
      "2025-09-05 16:38:51,431 - INFO - 진행률: 3180/6900 (46.1%)\n",
      "2025-09-05 16:38:51,683 - INFO - 진행률: 3190/6900 (46.2%)\n",
      "2025-09-05 16:38:52,012 - INFO - 진행률: 3200/6900 (46.4%)\n",
      "2025-09-05 16:38:54,015 - INFO - 배치 처리 중: ID 3301 ~ 3400\n",
      "2025-09-05 16:38:54,580 - INFO - 진행률: 3210/6900 (46.5%)\n",
      "2025-09-05 16:38:54,760 - INFO - 진행률: 3220/6900 (46.7%)\n",
      "2025-09-05 16:38:54,954 - INFO - 진행률: 3230/6900 (46.8%)\n",
      "2025-09-05 16:38:55,426 - INFO - 진행률: 3240/6900 (47.0%)\n",
      "2025-09-05 16:38:55,534 - INFO - 진행률: 3250/6900 (47.1%)\n",
      "2025-09-05 16:38:55,749 - INFO - 진행률: 3260/6900 (47.2%)\n",
      "2025-09-05 16:38:55,953 - INFO - 진행률: 3270/6900 (47.4%)\n",
      "2025-09-05 16:38:56,268 - INFO - 진행률: 3280/6900 (47.5%)\n",
      "2025-09-05 16:38:56,427 - INFO - 진행률: 3290/6900 (47.7%)\n",
      "2025-09-05 16:38:56,579 - INFO - 진행률: 3300/6900 (47.8%)\n",
      "2025-09-05 16:38:58,581 - INFO - 배치 처리 중: ID 3401 ~ 3500\n",
      "2025-09-05 16:38:59,246 - INFO - 진행률: 3310/6900 (48.0%)\n",
      "2025-09-05 16:38:59,407 - INFO - 진행률: 3320/6900 (48.1%)\n",
      "2025-09-05 16:38:59,633 - INFO - 진행률: 3330/6900 (48.3%)\n",
      "2025-09-05 16:38:59,828 - INFO - 진행률: 3340/6900 (48.4%)\n",
      "2025-09-05 16:39:00,009 - INFO - 진행률: 3350/6900 (48.6%)\n",
      "2025-09-05 16:39:00,225 - INFO - 진행률: 3360/6900 (48.7%)\n",
      "2025-09-05 16:39:00,532 - INFO - 진행률: 3370/6900 (48.8%)\n",
      "2025-09-05 16:39:00,729 - INFO - 진행률: 3380/6900 (49.0%)\n",
      "2025-09-05 16:39:01,076 - INFO - 진행률: 3390/6900 (49.1%)\n",
      "2025-09-05 16:39:01,283 - INFO - 진행률: 3400/6900 (49.3%)\n",
      "2025-09-05 16:39:03,285 - INFO - 배치 처리 중: ID 3501 ~ 3600\n",
      "2025-09-05 16:39:03,806 - INFO - 진행률: 3410/6900 (49.4%)\n",
      "2025-09-05 16:39:03,903 - INFO - 진행률: 3420/6900 (49.6%)\n",
      "2025-09-05 16:39:04,103 - INFO - 진행률: 3430/6900 (49.7%)\n",
      "2025-09-05 16:39:04,227 - INFO - 진행률: 3440/6900 (49.9%)\n",
      "2025-09-05 16:39:04,306 - INFO - 진행률: 3450/6900 (50.0%)\n",
      "2025-09-05 16:39:04,408 - INFO - 진행률: 3460/6900 (50.1%)\n",
      "2025-09-05 16:39:04,525 - INFO - 진행률: 3470/6900 (50.3%)\n",
      "2025-09-05 16:39:04,649 - INFO - 진행률: 3480/6900 (50.4%)\n",
      "2025-09-05 16:39:04,739 - INFO - 진행률: 3490/6900 (50.6%)\n",
      "2025-09-05 16:39:05,064 - INFO - 진행률: 3500/6900 (50.7%)\n",
      "2025-09-05 16:39:07,066 - INFO - 배치 처리 중: ID 3601 ~ 3700\n",
      "2025-09-05 16:39:07,512 - INFO - 진행률: 3510/6900 (50.9%)\n",
      "2025-09-05 16:39:07,691 - INFO - 진행률: 3520/6900 (51.0%)\n",
      "2025-09-05 16:39:07,880 - INFO - 진행률: 3530/6900 (51.2%)\n",
      "2025-09-05 16:39:08,081 - INFO - 진행률: 3540/6900 (51.3%)\n",
      "2025-09-05 16:39:08,366 - INFO - 진행률: 3550/6900 (51.4%)\n",
      "2025-09-05 16:39:08,490 - INFO - 진행률: 3560/6900 (51.6%)\n",
      "2025-09-05 16:39:08,646 - INFO - 진행률: 3570/6900 (51.7%)\n",
      "2025-09-05 16:39:08,901 - INFO - 진행률: 3580/6900 (51.9%)\n",
      "2025-09-05 16:39:09,103 - INFO - 진행률: 3590/6900 (52.0%)\n",
      "2025-09-05 16:39:09,294 - INFO - 진행률: 3600/6900 (52.2%)\n",
      "2025-09-05 16:39:11,296 - INFO - 배치 처리 중: ID 3701 ~ 3800\n",
      "2025-09-05 16:39:11,789 - INFO - 진행률: 3610/6900 (52.3%)\n",
      "2025-09-05 16:39:11,906 - INFO - 진행률: 3620/6900 (52.5%)\n",
      "2025-09-05 16:39:12,230 - INFO - 진행률: 3630/6900 (52.6%)\n",
      "2025-09-05 16:39:12,538 - INFO - 진행률: 3640/6900 (52.8%)\n",
      "2025-09-05 16:39:12,696 - INFO - 진행률: 3650/6900 (52.9%)\n",
      "2025-09-05 16:39:12,841 - INFO - 진행률: 3660/6900 (53.0%)\n",
      "2025-09-05 16:39:12,950 - INFO - 진행률: 3670/6900 (53.2%)\n",
      "2025-09-05 16:39:13,041 - INFO - 진행률: 3680/6900 (53.3%)\n",
      "2025-09-05 16:39:13,134 - INFO - 진행률: 3690/6900 (53.5%)\n",
      "2025-09-05 16:39:13,327 - INFO - 진행률: 3700/6900 (53.6%)\n",
      "2025-09-05 16:39:15,331 - INFO - 배치 처리 중: ID 3801 ~ 3900\n",
      "2025-09-05 16:39:15,533 - INFO - 진행률: 3710/6900 (53.8%)\n",
      "2025-09-05 16:39:15,650 - INFO - 진행률: 3720/6900 (53.9%)\n",
      "2025-09-05 16:39:15,788 - INFO - 진행률: 3730/6900 (54.1%)\n",
      "2025-09-05 16:39:15,848 - INFO - 진행률: 3740/6900 (54.2%)\n",
      "2025-09-05 16:39:15,961 - INFO - 진행률: 3750/6900 (54.3%)\n",
      "2025-09-05 16:39:16,029 - INFO - 진행률: 3760/6900 (54.5%)\n",
      "2025-09-05 16:39:16,154 - INFO - 진행률: 3770/6900 (54.6%)\n",
      "2025-09-05 16:39:16,310 - INFO - 진행률: 3780/6900 (54.8%)\n",
      "2025-09-05 16:39:16,435 - INFO - 진행률: 3790/6900 (54.9%)\n",
      "2025-09-05 16:39:16,553 - INFO - 진행률: 3800/6900 (55.1%)\n",
      "2025-09-05 16:39:18,557 - INFO - 배치 처리 중: ID 3901 ~ 4000\n",
      "2025-09-05 16:39:18,758 - INFO - 진행률: 3810/6900 (55.2%)\n",
      "2025-09-05 16:39:18,889 - INFO - 진행률: 3820/6900 (55.4%)\n",
      "2025-09-05 16:39:19,029 - INFO - 진행률: 3830/6900 (55.5%)\n",
      "2025-09-05 16:39:19,105 - INFO - 진행률: 3840/6900 (55.7%)\n",
      "2025-09-05 16:39:19,239 - INFO - 진행률: 3850/6900 (55.8%)\n",
      "2025-09-05 16:39:19,355 - INFO - 진행률: 3860/6900 (55.9%)\n",
      "2025-09-05 16:39:19,430 - INFO - 진행률: 3870/6900 (56.1%)\n",
      "2025-09-05 16:39:19,528 - INFO - 진행률: 3880/6900 (56.2%)\n",
      "2025-09-05 16:39:19,672 - INFO - 진행률: 3890/6900 (56.4%)\n",
      "2025-09-05 16:39:19,816 - INFO - 진행률: 3900/6900 (56.5%)\n",
      "2025-09-05 16:39:21,821 - INFO - 배치 처리 중: ID 4001 ~ 4100\n",
      "2025-09-05 16:39:22,014 - INFO - 진행률: 3910/6900 (56.7%)\n",
      "2025-09-05 16:39:22,137 - INFO - 진행률: 3920/6900 (56.8%)\n",
      "2025-09-05 16:39:22,177 - INFO - 진행률: 3930/6900 (57.0%)\n",
      "2025-09-05 16:39:22,326 - INFO - 진행률: 3940/6900 (57.1%)\n",
      "2025-09-05 16:39:22,469 - INFO - 진행률: 3950/6900 (57.2%)\n",
      "2025-09-05 16:39:22,524 - INFO - 진행률: 3960/6900 (57.4%)\n",
      "2025-09-05 16:39:22,672 - INFO - 진행률: 3970/6900 (57.5%)\n",
      "2025-09-05 16:39:22,813 - INFO - 진행률: 3980/6900 (57.7%)\n",
      "2025-09-05 16:39:22,934 - INFO - 진행률: 3990/6900 (57.8%)\n",
      "2025-09-05 16:39:23,139 - INFO - 진행률: 4000/6900 (58.0%)\n",
      "2025-09-05 16:39:25,141 - INFO - 배치 처리 중: ID 4101 ~ 4200\n",
      "2025-09-05 16:39:25,339 - INFO - 진행률: 4010/6900 (58.1%)\n",
      "2025-09-05 16:39:25,453 - INFO - 진행률: 4020/6900 (58.3%)\n",
      "2025-09-05 16:39:25,617 - INFO - 진행률: 4030/6900 (58.4%)\n",
      "2025-09-05 16:39:25,664 - INFO - 진행률: 4040/6900 (58.6%)\n",
      "2025-09-05 16:39:25,816 - INFO - 진행률: 4050/6900 (58.7%)\n",
      "2025-09-05 16:39:25,915 - INFO - 진행률: 4060/6900 (58.8%)\n",
      "2025-09-05 16:39:26,005 - INFO - 진행률: 4070/6900 (59.0%)\n",
      "2025-09-05 16:39:26,137 - INFO - 진행률: 4080/6900 (59.1%)\n",
      "2025-09-05 16:39:26,256 - INFO - 진행률: 4090/6900 (59.3%)\n",
      "2025-09-05 16:39:26,468 - INFO - 진행률: 4100/6900 (59.4%)\n",
      "2025-09-05 16:39:28,470 - INFO - 배치 처리 중: ID 4201 ~ 4300\n",
      "2025-09-05 16:39:28,683 - INFO - 진행률: 4110/6900 (59.6%)\n",
      "2025-09-05 16:39:28,800 - INFO - 진행률: 4120/6900 (59.7%)\n",
      "2025-09-05 16:39:28,940 - INFO - 진행률: 4130/6900 (59.9%)\n",
      "2025-09-05 16:39:29,017 - INFO - 진행률: 4140/6900 (60.0%)\n",
      "2025-09-05 16:39:29,210 - INFO - 진행률: 4150/6900 (60.1%)\n",
      "2025-09-05 16:39:29,301 - INFO - 진행률: 4160/6900 (60.3%)\n",
      "2025-09-05 16:39:29,436 - INFO - 진행률: 4170/6900 (60.4%)\n",
      "2025-09-05 16:39:29,590 - INFO - 진행률: 4180/6900 (60.6%)\n",
      "2025-09-05 16:39:29,724 - INFO - 진행률: 4190/6900 (60.7%)\n",
      "2025-09-05 16:39:29,887 - INFO - 진행률: 4200/6900 (60.9%)\n",
      "2025-09-05 16:39:31,889 - INFO - 배치 처리 중: ID 4301 ~ 4400\n",
      "2025-09-05 16:39:32,184 - INFO - 진행률: 4210/6900 (61.0%)\n",
      "2025-09-05 16:39:32,212 - INFO - 진행률: 4220/6900 (61.2%)\n",
      "2025-09-05 16:39:32,370 - INFO - 진행률: 4230/6900 (61.3%)\n",
      "2025-09-05 16:39:32,502 - INFO - 진행률: 4240/6900 (61.4%)\n",
      "2025-09-05 16:39:32,559 - INFO - 진행률: 4250/6900 (61.6%)\n",
      "2025-09-05 16:39:32,674 - INFO - 진행률: 4260/6900 (61.7%)\n",
      "2025-09-05 16:39:32,796 - INFO - 진행률: 4270/6900 (61.9%)\n",
      "2025-09-05 16:39:32,872 - INFO - 진행률: 4280/6900 (62.0%)\n",
      "2025-09-05 16:39:32,975 - INFO - 진행률: 4290/6900 (62.2%)\n",
      "2025-09-05 16:39:33,175 - INFO - 진행률: 4300/6900 (62.3%)\n",
      "2025-09-05 16:39:35,178 - INFO - 배치 처리 중: ID 4401 ~ 4500\n",
      "2025-09-05 16:39:35,377 - INFO - 진행률: 4310/6900 (62.5%)\n",
      "2025-09-05 16:39:35,501 - INFO - 진행률: 4320/6900 (62.6%)\n",
      "2025-09-05 16:39:35,661 - INFO - 진행률: 4330/6900 (62.8%)\n",
      "2025-09-05 16:39:35,716 - INFO - 진행률: 4340/6900 (62.9%)\n",
      "2025-09-05 16:39:35,848 - INFO - 진행률: 4350/6900 (63.0%)\n",
      "2025-09-05 16:39:35,942 - INFO - 진행률: 4360/6900 (63.2%)\n",
      "2025-09-05 16:39:36,032 - INFO - 진행률: 4370/6900 (63.3%)\n",
      "2025-09-05 16:39:36,134 - INFO - 진행률: 4380/6900 (63.5%)\n",
      "2025-09-05 16:39:36,275 - INFO - 진행률: 4390/6900 (63.6%)\n",
      "2025-09-05 16:39:36,747 - INFO - 진행률: 4400/6900 (63.8%)\n",
      "2025-09-05 16:39:38,752 - INFO - 배치 처리 중: ID 4501 ~ 4600\n",
      "2025-09-05 16:39:38,949 - INFO - 진행률: 4410/6900 (63.9%)\n",
      "2025-09-05 16:39:39,088 - INFO - 진행률: 4420/6900 (64.1%)\n",
      "2025-09-05 16:39:39,219 - INFO - 진행률: 4430/6900 (64.2%)\n",
      "2025-09-05 16:39:39,293 - INFO - 진행률: 4440/6900 (64.3%)\n",
      "2025-09-05 16:39:39,422 - INFO - 진행률: 4450/6900 (64.5%)\n",
      "2025-09-05 16:39:39,547 - INFO - 진행률: 4460/6900 (64.6%)\n",
      "2025-09-05 16:39:39,715 - INFO - 진행률: 4470/6900 (64.8%)\n",
      "2025-09-05 16:39:39,759 - INFO - 진행률: 4480/6900 (64.9%)\n",
      "2025-09-05 16:39:39,876 - INFO - 진행률: 4490/6900 (65.1%)\n",
      "2025-09-05 16:39:40,059 - INFO - 진행률: 4500/6900 (65.2%)\n",
      "2025-09-05 16:39:42,063 - INFO - 배치 처리 중: ID 4601 ~ 4700\n",
      "2025-09-05 16:39:42,261 - INFO - 진행률: 4510/6900 (65.4%)\n",
      "2025-09-05 16:39:42,347 - INFO - 진행률: 4520/6900 (65.5%)\n",
      "2025-09-05 16:39:42,443 - INFO - 진행률: 4530/6900 (65.7%)\n",
      "2025-09-05 16:39:42,563 - INFO - 진행률: 4540/6900 (65.8%)\n",
      "2025-09-05 16:39:42,698 - INFO - 진행률: 4550/6900 (65.9%)\n",
      "2025-09-05 16:39:42,830 - INFO - 진행률: 4560/6900 (66.1%)\n",
      "2025-09-05 16:39:42,899 - INFO - 진행률: 4570/6900 (66.2%)\n",
      "2025-09-05 16:39:43,031 - INFO - 진행률: 4580/6900 (66.4%)\n",
      "2025-09-05 16:39:43,105 - INFO - 진행률: 4590/6900 (66.5%)\n",
      "2025-09-05 16:39:43,326 - INFO - 진행률: 4600/6900 (66.7%)\n",
      "2025-09-05 16:39:45,328 - INFO - 배치 처리 중: ID 4701 ~ 4800\n",
      "2025-09-05 16:39:45,544 - INFO - 진행률: 4610/6900 (66.8%)\n",
      "2025-09-05 16:39:45,658 - INFO - 진행률: 4620/6900 (67.0%)\n",
      "2025-09-05 16:39:45,710 - INFO - 진행률: 4630/6900 (67.1%)\n",
      "2025-09-05 16:39:45,861 - INFO - 진행률: 4640/6900 (67.2%)\n",
      "2025-09-05 16:39:45,969 - INFO - 진행률: 4650/6900 (67.4%)\n",
      "2025-09-05 16:39:46,044 - INFO - 진행률: 4660/6900 (67.5%)\n",
      "2025-09-05 16:39:46,163 - INFO - 진행률: 4670/6900 (67.7%)\n",
      "2025-09-05 16:39:46,284 - INFO - 진행률: 4680/6900 (67.8%)\n",
      "2025-09-05 16:39:46,395 - INFO - 진행률: 4690/6900 (68.0%)\n",
      "2025-09-05 16:39:46,504 - INFO - 진행률: 4700/6900 (68.1%)\n",
      "2025-09-05 16:39:48,506 - INFO - 배치 처리 중: ID 4801 ~ 4900\n",
      "2025-09-05 16:39:48,705 - INFO - 진행률: 4710/6900 (68.3%)\n",
      "2025-09-05 16:39:48,840 - INFO - 진행률: 4720/6900 (68.4%)\n",
      "2025-09-05 16:39:48,988 - INFO - 진행률: 4730/6900 (68.6%)\n",
      "2025-09-05 16:39:49,030 - INFO - 진행률: 4740/6900 (68.7%)\n",
      "2025-09-05 16:39:49,164 - INFO - 진행률: 4750/6900 (68.8%)\n",
      "2025-09-05 16:39:49,288 - INFO - 진행률: 4760/6900 (69.0%)\n",
      "2025-09-05 16:39:49,375 - INFO - 진행률: 4770/6900 (69.1%)\n",
      "2025-09-05 16:39:49,464 - INFO - 진행률: 4780/6900 (69.3%)\n",
      "2025-09-05 16:39:49,623 - INFO - 진행률: 4790/6900 (69.4%)\n",
      "2025-09-05 16:39:49,787 - INFO - 진행률: 4800/6900 (69.6%)\n",
      "2025-09-05 16:39:51,790 - INFO - 배치 처리 중: ID 4901 ~ 5000\n",
      "2025-09-05 16:39:51,990 - INFO - 진행률: 4810/6900 (69.7%)\n",
      "2025-09-05 16:39:52,126 - INFO - 진행률: 4820/6900 (69.9%)\n",
      "2025-09-05 16:39:52,217 - INFO - 진행률: 4830/6900 (70.0%)\n",
      "2025-09-05 16:39:52,301 - INFO - 진행률: 4840/6900 (70.1%)\n",
      "2025-09-05 16:39:52,459 - INFO - 진행률: 4850/6900 (70.3%)\n",
      "2025-09-05 16:39:52,569 - INFO - 진행률: 4860/6900 (70.4%)\n",
      "2025-09-05 16:39:52,640 - INFO - 진행률: 4870/6900 (70.6%)\n",
      "2025-09-05 16:39:52,758 - INFO - 진행률: 4880/6900 (70.7%)\n",
      "2025-09-05 16:39:52,898 - INFO - 진행률: 4890/6900 (70.9%)\n",
      "2025-09-05 16:39:53,158 - INFO - 진행률: 4900/6900 (71.0%)\n",
      "2025-09-05 16:39:55,160 - INFO - 배치 처리 중: ID 5001 ~ 5100\n",
      "2025-09-05 16:39:55,413 - INFO - 진행률: 4910/6900 (71.2%)\n",
      "2025-09-05 16:39:55,519 - INFO - 진행률: 4920/6900 (71.3%)\n",
      "2025-09-05 16:39:55,690 - INFO - 진행률: 4930/6900 (71.4%)\n",
      "2025-09-05 16:39:55,778 - INFO - 진행률: 4940/6900 (71.6%)\n",
      "2025-09-05 16:39:55,871 - INFO - 진행률: 4950/6900 (71.7%)\n",
      "2025-09-05 16:39:56,026 - INFO - 진행률: 4960/6900 (71.9%)\n",
      "2025-09-05 16:39:56,151 - INFO - 진행률: 4970/6900 (72.0%)\n",
      "2025-09-05 16:39:56,254 - INFO - 진행률: 4980/6900 (72.2%)\n",
      "2025-09-05 16:39:56,332 - INFO - 진행률: 4990/6900 (72.3%)\n",
      "2025-09-05 16:39:56,572 - INFO - 진행률: 5000/6900 (72.5%)\n",
      "2025-09-05 16:39:58,574 - INFO - 배치 처리 중: ID 5101 ~ 5200\n",
      "2025-09-05 16:39:58,783 - INFO - 진행률: 5010/6900 (72.6%)\n",
      "2025-09-05 16:39:58,906 - INFO - 진행률: 5020/6900 (72.8%)\n",
      "2025-09-05 16:39:59,057 - INFO - 진행률: 5030/6900 (72.9%)\n",
      "2025-09-05 16:39:59,092 - INFO - 진행률: 5040/6900 (73.0%)\n",
      "2025-09-05 16:39:59,225 - INFO - 진행률: 5050/6900 (73.2%)\n",
      "2025-09-05 16:39:59,263 - INFO - 진행률: 5060/6900 (73.3%)\n",
      "2025-09-05 16:39:59,411 - INFO - 진행률: 5070/6900 (73.5%)\n",
      "2025-09-05 16:39:59,548 - INFO - 진행률: 5080/6900 (73.6%)\n",
      "2025-09-05 16:39:59,677 - INFO - 진행률: 5090/6900 (73.8%)\n",
      "2025-09-05 16:39:59,821 - INFO - 진행률: 5100/6900 (73.9%)\n",
      "2025-09-05 16:40:01,825 - INFO - 배치 처리 중: ID 5201 ~ 5300\n",
      "2025-09-05 16:40:02,018 - INFO - 진행률: 5110/6900 (74.1%)\n",
      "2025-09-05 16:40:02,153 - INFO - 진행률: 5120/6900 (74.2%)\n",
      "2025-09-05 16:40:02,294 - INFO - 진행률: 5130/6900 (74.3%)\n",
      "2025-09-05 16:40:02,336 - INFO - 진행률: 5140/6900 (74.5%)\n",
      "2025-09-05 16:40:02,469 - INFO - 진행률: 5150/6900 (74.6%)\n",
      "2025-09-05 16:40:02,746 - INFO - 진행률: 5160/6900 (74.8%)\n",
      "2025-09-05 16:40:08,594 - INFO - 진행률: 5170/6900 (74.9%)\n",
      "2025-09-05 16:40:08,793 - INFO - 진행률: 5180/6900 (75.1%)\n",
      "2025-09-05 16:40:08,816 - INFO - 진행률: 5190/6900 (75.2%)\n",
      "2025-09-05 16:40:09,096 - INFO - 진행률: 5200/6900 (75.4%)\n",
      "2025-09-05 16:40:11,100 - INFO - 배치 처리 중: ID 5301 ~ 5400\n",
      "2025-09-05 16:40:11,301 - INFO - 진행률: 5210/6900 (75.5%)\n",
      "2025-09-05 16:40:11,439 - INFO - 진행률: 5220/6900 (75.7%)\n",
      "2025-09-05 16:40:11,484 - INFO - 진행률: 5230/6900 (75.8%)\n",
      "2025-09-05 16:40:11,620 - INFO - 진행률: 5240/6900 (75.9%)\n",
      "2025-09-05 16:40:11,777 - INFO - 진행률: 5250/6900 (76.1%)\n",
      "2025-09-05 16:40:11,832 - INFO - 진행률: 5260/6900 (76.2%)\n",
      "2025-09-05 16:40:11,948 - INFO - 진행률: 5270/6900 (76.4%)\n",
      "2025-09-05 16:40:12,086 - INFO - 진행률: 5280/6900 (76.5%)\n",
      "2025-09-05 16:40:12,234 - INFO - 진행률: 5290/6900 (76.7%)\n",
      "2025-09-05 16:40:12,383 - INFO - 진행률: 5300/6900 (76.8%)\n",
      "2025-09-05 16:40:14,387 - INFO - 배치 처리 중: ID 5401 ~ 5500\n",
      "2025-09-05 16:40:14,579 - INFO - 진행률: 5310/6900 (77.0%)\n",
      "2025-09-05 16:40:14,726 - INFO - 진행률: 5320/6900 (77.1%)\n",
      "2025-09-05 16:40:14,786 - INFO - 진행률: 5330/6900 (77.2%)\n",
      "2025-09-05 16:40:14,893 - INFO - 진행률: 5340/6900 (77.4%)\n",
      "2025-09-05 16:40:15,030 - INFO - 진행률: 5350/6900 (77.5%)\n",
      "2025-09-05 16:40:15,081 - INFO - 진행률: 5360/6900 (77.7%)\n",
      "2025-09-05 16:40:15,201 - INFO - 진행률: 5370/6900 (77.8%)\n",
      "2025-09-05 16:40:15,310 - INFO - 진행률: 5380/6900 (78.0%)\n",
      "2025-09-05 16:40:15,392 - INFO - 진행률: 5390/6900 (78.1%)\n",
      "2025-09-05 16:40:15,567 - INFO - 진행률: 5400/6900 (78.3%)\n",
      "2025-09-05 16:40:17,570 - INFO - 배치 처리 중: ID 5501 ~ 5600\n",
      "2025-09-05 16:40:17,762 - INFO - 진행률: 5410/6900 (78.4%)\n",
      "2025-09-05 16:40:17,900 - INFO - 진행률: 5420/6900 (78.6%)\n",
      "2025-09-05 16:40:18,047 - INFO - 진행률: 5430/6900 (78.7%)\n",
      "2025-09-05 16:40:18,100 - INFO - 진행률: 5440/6900 (78.8%)\n",
      "2025-09-05 16:40:18,249 - INFO - 진행률: 5450/6900 (79.0%)\n",
      "2025-09-05 16:40:18,342 - INFO - 진행률: 5460/6900 (79.1%)\n",
      "2025-09-05 16:40:18,530 - INFO - 진행률: 5470/6900 (79.3%)\n",
      "2025-09-05 16:40:18,585 - INFO - 진행률: 5480/6900 (79.4%)\n",
      "2025-09-05 16:40:18,735 - INFO - 진행률: 5490/6900 (79.6%)\n",
      "2025-09-05 16:40:19,073 - INFO - 진행률: 5500/6900 (79.7%)\n",
      "2025-09-05 16:40:21,077 - INFO - 배치 처리 중: ID 5601 ~ 5700\n",
      "2025-09-05 16:40:21,294 - INFO - 진행률: 5510/6900 (79.9%)\n",
      "2025-09-05 16:40:21,411 - INFO - 진행률: 5520/6900 (80.0%)\n",
      "2025-09-05 16:40:21,486 - INFO - 진행률: 5530/6900 (80.1%)\n",
      "2025-09-05 16:40:21,585 - INFO - 진행률: 5540/6900 (80.3%)\n",
      "2025-09-05 16:40:21,723 - INFO - 진행률: 5550/6900 (80.4%)\n",
      "2025-09-05 16:40:21,779 - INFO - 진행률: 5560/6900 (80.6%)\n",
      "2025-09-05 16:40:21,890 - INFO - 진행률: 5570/6900 (80.7%)\n",
      "2025-09-05 16:40:22,014 - INFO - 진행률: 5580/6900 (80.9%)\n",
      "2025-09-05 16:40:22,099 - INFO - 진행률: 5590/6900 (81.0%)\n",
      "2025-09-05 16:40:22,253 - INFO - 진행률: 5600/6900 (81.2%)\n",
      "2025-09-05 16:40:24,255 - INFO - 배치 처리 중: ID 5701 ~ 5800\n",
      "2025-09-05 16:40:24,450 - INFO - 진행률: 5610/6900 (81.3%)\n",
      "2025-09-05 16:40:24,587 - INFO - 진행률: 5620/6900 (81.4%)\n",
      "2025-09-05 16:40:24,737 - INFO - 진행률: 5630/6900 (81.6%)\n",
      "2025-09-05 16:40:24,772 - INFO - 진행률: 5640/6900 (81.7%)\n",
      "2025-09-05 16:40:24,933 - INFO - 진행률: 5650/6900 (81.9%)\n",
      "2025-09-05 16:40:25,067 - INFO - 진행률: 5660/6900 (82.0%)\n",
      "2025-09-05 16:40:25,140 - INFO - 진행률: 5670/6900 (82.2%)\n",
      "2025-09-05 16:40:25,258 - INFO - 진행률: 5680/6900 (82.3%)\n",
      "2025-09-05 16:40:25,391 - INFO - 진행률: 5690/6900 (82.5%)\n",
      "2025-09-05 16:40:25,758 - INFO - 진행률: 5700/6900 (82.6%)\n",
      "2025-09-05 16:40:27,782 - INFO - 배치 처리 중: ID 5801 ~ 5900\n",
      "2025-09-05 16:40:27,987 - INFO - 진행률: 5710/6900 (82.8%)\n",
      "2025-09-05 16:40:28,108 - INFO - 진행률: 5720/6900 (82.9%)\n",
      "2025-09-05 16:40:28,175 - INFO - 진행률: 5730/6900 (83.0%)\n",
      "2025-09-05 16:40:28,312 - INFO - 진행률: 5740/6900 (83.2%)\n",
      "2025-09-05 16:40:28,433 - INFO - 진행률: 5750/6900 (83.3%)\n",
      "2025-09-05 16:40:28,531 - INFO - 진행률: 5760/6900 (83.5%)\n",
      "2025-09-05 16:40:28,626 - INFO - 진행률: 5770/6900 (83.6%)\n",
      "2025-09-05 16:40:28,718 - INFO - 진행률: 5780/6900 (83.8%)\n",
      "2025-09-05 16:40:28,801 - INFO - 진행률: 5790/6900 (83.9%)\n",
      "2025-09-05 16:40:28,985 - INFO - 진행률: 5800/6900 (84.1%)\n",
      "2025-09-05 16:40:30,989 - INFO - 배치 처리 중: ID 5901 ~ 6000\n",
      "2025-09-05 16:40:31,295 - INFO - 진행률: 5810/6900 (84.2%)\n",
      "2025-09-05 16:40:31,328 - INFO - 진행률: 5820/6900 (84.3%)\n",
      "2025-09-05 16:40:31,495 - INFO - 진행률: 5830/6900 (84.5%)\n",
      "2025-09-05 16:40:31,616 - INFO - 진행률: 5840/6900 (84.6%)\n",
      "2025-09-05 16:40:31,680 - INFO - 진행률: 5850/6900 (84.8%)\n",
      "2025-09-05 16:40:31,806 - INFO - 진행률: 5860/6900 (84.9%)\n",
      "2025-09-05 16:40:31,920 - INFO - 진행률: 5870/6900 (85.1%)\n",
      "2025-09-05 16:40:32,004 - INFO - 진행률: 5880/6900 (85.2%)\n",
      "2025-09-05 16:40:32,113 - INFO - 진행률: 5890/6900 (85.4%)\n",
      "2025-09-05 16:40:32,410 - INFO - 진행률: 5900/6900 (85.5%)\n",
      "2025-09-05 16:40:34,412 - INFO - 배치 처리 중: ID 6001 ~ 6100\n",
      "2025-09-05 16:40:34,898 - INFO - 진행률: 5910/6900 (85.7%)\n",
      "2025-09-05 16:40:35,194 - INFO - 진행률: 5920/6900 (85.8%)\n",
      "2025-09-05 16:40:35,459 - INFO - 진행률: 5930/6900 (85.9%)\n",
      "2025-09-05 16:40:35,834 - INFO - 진행률: 5940/6900 (86.1%)\n",
      "2025-09-05 16:40:35,966 - INFO - 진행률: 5950/6900 (86.2%)\n",
      "2025-09-05 16:40:36,137 - INFO - 진행률: 5960/6900 (86.4%)\n",
      "2025-09-05 16:40:36,374 - INFO - 진행률: 5970/6900 (86.5%)\n",
      "2025-09-05 16:40:36,608 - INFO - 진행률: 5980/6900 (86.7%)\n",
      "2025-09-05 16:40:36,737 - INFO - 진행률: 5990/6900 (86.8%)\n",
      "2025-09-05 16:40:37,036 - INFO - 진행률: 6000/6900 (87.0%)\n",
      "2025-09-05 16:40:39,040 - INFO - 배치 처리 중: ID 6101 ~ 6200\n",
      "2025-09-05 16:40:39,664 - INFO - 진행률: 6010/6900 (87.1%)\n",
      "2025-09-05 16:40:39,800 - INFO - 진행률: 6020/6900 (87.2%)\n",
      "2025-09-05 16:40:40,154 - INFO - 진행률: 6030/6900 (87.4%)\n",
      "2025-09-05 16:40:40,312 - INFO - 진행률: 6040/6900 (87.5%)\n",
      "2025-09-05 16:40:40,483 - INFO - 진행률: 6050/6900 (87.7%)\n",
      "2025-09-05 16:40:40,756 - INFO - 진행률: 6060/6900 (87.8%)\n",
      "2025-09-05 16:40:40,989 - INFO - 진행률: 6070/6900 (88.0%)\n",
      "2025-09-05 16:40:41,181 - INFO - 진행률: 6080/6900 (88.1%)\n",
      "2025-09-05 16:40:41,373 - INFO - 진행률: 6090/6900 (88.3%)\n",
      "2025-09-05 16:40:41,605 - INFO - 진행률: 6100/6900 (88.4%)\n",
      "2025-09-05 16:40:43,618 - INFO - 배치 처리 중: ID 6201 ~ 6300\n",
      "2025-09-05 16:40:44,729 - INFO - 진행률: 6110/6900 (88.6%)\n",
      "2025-09-05 16:40:44,841 - INFO - 진행률: 6120/6900 (88.7%)\n",
      "2025-09-05 16:40:45,101 - INFO - 진행률: 6130/6900 (88.8%)\n",
      "2025-09-05 16:40:45,354 - INFO - 진행률: 6140/6900 (89.0%)\n",
      "2025-09-05 16:40:45,504 - INFO - 진행률: 6150/6900 (89.1%)\n",
      "2025-09-05 16:40:45,667 - INFO - 진행률: 6160/6900 (89.3%)\n",
      "2025-09-05 16:40:45,895 - INFO - 진행률: 6170/6900 (89.4%)\n",
      "2025-09-05 16:40:46,128 - INFO - 진행률: 6180/6900 (89.6%)\n",
      "2025-09-05 16:40:46,566 - INFO - 진행률: 6190/6900 (89.7%)\n",
      "2025-09-05 16:40:46,714 - INFO - 진행률: 6200/6900 (89.9%)\n",
      "2025-09-05 16:40:48,723 - INFO - 배치 처리 중: ID 6301 ~ 6400\n",
      "2025-09-05 16:40:49,746 - INFO - 진행률: 6210/6900 (90.0%)\n",
      "2025-09-05 16:40:49,911 - INFO - 진행률: 6220/6900 (90.1%)\n",
      "2025-09-05 16:40:50,241 - INFO - 진행률: 6230/6900 (90.3%)\n",
      "2025-09-05 16:40:50,405 - INFO - 진행률: 6240/6900 (90.4%)\n",
      "2025-09-05 16:40:50,705 - INFO - 진행률: 6250/6900 (90.6%)\n",
      "2025-09-05 16:40:50,900 - INFO - 진행률: 6260/6900 (90.7%)\n",
      "2025-09-05 16:40:51,229 - INFO - 진행률: 6270/6900 (90.9%)\n",
      "2025-09-05 16:40:51,506 - INFO - 진행률: 6280/6900 (91.0%)\n",
      "2025-09-05 16:40:51,644 - INFO - 진행률: 6290/6900 (91.2%)\n",
      "2025-09-05 16:40:51,932 - INFO - 진행률: 6300/6900 (91.3%)\n",
      "2025-09-05 16:40:53,934 - INFO - 배치 처리 중: ID 6401 ~ 6500\n",
      "2025-09-05 16:40:54,678 - INFO - 진행률: 6310/6900 (91.4%)\n",
      "2025-09-05 16:40:54,916 - INFO - 진행률: 6320/6900 (91.6%)\n",
      "2025-09-05 16:40:55,126 - INFO - 진행률: 6330/6900 (91.7%)\n",
      "2025-09-05 16:40:55,408 - INFO - 진행률: 6340/6900 (91.9%)\n",
      "2025-09-05 16:40:55,724 - INFO - 진행률: 6350/6900 (92.0%)\n",
      "2025-09-05 16:40:56,208 - INFO - 진행률: 6360/6900 (92.2%)\n",
      "2025-09-05 16:40:56,374 - INFO - 진행률: 6370/6900 (92.3%)\n",
      "2025-09-05 16:40:56,585 - INFO - 진행률: 6380/6900 (92.5%)\n",
      "2025-09-05 16:40:56,757 - INFO - 진행률: 6390/6900 (92.6%)\n",
      "2025-09-05 16:40:56,955 - INFO - 진행률: 6400/6900 (92.8%)\n",
      "2025-09-05 16:40:58,960 - INFO - 배치 처리 중: ID 6501 ~ 6600\n",
      "2025-09-05 16:40:59,562 - INFO - 진행률: 6410/6900 (92.9%)\n",
      "2025-09-05 16:40:59,667 - INFO - 진행률: 6420/6900 (93.0%)\n",
      "2025-09-05 16:40:59,766 - INFO - 진행률: 6430/6900 (93.2%)\n",
      "2025-09-05 16:41:00,158 - INFO - 진행률: 6440/6900 (93.3%)\n",
      "2025-09-05 16:41:00,513 - INFO - 진행률: 6450/6900 (93.5%)\n",
      "2025-09-05 16:41:00,671 - INFO - 진행률: 6460/6900 (93.6%)\n",
      "2025-09-05 16:41:00,895 - INFO - 진행률: 6470/6900 (93.8%)\n",
      "2025-09-05 16:41:01,128 - INFO - 진행률: 6480/6900 (93.9%)\n",
      "2025-09-05 16:41:01,301 - INFO - 진행률: 6490/6900 (94.1%)\n",
      "2025-09-05 16:41:01,590 - INFO - 진행률: 6500/6900 (94.2%)\n",
      "2025-09-05 16:41:03,600 - INFO - 배치 처리 중: ID 6601 ~ 6700\n",
      "2025-09-05 16:41:04,049 - INFO - 진행률: 6510/6900 (94.3%)\n",
      "2025-09-05 16:41:04,241 - INFO - 진행률: 6520/6900 (94.5%)\n",
      "2025-09-05 16:41:04,504 - INFO - 진행률: 6530/6900 (94.6%)\n",
      "2025-09-05 16:41:04,688 - INFO - 진행률: 6540/6900 (94.8%)\n",
      "2025-09-05 16:41:05,160 - INFO - 진행률: 6550/6900 (94.9%)\n",
      "2025-09-05 16:41:05,296 - INFO - 진행률: 6560/6900 (95.1%)\n",
      "2025-09-05 16:41:05,502 - INFO - 진행률: 6570/6900 (95.2%)\n",
      "2025-09-05 16:41:05,715 - INFO - 진행률: 6580/6900 (95.4%)\n",
      "2025-09-05 16:41:05,959 - INFO - 진행률: 6590/6900 (95.5%)\n",
      "2025-09-05 16:41:06,622 - INFO - 진행률: 6600/6900 (95.7%)\n",
      "2025-09-05 16:41:08,625 - INFO - 배치 처리 중: ID 6701 ~ 6800\n",
      "2025-09-05 16:41:09,076 - INFO - 진행률: 6610/6900 (95.8%)\n",
      "2025-09-05 16:41:09,241 - INFO - 진행률: 6620/6900 (95.9%)\n",
      "2025-09-05 16:41:09,426 - INFO - 진행률: 6630/6900 (96.1%)\n",
      "2025-09-05 16:41:09,609 - INFO - 진행률: 6640/6900 (96.2%)\n",
      "2025-09-05 16:41:10,025 - INFO - 진행률: 6650/6900 (96.4%)\n",
      "2025-09-05 16:41:10,182 - INFO - 진행률: 6660/6900 (96.5%)\n",
      "2025-09-05 16:41:10,488 - INFO - 진행률: 6670/6900 (96.7%)\n",
      "2025-09-05 16:41:10,644 - INFO - 진행률: 6680/6900 (96.8%)\n",
      "2025-09-05 16:41:10,842 - INFO - 진행률: 6690/6900 (97.0%)\n",
      "2025-09-05 16:41:11,142 - INFO - 진행률: 6700/6900 (97.1%)\n",
      "2025-09-05 16:41:13,157 - INFO - 배치 처리 중: ID 6801 ~ 6900\n",
      "2025-09-05 16:41:13,608 - INFO - 진행률: 6710/6900 (97.2%)\n",
      "2025-09-05 16:41:13,791 - INFO - 진행률: 6720/6900 (97.4%)\n",
      "2025-09-05 16:41:13,984 - INFO - 진행률: 6730/6900 (97.5%)\n",
      "2025-09-05 16:41:14,233 - INFO - 진행률: 6740/6900 (97.7%)\n",
      "2025-09-05 16:41:14,613 - INFO - 진행률: 6750/6900 (97.8%)\n",
      "2025-09-05 16:41:14,724 - INFO - 진행률: 6760/6900 (98.0%)\n",
      "2025-09-05 16:41:14,940 - INFO - 진행률: 6770/6900 (98.1%)\n",
      "2025-09-05 16:41:15,154 - INFO - 진행률: 6780/6900 (98.3%)\n",
      "2025-09-05 16:41:15,254 - INFO - 진행률: 6790/6900 (98.4%)\n",
      "2025-09-05 16:41:15,550 - INFO - 진행률: 6800/6900 (98.6%)\n",
      "2025-09-05 16:41:17,552 - INFO - 배치 처리 중: ID 6901 ~ 7000\n",
      "2025-09-05 16:41:17,988 - INFO - 진행률: 6810/6900 (98.7%)\n",
      "2025-09-05 16:41:18,135 - INFO - 진행률: 6820/6900 (98.8%)\n",
      "2025-09-05 16:41:18,277 - INFO - 진행률: 6830/6900 (99.0%)\n",
      "2025-09-05 16:41:18,348 - INFO - 진행률: 6840/6900 (99.1%)\n",
      "2025-09-05 16:41:18,450 - INFO - 진행률: 6850/6900 (99.3%)\n",
      "2025-09-05 16:41:18,598 - INFO - 진행률: 6860/6900 (99.4%)\n",
      "2025-09-05 16:41:18,673 - INFO - 진행률: 6870/6900 (99.6%)\n",
      "2025-09-05 16:41:18,799 - INFO - 진행률: 6880/6900 (99.7%)\n",
      "2025-09-05 16:41:18,890 - INFO - 진행률: 6890/6900 (99.9%)\n",
      "2025-09-05 16:41:19,085 - INFO - 진행률: 6900/6900 (100.0%)\n",
      "2025-09-05 16:41:21,142 - INFO - CSV 파일 저장 완료: anilife_data_20250905_164121.csv\n",
      "2025-09-05 16:41:21,143 - INFO - 성공 데이터: 4398개 항목\n",
      "2025-09-05 16:41:21,152 - INFO - CSV 파일 저장 완료: anilife_errors_20250905_164121.csv\n",
      "2025-09-05 16:41:21,153 - INFO - 에러 데이터: 2502개 항목\n",
      "2025-09-05 16:41:21,153 - INFO - \n",
      "크롤링 완료 통계:\n",
      "2025-09-05 16:41:21,154 - INFO - - 전체: 6900개\n",
      "2025-09-05 16:41:21,154 - INFO - - 성공: 4398개\n",
      "2025-09-05 16:41:21,155 - INFO - - 실패: 2502개\n",
      "2025-09-05 16:41:21,155 - INFO - - 성공률: 63.7%\n",
      "2025-09-05 16:41:21,156 - INFO - \n",
      "총 소요 시간: 0시간 4분 55초\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Anilife 애니메이션 대량 크롤링 스크립트\n",
    "ID 101부터 7000까지 병렬로 크롤링하여 CSV로 저장\n",
    "\"\"\"\n",
    "\n",
    "import csv\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from typing import Dict, List, Optional\n",
    "from datetime import datetime\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 이전에 작성한 AnilifeScraper 클래스를 import\n",
    "# from anilife_scraper import AnilifeScraper\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# 로깅 설정\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('crawling.log', encoding='utf-8'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "class AnilifeScraper:\n",
    "    \"\"\"기존 스크래퍼 클래스 (간소화 버전)\"\"\"\n",
    "    def __init__(self):\n",
    "        self.headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) StepByStepCrawler/0.1\",\n",
    "            \"Accept-Language\": \"ko-KR,ko;q=0.9,en-US;q=0.8\"\n",
    "        }\n",
    "\n",
    "    def scrape_anime_info(self, url: str) -> Dict:\n",
    "        \"\"\"애니메이션 정보를 크롤링하는 메인 함수\"\"\"\n",
    "        try:\n",
    "            if \"tab=info\" not in url:\n",
    "                if \"?\" in url:\n",
    "                    url = url.split(\"?\")[0] + \"?tab=info\"\n",
    "                else:\n",
    "                    url = url + \"?tab=info\"\n",
    "\n",
    "            resp = requests.get(url, headers=self.headers, timeout=10)\n",
    "\n",
    "            if resp.status_code != 200:\n",
    "                return {\"error\": f\"HTTP {resp.status_code}\"}\n",
    "\n",
    "            soup = BeautifulSoup(resp.text, \"lxml\")\n",
    "            nuxt_data = self.extract_nuxt_data(resp.text)\n",
    "\n",
    "            # 간소화된 데이터 추출\n",
    "            content_detail = nuxt_data.get('pinia', {}).get('content', {}).get('contentDetail', {})\n",
    "\n",
    "            anime_info = {\n",
    "                \"id\": content_detail.get('id', ''),\n",
    "                \"title_kr\": content_detail.get('name', {}).get('kr', ''),\n",
    "                \"title_en\": content_detail.get('name', {}).get('en', ''),\n",
    "                \"title_jp\": content_detail.get('name', {}).get('jp', ''),\n",
    "                \"format\": content_detail.get('format', ''),\n",
    "                \"status\": content_detail.get('status', ''),\n",
    "                \"year\": content_detail.get('season', {}).get('year', ''),\n",
    "                \"quarter\": content_detail.get('season', {}).get('quarter', ''),\n",
    "                \"start_date\": content_detail.get('startDate', ''),\n",
    "                \"end_date\": content_detail.get('endDate', ''),\n",
    "                \"episodes\": content_detail.get('totalEpisode', ''),\n",
    "                \"duration\": content_detail.get('duration', ''),\n",
    "                \"genres\": '|'.join(content_detail.get('genre', [])),\n",
    "                \"tags\": '|'.join([tag.get('name', '') if isinstance(tag, dict) else tag\n",
    "                                 for tag in content_detail.get('tag', [])]),\n",
    "                \"description\": content_detail.get('description', ''),\n",
    "                \"url\": url\n",
    "            }\n",
    "\n",
    "            return anime_info\n",
    "\n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "    def extract_nuxt_data(self, html_content: str) -> Dict:\n",
    "        \"\"\"Nuxt 데이터 추출\"\"\"\n",
    "        try:\n",
    "            pattern = r'window\\.__NUXT__=\\(function\\([^)]*\\)\\{return (.+?)\\}\\)\\([^)]+\\)'\n",
    "            match = re.search(pattern, html_content, re.DOTALL)\n",
    "\n",
    "            if match:\n",
    "                json_str = match.group(1)\n",
    "\n",
    "                replacements = {\n",
    "                    r'\\ba\\b': 'false',\n",
    "                    r'\\bb\\b': '1',\n",
    "                    r'\\bc\\b': 'true',\n",
    "                    r'\\bd\\b': 'null',\n",
    "                    r'\\be\\b': '\"system\"',\n",
    "                    r'\\bf\\b': '\"https://anilife.app\"',\n",
    "                    r'\\bg\\b': '\"N/A\"'\n",
    "                }\n",
    "\n",
    "                for pattern, value in replacements.items():\n",
    "                    json_str = re.sub(pattern, value, json_str)\n",
    "\n",
    "                return json.loads(json_str)\n",
    "\n",
    "            return {}\n",
    "        except:\n",
    "            return {}\n",
    "\n",
    "\n",
    "class BulkCrawler:\n",
    "    \"\"\"대량 크롤링 관리 클래스\"\"\"\n",
    "\n",
    "    def __init__(self, start_id: int = 101, end_id: int = 7000, max_workers: int = 10):\n",
    "        self.start_id = start_id\n",
    "        self.end_id = end_id\n",
    "        self.max_workers = max_workers\n",
    "        self.scraper = AnilifeScraper()\n",
    "        self.results = []\n",
    "        self.failed_ids = []\n",
    "\n",
    "    def crawl_single_anime(self, anime_id: int) -> Optional[Dict]:\n",
    "        \"\"\"단일 애니메이션 크롤링\"\"\"\n",
    "        url = f\"https://anilife.app/content/{anime_id}\"\n",
    "\n",
    "        try:\n",
    "            result = self.scraper.scrape_anime_info(url)\n",
    "\n",
    "            if \"error\" in result:\n",
    "                logging.warning(f\"ID {anime_id} 크롤링 실패: {result['error']}\")\n",
    "                self.failed_ids.append(anime_id)\n",
    "                return None\n",
    "\n",
    "            # ID가 없으면 수동으로 추가\n",
    "            if not result.get('id'):\n",
    "                result['id'] = anime_id\n",
    "\n",
    "            # 데이터 유효성 검사\n",
    "            if not any([result.get('title_kr'), result.get('title_en'), result.get('title_jp')]):\n",
    "                logging.warning(f\"ID {anime_id}: 제목이 없음\")\n",
    "                self.failed_ids.append(anime_id)\n",
    "                return None\n",
    "\n",
    "            logging.debug(f\"ID {anime_id} 성공: {result.get('title_kr', 'No title')}\")\n",
    "            return result\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"ID {anime_id} 처리 중 에러: {str(e)}\")\n",
    "            self.failed_ids.append(anime_id)\n",
    "            return None\n",
    "\n",
    "    def save_to_csv(self, data: List[Dict], filename: str):\n",
    "        \"\"\"결과를 CSV로 저장\"\"\"\n",
    "        if not data:\n",
    "            logging.warning(\"저장할 데이터가 없습니다.\")\n",
    "            return\n",
    "\n",
    "        # CSV 필드명\n",
    "        fieldnames = [\n",
    "            'id', 'title_kr', 'title_en', 'title_jp',\n",
    "            'format', 'status', 'year', 'quarter',\n",
    "            'start_date', 'end_date', 'episodes', 'duration',\n",
    "            'genres', 'tags', 'description', 'url'\n",
    "        ]\n",
    "\n",
    "        with open(filename, 'w', newline='', encoding='utf-8-sig') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "\n",
    "            for item in data:\n",
    "                # 누락된 필드를 빈 문자열로 채우기\n",
    "                row = {field: item.get(field, '') for field in fieldnames}\n",
    "                writer.writerow(row)\n",
    "\n",
    "        logging.info(f\"데이터가 {filename}에 저장되었습니다.\")\n",
    "\n",
    "    def save_checkpoint(self, checkpoint_id: int):\n",
    "        \"\"\"진행 상황 체크포인트 저장\"\"\"\n",
    "        checkpoint_data = {\n",
    "            'last_id': checkpoint_id,\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'total_collected': len(self.results),\n",
    "            'failed_ids': self.failed_ids\n",
    "        }\n",
    "\n",
    "        with open('checkpoint.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(checkpoint_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    def load_checkpoint(self) -> Optional[int]:\n",
    "        \"\"\"체크포인트에서 재시작 위치 로드\"\"\"\n",
    "        if os.path.exists('checkpoint.json'):\n",
    "            with open('checkpoint.json', 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "                return data.get('last_id', self.start_id)\n",
    "        return self.start_id\n",
    "\n",
    "    def run_parallel(self):\n",
    "        \"\"\"병렬 크롤링 실행\"\"\"\n",
    "        # 체크포인트 확인\n",
    "        resume_id = self.load_checkpoint()\n",
    "        if resume_id > self.start_id:\n",
    "            logging.info(f\"체크포인트에서 재시작: ID {resume_id}\")\n",
    "            self.start_id = resume_id\n",
    "\n",
    "        anime_ids = list(range(self.start_id, self.end_id + 1))\n",
    "        total = len(anime_ids)\n",
    "\n",
    "        logging.info(f\"크롤링 시작: ID {self.start_id} ~ {self.end_id} (총 {total}개)\")\n",
    "        logging.info(f\"워커 수: {self.max_workers}\")\n",
    "\n",
    "        # 프로그레스 바 설정\n",
    "        with tqdm(total=total, desc=\"크롤링 진행\") as pbar:\n",
    "            with ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n",
    "                # 작업 제출\n",
    "                futures = {\n",
    "                    executor.submit(self.crawl_single_anime, anime_id): anime_id\n",
    "                    for anime_id in anime_ids\n",
    "                }\n",
    "\n",
    "                # 결과 수집\n",
    "                batch_count = 0\n",
    "                for future in as_completed(futures):\n",
    "                    anime_id = futures[future]\n",
    "\n",
    "                    try:\n",
    "                        result = future.result()\n",
    "                        if result:\n",
    "                            self.results.append(result)\n",
    "\n",
    "                    except Exception as e:\n",
    "                        logging.error(f\"ID {anime_id} 처리 실패: {str(e)}\")\n",
    "                        self.failed_ids.append(anime_id)\n",
    "\n",
    "                    pbar.update(1)\n",
    "                    batch_count += 1\n",
    "\n",
    "                    # 100개마다 중간 저장\n",
    "                    if batch_count % 100 == 0:\n",
    "                        self.save_checkpoint(anime_id)\n",
    "                        self.save_intermediate_results(batch_count)\n",
    "\n",
    "                    # 요청 간 딜레이 (너무 빠른 요청 방지)\n",
    "                    time.sleep(0.1)\n",
    "\n",
    "        logging.info(f\"크롤링 완료! 성공: {len(self.results)}개, 실패: {len(self.failed_ids)}개\")\n",
    "\n",
    "    def save_intermediate_results(self, batch_num: int):\n",
    "        \"\"\"중간 결과 저장\"\"\"\n",
    "        if self.results:\n",
    "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "            filename = f'anilife_data_batch_{batch_num}_{timestamp}.csv'\n",
    "            self.save_to_csv(self.results, filename)\n",
    "\n",
    "    def save_failed_ids(self):\n",
    "        \"\"\"실패한 ID 목록 저장\"\"\"\n",
    "        if self.failed_ids:\n",
    "            with open('failed_ids.txt', 'w') as f:\n",
    "                for id in self.failed_ids:\n",
    "                    f.write(f\"{id}\\n\")\n",
    "            logging.info(f\"실패한 ID 목록이 failed_ids.txt에 저장되었습니다.\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"메인 실행 함수\"\"\"\n",
    "    # 설정\n",
    "    START_ID = 101\n",
    "    END_ID = 7000\n",
    "    MAX_WORKERS = 10  # 동시 실행 스레드 수 (서버 부하 고려하여 조절)\n",
    "\n",
    "    # 크롤러 초기화\n",
    "    crawler = BulkCrawler(\n",
    "        start_id=START_ID,\n",
    "        end_id=END_ID,\n",
    "        max_workers=MAX_WORKERS\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # 병렬 크롤링 실행\n",
    "        start_time = time.time()\n",
    "        crawler.run_parallel()\n",
    "\n",
    "        # 최종 결과 저장\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        final_filename = f'anilife_complete_{timestamp}.csv'\n",
    "        crawler.save_to_csv(crawler.results, final_filename)\n",
    "\n",
    "        # 실패한 ID 저장\n",
    "        crawler.save_failed_ids()\n",
    "\n",
    "        # 실행 시간 출력\n",
    "        elapsed_time = time.time() - start_time\n",
    "        hours = int(elapsed_time // 3600)\n",
    "        minutes = int((elapsed_time % 3600) // 60)\n",
    "        seconds = int(elapsed_time % 60)\n",
    "\n",
    "        print(f\"\\n크롤링 완료!\")\n",
    "        print(f\"총 실행 시간: {hours}시간 {minutes}분 {seconds}초\")\n",
    "        print(f\"수집된 데이터: {len(crawler.results)}개\")\n",
    "        print(f\"실패한 ID: {len(crawler.failed_ids)}개\")\n",
    "        print(f\"최종 파일: {final_filename}\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n크롤링이 사용자에 의해 중단되었습니다.\")\n",
    "        print(\"현재까지의 결과를 저장합니다...\")\n",
    "\n",
    "        # 중단 시점까지의 결과 저장\n",
    "        if crawler.results:\n",
    "            interrupt_filename = f'anilife_interrupted_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.csv'\n",
    "            crawler.save_to_csv(crawler.results, interrupt_filename)\n",
    "            print(f\"중간 결과가 {interrupt_filename}에 저장되었습니다.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"예상치 못한 에러 발생: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "db6b1febf38012b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Anilife 테스트 크롤러 - ID 101~110만 크롤링하여 문제 파악\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "import csv\n",
    "import time\n",
    "\n",
    "class TestCrawler:\n",
    "    def __init__(self):\n",
    "        self.headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
    "            \"Accept-Language\": \"ko-KR,ko;q=0.9,en-US;q=0.8\"\n",
    "        }\n",
    "\n",
    "    def test_single_page(self, anime_id: int):\n",
    "        \"\"\"단일 페이지 테스트 크롤링\"\"\"\n",
    "        url = f\"https://anilife.app/content/{anime_id}\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"테스트 ID: {anime_id}\")\n",
    "        print(f\"URL: {url}\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        try:\n",
    "            # 페이지 요청\n",
    "            resp = requests.get(url, headers=self.headers, timeout=10)\n",
    "            print(f\"상태 코드: {resp.status_code}\")\n",
    "\n",
    "            if resp.status_code != 200:\n",
    "                print(f\"❌ HTTP 에러: {resp.status_code}\")\n",
    "                return None\n",
    "\n",
    "            # HTML 파싱\n",
    "            soup = BeautifulSoup(resp.text, 'lxml')\n",
    "\n",
    "            # 1. 페이지 제목 확인\n",
    "            page_title = soup.find('title')\n",
    "            if page_title:\n",
    "                print(f\"페이지 타이틀: {page_title.text[:50]}...\")\n",
    "\n",
    "            # 2. Nuxt 데이터 확인\n",
    "            nuxt_match = re.search(r'window\\.__NUXT__', resp.text)\n",
    "            if nuxt_match:\n",
    "                print(\"✓ Nuxt 데이터 발견\")\n",
    "                # Nuxt 데이터 추출 시도\n",
    "                self.extract_nuxt_data(resp.text)\n",
    "            else:\n",
    "                print(\"✗ Nuxt 데이터 없음\")\n",
    "\n",
    "            # 3. HTML 구조 확인\n",
    "            print(\"\\nHTML 구조 확인:\")\n",
    "\n",
    "            # h1 태그들\n",
    "            h1_tags = soup.find_all('h1')\n",
    "            print(f\"  h1 태그 개수: {len(h1_tags)}\")\n",
    "            for i, h1 in enumerate(h1_tags[:3]):\n",
    "                print(f\"    h1[{i}]: {h1.get_text(strip=True)[:50]}\")\n",
    "                if h1.get('class'):\n",
    "                    print(f\"      class: {h1.get('class')}\")\n",
    "\n",
    "            # h2 태그들\n",
    "            h2_tags = soup.find_all('h2')\n",
    "            print(f\"  h2 태그 개수: {len(h2_tags)}\")\n",
    "            for i, h2 in enumerate(h2_tags[:3]):\n",
    "                text = h2.get_text(strip=True)[:50]\n",
    "                if text:\n",
    "                    print(f\"    h2[{i}]: {text}\")\n",
    "\n",
    "            # 장르 링크\n",
    "            genre_links = soup.select('a[rel=\"genre\"]')\n",
    "            print(f\"  장르 링크 개수: {len(genre_links)}\")\n",
    "            if genre_links:\n",
    "                genres = [g.get_text(strip=True) for g in genre_links[:5]]\n",
    "                print(f\"    장르: {', '.join(genres)}\")\n",
    "\n",
    "            # 404 체크\n",
    "            if '404' in soup.text[:1000] or 'Not Found' in soup.text[:1000]:\n",
    "                print(\"⚠️ 404 페이지일 가능성\")\n",
    "\n",
    "            # 데이터 추출 시도\n",
    "            result = self.extract_data(soup, url, resp.text)\n",
    "\n",
    "            print(\"\\n추출된 데이터:\")\n",
    "            for key, value in result.items():\n",
    "                if value:\n",
    "                    print(f\"  {key}: {str(value)[:50]}\")\n",
    "\n",
    "            return result\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 에러 발생: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return None\n",
    "\n",
    "    def extract_nuxt_data(self, html_content: str):\n",
    "        \"\"\"Nuxt 데이터 추출 테스트\"\"\"\n",
    "        try:\n",
    "            pattern = r'window\\.__NUXT__=\\(function\\([^)]*\\)\\{return (.+?)\\}\\)\\([^)]+\\)'\n",
    "            match = re.search(pattern, html_content, re.DOTALL)\n",
    "\n",
    "            if match:\n",
    "                json_str = match.group(1)\n",
    "                print(f\"  Nuxt 데이터 길이: {len(json_str)} 문자\")\n",
    "\n",
    "                # 변수 치환\n",
    "                replacements = {\n",
    "                    r'\\ba\\b': 'false',\n",
    "                    r'\\bb\\b': '1',\n",
    "                    r'\\bc\\b': 'true',\n",
    "                    r'\\bd\\b': 'null',\n",
    "                    r'\\be\\b': '\"system\"',\n",
    "                    r'\\bf\\b': '\"https://anilife.app\"',\n",
    "                    r'\\bg\\b': '\"N/A\"'\n",
    "                }\n",
    "\n",
    "                for pattern, value in replacements.items():\n",
    "                    json_str = re.sub(pattern, value, json_str)\n",
    "\n",
    "                data = json.loads(json_str)\n",
    "\n",
    "                # 데이터 구조 확인\n",
    "                print(\"  Nuxt 데이터 키:\")\n",
    "                for key in list(data.keys())[:10]:\n",
    "                    print(f\"    - {key}\")\n",
    "\n",
    "                # pinia 확인\n",
    "                if 'pinia' in data:\n",
    "                    print(\"  ✓ pinia 발견\")\n",
    "                    if 'content' in data['pinia']:\n",
    "                        print(\"    ✓ content 발견\")\n",
    "                        if 'contentDetail' in data['pinia']['content']:\n",
    "                            print(\"      ✓ contentDetail 발견\")\n",
    "                            detail = data['pinia']['content']['contentDetail']\n",
    "                            if 'name' in detail:\n",
    "                                print(f\"        name: {detail['name']}\")\n",
    "\n",
    "                return data\n",
    "        except Exception as e:\n",
    "            print(f\"  Nuxt 파싱 에러: {str(e)}\")\n",
    "            return {}\n",
    "\n",
    "    def extract_data(self, soup: BeautifulSoup, url: str, html_text: str) -> dict:\n",
    "        \"\"\"데이터 추출\"\"\"\n",
    "        result = {'id': re.search(r'/content/(\\d+)', url).group(1), 'url': url}\n",
    "\n",
    "        # 1. 다양한 h1 클래스 시도\n",
    "        h1_classes = ['fpUXWby', 'title', 'content-title', 'anime-title']\n",
    "        for cls in h1_classes:\n",
    "            h1 = soup.find('h1', class_=cls)\n",
    "            if h1:\n",
    "                result['title_kr'] = h1.get_text(strip=True)\n",
    "                break\n",
    "\n",
    "        # 2. h1 클래스 없이 시도\n",
    "        if not result.get('title_kr'):\n",
    "            h1_all = soup.find_all('h1')\n",
    "            for h1 in h1_all:\n",
    "                text = h1.get_text(strip=True)\n",
    "                if text and len(text) > 2 and '404' not in text:\n",
    "                    result['title_kr'] = text\n",
    "                    break\n",
    "\n",
    "        # 3. Nuxt에서 시도\n",
    "        if not result.get('title_kr'):\n",
    "            nuxt_data = self.extract_nuxt_data(html_text)\n",
    "            if nuxt_data:\n",
    "                try:\n",
    "                    detail = nuxt_data.get('pinia', {}).get('content', {}).get('contentDetail', {})\n",
    "                    if detail and 'name' in detail:\n",
    "                        if isinstance(detail['name'], dict):\n",
    "                            result['title_kr'] = detail['name'].get('kr', '')\n",
    "                            result['title_en'] = detail['name'].get('en', '')\n",
    "                            result['title_jp'] = detail['name'].get('jp', '')\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        return result\n",
    "\n",
    "    def run_test(self):\n",
    "        \"\"\"테스트 실행\"\"\"\n",
    "        print(\"Anilife 테스트 크롤링 시작 (ID 101-110)\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        results = []\n",
    "\n",
    "        for anime_id in range(101, 111):\n",
    "            result = self.test_single_page(anime_id)\n",
    "            if result:\n",
    "                results.append(result)\n",
    "            time.sleep(1)  # 서버 부하 방지\n",
    "\n",
    "        # 결과 저장\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"크롤링 완료!\")\n",
    "        print(f\"성공: {len(results)}/10\")\n",
    "\n",
    "        # CSV 저장\n",
    "        if results:\n",
    "            with open('test_results.csv', 'w', newline='', encoding='utf-8-sig') as f:\n",
    "                fieldnames = ['id', 'url', 'title_kr', 'title_en', 'title_jp']\n",
    "                writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "                writer.writeheader()\n",
    "\n",
    "                for result in results:\n",
    "                    row = {field: result.get(field, '') for field in fieldnames}\n",
    "                    writer.writerow(row)\n",
    "\n",
    "            print(\"결과가 test_results.csv에 저장되었습니다.\")\n",
    "\n",
    "        # 요약\n",
    "        print(\"\\n요약:\")\n",
    "        for result in results:\n",
    "            if result.get('title_kr'):\n",
    "                print(f\"  ID {result['id']}: {result['title_kr']}\")\n",
    "            else:\n",
    "                print(f\"  ID {result['id']}: 제목 없음\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    crawler = TestCrawler()\n",
    "    crawler.run_test()"
   ],
   "id": "6d72652d7e57442f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Anilife 테스트 크롤러 - ID 101~110만 크롤링하여 문제 파악\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "import csv\n",
    "import time\n",
    "\n",
    "class TestCrawler:\n",
    "    def __init__(self):\n",
    "        self.headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
    "            \"Accept-Language\": \"ko-KR,ko;q=0.9,en-US;q=0.8\"\n",
    "        }\n",
    "\n",
    "    def test_single_page(self, anime_id: int):\n",
    "        \"\"\"단일 페이지 테스트 크롤링\"\"\"\n",
    "        # URL에 tab=info 추가하여 작품 정보 페이지로 이동\n",
    "        url = f\"https://anilife.app/content/{anime_id}?tab=info\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"테스트 ID: {anime_id}\")\n",
    "        print(f\"URL: {url}\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        try:\n",
    "            # 페이지 요청\n",
    "            resp = requests.get(url, headers=self.headers, timeout=10)\n",
    "            print(f\"상태 코드: {resp.status_code}\")\n",
    "\n",
    "            if resp.status_code != 200:\n",
    "                print(f\"❌ HTTP 에러: {resp.status_code}\")\n",
    "                return None\n",
    "\n",
    "            # HTML 파싱\n",
    "            soup = BeautifulSoup(resp.text, 'lxml')\n",
    "\n",
    "            # 1. 페이지 제목 확인\n",
    "            page_title = soup.find('title')\n",
    "            if page_title:\n",
    "                print(f\"페이지 타이틀: {page_title.text[:50]}...\")\n",
    "\n",
    "            # 2. Nuxt 데이터 확인\n",
    "            nuxt_match = re.search(r'window\\.__NUXT__', resp.text)\n",
    "            if nuxt_match:\n",
    "                print(\"✓ Nuxt 데이터 발견\")\n",
    "                # Nuxt 데이터 추출 시도\n",
    "                self.extract_nuxt_data(resp.text)\n",
    "            else:\n",
    "                print(\"✗ Nuxt 데이터 없음\")\n",
    "\n",
    "            # 3. HTML 구조 확인\n",
    "            print(\"\\nHTML 구조 확인:\")\n",
    "\n",
    "            # h1 태그들\n",
    "            h1_tags = soup.find_all('h1')\n",
    "            print(f\"  h1 태그 개수: {len(h1_tags)}\")\n",
    "            for i, h1 in enumerate(h1_tags[:3]):\n",
    "                print(f\"    h1[{i}]: {h1.get_text(strip=True)[:50]}\")\n",
    "                if h1.get('class'):\n",
    "                    print(f\"      class: {h1.get('class')}\")\n",
    "\n",
    "            # h2 태그들\n",
    "            h2_tags = soup.find_all('h2')\n",
    "            print(f\"  h2 태그 개수: {len(h2_tags)}\")\n",
    "            for i, h2 in enumerate(h2_tags[:3]):\n",
    "                text = h2.get_text(strip=True)[:50]\n",
    "                if text:\n",
    "                    print(f\"    h2[{i}]: {text}\")\n",
    "\n",
    "            # 장르 링크\n",
    "            genre_links = soup.select('a[rel=\"genre\"]')\n",
    "            print(f\"  장르 링크 개수: {len(genre_links)}\")\n",
    "            if genre_links:\n",
    "                genres = [g.get_text(strip=True) for g in genre_links[:5]]\n",
    "                print(f\"    장르: {', '.join(genres)}\")\n",
    "\n",
    "            # 404 체크\n",
    "            if '404' in soup.text[:1000] or 'Not Found' in soup.text[:1000]:\n",
    "                print(\"⚠️ 404 페이지일 가능성\")\n",
    "\n",
    "            # 데이터 추출 시도\n",
    "            result = self.extract_data(soup, url, resp.text)\n",
    "\n",
    "            print(\"\\n추출된 데이터:\")\n",
    "            for key, value in result.items():\n",
    "                if value:\n",
    "                    print(f\"  {key}: {str(value)[:50]}\")\n",
    "\n",
    "            return result\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 에러 발생: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return None\n",
    "\n",
    "    def extract_nuxt_data(self, html_content: str):\n",
    "        \"\"\"Nuxt 데이터 추출 테스트\"\"\"\n",
    "        try:\n",
    "            pattern = r'window\\.__NUXT__=\\(function\\([^)]*\\)\\{return (.+?)\\}\\)\\([^)]+\\)'\n",
    "            match = re.search(pattern, html_content, re.DOTALL)\n",
    "\n",
    "            if match:\n",
    "                json_str = match.group(1)\n",
    "                print(f\"  Nuxt 데이터 길이: {len(json_str)} 문자\")\n",
    "\n",
    "                # 변수 치환\n",
    "                replacements = {\n",
    "                    r'\\ba\\b': 'false',\n",
    "                    r'\\bb\\b': '1',\n",
    "                    r'\\bc\\b': 'true',\n",
    "                    r'\\bd\\b': 'null',\n",
    "                    r'\\be\\b': '\"system\"',\n",
    "                    r'\\bf\\b': '\"https://anilife.app\"',\n",
    "                    r'\\bg\\b': '\"N/A\"'\n",
    "                }\n",
    "\n",
    "                for pattern, value in replacements.items():\n",
    "                    json_str = re.sub(pattern, value, json_str)\n",
    "\n",
    "                data = json.loads(json_str)\n",
    "\n",
    "                # 데이터 구조 확인\n",
    "                print(\"  Nuxt 데이터 키:\")\n",
    "                for key in list(data.keys())[:10]:\n",
    "                    print(f\"    - {key}\")\n",
    "\n",
    "                # pinia 확인\n",
    "                if 'pinia' in data:\n",
    "                    print(\"  ✓ pinia 발견\")\n",
    "                    if 'content' in data['pinia']:\n",
    "                        print(\"    ✓ content 발견\")\n",
    "                        if 'contentDetail' in data['pinia']['content']:\n",
    "                            print(\"      ✓ contentDetail 발견\")\n",
    "                            detail = data['pinia']['content']['contentDetail']\n",
    "                            if 'name' in detail:\n",
    "                                print(f\"        name: {detail['name']}\")\n",
    "\n",
    "                return data\n",
    "        except Exception as e:\n",
    "            print(f\"  Nuxt 파싱 에러: {str(e)}\")\n",
    "            return {}\n",
    "\n",
    "    def extract_data(self, soup: BeautifulSoup, url: str, html_text: str) -> dict:\n",
    "        \"\"\"데이터 추출\"\"\"\n",
    "        result = {'id': re.search(r'/content/(\\d+)', url).group(1), 'url': url}\n",
    "\n",
    "        # 1. 다양한 h1 클래스 시도\n",
    "        h1_classes = ['fpUXWby', 'title', 'content-title', 'anime-title']\n",
    "        for cls in h1_classes:\n",
    "            h1 = soup.find('h1', class_=cls)\n",
    "            if h1:\n",
    "                result['title_kr'] = h1.get_text(strip=True)\n",
    "                break\n",
    "\n",
    "        # 2. h1 클래스 없이 시도\n",
    "        if not result.get('title_kr'):\n",
    "            h1_all = soup.find_all('h1')\n",
    "            for h1 in h1_all:\n",
    "                text = h1.get_text(strip=True)\n",
    "                if text and len(text) > 2 and '404' not in text:\n",
    "                    result['title_kr'] = text\n",
    "                    break\n",
    "\n",
    "        # 3. Nuxt에서 시도\n",
    "        if not result.get('title_kr'):\n",
    "            nuxt_data = self.extract_nuxt_data(html_text)\n",
    "            if nuxt_data:\n",
    "                try:\n",
    "                    detail = nuxt_data.get('pinia', {}).get('content', {}).get('contentDetail', {})\n",
    "                    if detail and 'name' in detail:\n",
    "                        if isinstance(detail['name'], dict):\n",
    "                            result['title_kr'] = detail['name'].get('kr', '')\n",
    "                            result['title_en'] = detail['name'].get('en', '')\n",
    "                            result['title_jp'] = detail['name'].get('jp', '')\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        return result\n",
    "\n",
    "    def run_test(self):\n",
    "        \"\"\"테스트 실행\"\"\"\n",
    "        print(\"Anilife 테스트 크롤링 시작 (ID 101-110)\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        results = []\n",
    "\n",
    "        for anime_id in range(101, 111):\n",
    "            result = self.test_single_page(anime_id)\n",
    "            if result:\n",
    "                results.append(result)\n",
    "            time.sleep(1)  # 서버 부하 방지\n",
    "\n",
    "        # 결과 저장\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"크롤링 완료!\")\n",
    "        print(f\"성공: {len(results)}/10\")\n",
    "\n",
    "        # CSV 저장\n",
    "        if results:\n",
    "            with open('test_results.csv', 'w', newline='', encoding='utf-8-sig') as f:\n",
    "                fieldnames = ['id', 'url', 'title_kr', 'title_en', 'title_jp']\n",
    "                writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "                writer.writeheader()\n",
    "\n",
    "                for result in results:\n",
    "                    row = {field: result.get(field, '') for field in fieldnames}\n",
    "                    writer.writerow(row)\n",
    "\n",
    "            print(\"결과가 test_results.csv에 저장되었습니다.\")\n",
    "\n",
    "        # 요약\n",
    "        print(\"\\n요약:\")\n",
    "        for result in results:\n",
    "            if result.get('title_kr'):\n",
    "                print(f\"  ID {result['id']}: {result['title_kr']}\")\n",
    "            else:\n",
    "                print(f\"  ID {result['id']}: 제목 없음\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    crawler = TestCrawler()\n",
    "    crawler.run_test()"
   ],
   "id": "dbd3893ba6425734"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T07:47:29.618709Z",
     "start_time": "2025-09-05T07:47:27.689415Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "import pprint as pp\n",
    "\n",
    "def debug_scrape(url):\n",
    "    \"\"\"디버깅을 위한 상세 크롤링\"\"\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) StepByStepCrawler/0.1\",\n",
    "        \"Accept-Language\": \"ko-KR,ko;q=0.9,en-US;q=0.8\"\n",
    "    }\n",
    "\n",
    "    # URL 정규화\n",
    "    if \"tab=info\" not in url:\n",
    "        if \"?\" in url:\n",
    "            url = url.split(\"?\")[0] + \"?tab=info\"\n",
    "        else:\n",
    "            url = url + \"?tab=info\"\n",
    "\n",
    "    print(f\"크롤링 URL: {url}\")\n",
    "\n",
    "    resp = requests.get(url, headers=headers, timeout=20)\n",
    "    print(f\"응답 코드: {resp.status_code}\")\n",
    "\n",
    "    soup = BeautifulSoup(resp.text, \"lxml\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"1. NUXT 데이터 추출 시도\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # Nuxt 데이터 추출\n",
    "    pattern = r'window\\.__NUXT__=\\(function\\([^)]*\\)\\{return (.+?)\\}\\)\\([^)]+\\)'\n",
    "    match = re.search(pattern, resp.text, re.DOTALL)\n",
    "\n",
    "    nuxt_data = {}\n",
    "    if match:\n",
    "        json_str = match.group(1)\n",
    "        print(f\"Nuxt 데이터 찾음! (길이: {len(json_str)})\")\n",
    "\n",
    "        # 매개변수 치환\n",
    "        replacements = {\n",
    "            r'\\ba\\b': 'false',\n",
    "            r'\\bb\\b': '1',\n",
    "            r'\\bc\\b': 'true',\n",
    "            r'\\bd\\b': 'null',\n",
    "            r'\\be\\b': '\"system\"',\n",
    "            r'\\bf\\b': '\"https://anilife.app\"',\n",
    "            r'\\bg\\b': '\"N/A\"'\n",
    "        }\n",
    "\n",
    "        for pattern, value in replacements.items():\n",
    "            json_str = re.sub(pattern, value, json_str)\n",
    "\n",
    "        try:\n",
    "            nuxt_data = json.loads(json_str)\n",
    "            print(\"Nuxt 데이터 파싱 성공!\")\n",
    "\n",
    "            # 구조 탐색\n",
    "            if 'pinia' in nuxt_data:\n",
    "                print(f\"\\nPinia 키들: {list(nuxt_data['pinia'].keys())}\")\n",
    "\n",
    "                # content 관련 키 찾기\n",
    "                for key in nuxt_data['pinia'].keys():\n",
    "                    if 'content' in key.lower():\n",
    "                        print(f\"\\n'{key}' 발견!\")\n",
    "                        content = nuxt_data['pinia'][key]\n",
    "\n",
    "                        if 'contentDetail' in content:\n",
    "                            detail = content['contentDetail']\n",
    "                            print(f\"contentDetail 키들: {list(detail.keys())[:20]}\")\n",
    "\n",
    "                            # 시즌 정보\n",
    "                            if 'season' in detail:\n",
    "                                print(f\"\\nseason 데이터: {detail['season']}\")\n",
    "\n",
    "                            # 스태프/제작 정보\n",
    "                            for staff_key in ['staff', 'staffs', 'production', 'studio']:\n",
    "                                if staff_key in detail:\n",
    "                                    print(f\"\\n{staff_key} 데이터: {detail[staff_key][:3] if isinstance(detail[staff_key], list) else detail[staff_key]}\")\n",
    "\n",
    "                            # 원작 정보\n",
    "                            for source_key in ['source', 'original', 'originalWork']:\n",
    "                                if source_key in detail:\n",
    "                                    print(f\"\\n{source_key}: {detail[source_key]}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Nuxt 데이터 파싱 실패: {e}\")\n",
    "    else:\n",
    "        print(\"Nuxt 데이터를 찾을 수 없음\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"2. HTML 직접 파싱\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # 방영 정보 찾기\n",
    "    print(\"\\n[방영 정보]\")\n",
    "    for class_name in ['nBnfiIh', 'season-info', 'anime-info', 'broadcast-info']:\n",
    "        elem = soup.find('div', class_=class_name)\n",
    "        if elem:\n",
    "            text = elem.get_text(strip=True)\n",
    "            print(f\"클래스 '{class_name}': {text}\")\n",
    "\n",
    "            # 연도와 분기 추출\n",
    "            year_match = re.search(r'(19\\d{2}|20\\d{2})', text)\n",
    "            quarter_match = re.search(r'(\\d)분기|(\\d)쿨|Q(\\d)|봄|여름|가을|겨울', text)\n",
    "\n",
    "            if year_match:\n",
    "                print(f\"  → 연도: {year_match.group(1)}\")\n",
    "            if quarter_match:\n",
    "                print(f\"  → 분기: {quarter_match.group(0)}\")\n",
    "\n",
    "    # 모든 div의 텍스트에서 연도 찾기\n",
    "    print(\"\\n[연도가 포함된 모든 요소]\")\n",
    "    for div in soup.find_all('div'):\n",
    "        text = div.get_text(strip=True)\n",
    "        if re.search(r'20\\d{2}년|20\\d{2}\\s', text) and len(text) < 100:\n",
    "            print(f\"  - {text[:80]}\")\n",
    "\n",
    "    print(\"\\n[제작 정보 섹션]\")\n",
    "    # 제작 정보 섹션 찾기 - 여러 방법 시도\n",
    "\n",
    "    # 방법 1: h2로 섹션 찾기\n",
    "    for h2 in soup.find_all('h2'):\n",
    "        h2_text = h2.get_text(strip=True)\n",
    "        if any(keyword in h2_text for keyword in ['제작', '스태프', 'Staff', '제작진', '스튜디오']):\n",
    "            print(f\"제작 관련 h2 발견: {h2_text}\")\n",
    "\n",
    "            # 부모 섹션 찾기\n",
    "            section = h2.find_parent('section')\n",
    "            if section:\n",
    "                # 섹션 내의 모든 링크 확인\n",
    "                links = section.find_all('a')\n",
    "                print(f\"  섹션 내 링크 수: {len(links)}\")\n",
    "\n",
    "                for i, link in enumerate(links[:5]):  # 처음 5개만\n",
    "                    link_text = link.get_text(strip=True)\n",
    "                    print(f\"    링크 {i+1}: {link_text}\")\n",
    "\n",
    "                    # div 구조 확인\n",
    "                    divs = link.find_all('div')\n",
    "                    for div in divs:\n",
    "                        div_class = div.get('class', [])\n",
    "                        div_text = div.get_text(strip=True)\n",
    "                        print(f\"      div (class={div_class}): {div_text}\")\n",
    "\n",
    "    # 방법 2: 특정 클래스로 찾기\n",
    "    for class_combo in [['_1coMKET', '-HW4ChD'], ['production-info'], ['staff-info']]:\n",
    "        if len(class_combo) == 1:\n",
    "            elem = soup.find('div', class_=class_combo[0])\n",
    "        else:\n",
    "            elem = soup.find('div', class_=' '.join(class_combo))\n",
    "\n",
    "        if elem:\n",
    "            print(f\"\\n클래스 {class_combo}로 요소 발견\")\n",
    "            links = elem.find_all('a')\n",
    "            print(f\"  링크 수: {len(links)}\")\n",
    "\n",
    "            for link in links[:3]:\n",
    "                print(f\"  - {link.get_text(strip=True)}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"3. 메타 데이터 확인\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # meta 태그 확인\n",
    "    for meta in soup.find_all('meta'):\n",
    "        if meta.get('property') and 'og:' in meta.get('property', ''):\n",
    "            print(f\"{meta.get('property')}: {meta.get('content', '')[:100]}\")\n",
    "\n",
    "    # script 태그에서 JSON-LD 찾기\n",
    "    for script in soup.find_all('script', type='application/ld+json'):\n",
    "        try:\n",
    "            data = json.loads(script.string)\n",
    "            print(f\"\\nJSON-LD 데이터 발견: {list(data.keys())}\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return nuxt_data, soup\n",
    "\n",
    "\n",
    "# 테스트 실행\n",
    "if __name__ == \"__main__\":\n",
    "    # 몇 개의 URL로 테스트\n",
    "    test_urls = [\n",
    "        \"https://anilife.app/content/101\",  # 원피스\n",
    "        \"https://anilife.app/content/110\",  # 꿈속의 뮤\n",
    "        \"https://anilife.app/content/119\",  # 일하는 세포 BLACK\n",
    "    ]\n",
    "\n",
    "    for url in test_urls:\n",
    "        print(\"\\n\" + \"=\"*100)\n",
    "        print(f\"테스트: {url}\")\n",
    "        print(\"=\"*100)\n",
    "\n",
    "        nuxt_data, soup = debug_scrape(url)\n",
    "\n",
    "        print(\"\\n완료!\\n\")"
   ],
   "id": "86d7f402a9c1fd09",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "테스트: https://anilife.app/content/101\n",
      "====================================================================================================\n",
      "크롤링 URL: https://anilife.app/content/101?tab=info\n",
      "응답 코드: 200\n",
      "\n",
      "================================================================================\n",
      "1. NUXT 데이터 추출 시도\n",
      "================================================================================\n",
      "Nuxt 데이터를 찾을 수 없음\n",
      "\n",
      "================================================================================\n",
      "2. HTML 직접 파싱\n",
      "================================================================================\n",
      "\n",
      "[방영 정보]\n",
      "클래스 'nBnfiIh': 1999년도 4분기·TV\n",
      "  → 연도: 1999\n",
      "  → 분기: 4분기\n",
      "\n",
      "[연도가 포함된 모든 요소]\n",
      "\n",
      "[제작 정보 섹션]\n",
      "제작 관련 h2 발견: 작품 제작\n",
      "  섹션 내 링크 수: 18\n",
      "    링크 1: 오다 에이치로원작자\n",
      "      div (class=['OuXf8uf', 'z4xkYZ9']): 오다 에이치로원작자\n",
      "      div (class=['ygvbJ2N']): \n",
      "      div (class=['whFyH-k']): \n",
      "      div (class=['H3oaiWl']): \n",
      "      div (class=['nshcU0W']): 오다 에이치로원작자\n",
      "      div (class=['C9a9MX4']): 오다 에이치로원작자\n",
      "      div (class=['iO6bs1d']): 오다 에이치로\n",
      "      div (class=['_99DZmqJ']): 원작자\n",
      "    링크 2: 토에이 애니메이션애니메이션 제작\n",
      "      div (class=['OuXf8uf', 'z4xkYZ9']): 토에이 애니메이션애니메이션 제작\n",
      "      div (class=['ygvbJ2N']): \n",
      "      div (class=['whFyH-k']): \n",
      "      div (class=['H3oaiWl']): \n",
      "      div (class=['nshcU0W']): 토에이 애니메이션애니메이션 제작\n",
      "      div (class=['C9a9MX4']): 토에이 애니메이션애니메이션 제작\n",
      "      div (class=['iO6bs1d']): 토에이 애니메이션\n",
      "      div (class=['_99DZmqJ']): 애니메이션 제작\n",
      "    링크 3: TAP애니메이션 제작\n",
      "      div (class=['OuXf8uf', 'z4xkYZ9']): TAP애니메이션 제작\n",
      "      div (class=['ygvbJ2N']): \n",
      "      div (class=['whFyH-k']): \n",
      "      div (class=['H3oaiWl']): \n",
      "      div (class=['nshcU0W']): TAP애니메이션 제작\n",
      "      div (class=['C9a9MX4']): TAP애니메이션 제작\n",
      "      div (class=['iO6bs1d']): TAP\n",
      "      div (class=['_99DZmqJ']): 애니메이션 제작\n",
      "    링크 4: 매직 버스애니메이션 제작\n",
      "      div (class=['OuXf8uf', 'z4xkYZ9']): 매직 버스애니메이션 제작\n",
      "      div (class=['ygvbJ2N']): \n",
      "      div (class=['whFyH-k']): \n",
      "      div (class=['H3oaiWl']): \n",
      "      div (class=['nshcU0W']): 매직 버스애니메이션 제작\n",
      "      div (class=['C9a9MX4']): 매직 버스애니메이션 제작\n",
      "      div (class=['iO6bs1d']): 매직 버스\n",
      "      div (class=['_99DZmqJ']): 애니메이션 제작\n",
      "    링크 5: 무시 프로덕션애니메이션 제작\n",
      "      div (class=['OuXf8uf', 'z4xkYZ9']): 무시 프로덕션애니메이션 제작\n",
      "      div (class=['ygvbJ2N']): \n",
      "      div (class=['whFyH-k']): \n",
      "      div (class=['H3oaiWl']): \n",
      "      div (class=['nshcU0W']): 무시 프로덕션애니메이션 제작\n",
      "      div (class=['C9a9MX4']): 무시 프로덕션애니메이션 제작\n",
      "      div (class=['iO6bs1d']): 무시 프로덕션\n",
      "      div (class=['_99DZmqJ']): 애니메이션 제작\n",
      "\n",
      "클래스 ['_1coMKET', '-HW4ChD']로 요소 발견\n",
      "  링크 수: 18\n",
      "  - 오다 에이치로원작자\n",
      "  - 토에이 애니메이션애니메이션 제작\n",
      "  - TAP애니메이션 제작\n",
      "\n",
      "================================================================================\n",
      "3. 메타 데이터 확인\n",
      "================================================================================\n",
      "og:title: 원피스 작품 상세 정보\n",
      "og:description: 부-명성-힘⋯. 한때 이 세상의 모든 것을 손에 넣은 사나이. 「해적왕 골드 로저」그가 죽 - 작품 정보\n",
      "og:type: profile\n",
      "og:url: https://anilife.app/content/101/원피스/info\n",
      "\n",
      "완료!\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "테스트: https://anilife.app/content/110\n",
      "====================================================================================================\n",
      "크롤링 URL: https://anilife.app/content/110?tab=info\n",
      "응답 코드: 200\n",
      "\n",
      "================================================================================\n",
      "1. NUXT 데이터 추출 시도\n",
      "================================================================================\n",
      "Nuxt 데이터를 찾을 수 없음\n",
      "\n",
      "================================================================================\n",
      "2. HTML 직접 파싱\n",
      "================================================================================\n",
      "\n",
      "[방영 정보]\n",
      "클래스 'nBnfiIh': 2020년도 2분기·TV\n",
      "  → 연도: 2020\n",
      "  → 분기: 2분기\n",
      "\n",
      "[연도가 포함된 모든 요소]\n",
      "  - 2020년도 2분기·TV\n",
      "\n",
      "[제작 정보 섹션]\n",
      "제작 관련 h2 발견: 작품 제작\n",
      "  섹션 내 링크 수: 6\n",
      "    링크 1: 사쿠라이 히로아키감독\n",
      "      div (class=['OuXf8uf', 'z4xkYZ9']): 사쿠라이 히로아키감독\n",
      "      div (class=['ygvbJ2N']): \n",
      "      div (class=['whFyH-k']): \n",
      "      div (class=['H3oaiWl']): \n",
      "      div (class=['nshcU0W']): 사쿠라이 히로아키감독\n",
      "      div (class=['C9a9MX4']): 사쿠라이 히로아키감독\n",
      "      div (class=['iO6bs1d']): 사쿠라이 히로아키\n",
      "      div (class=['_99DZmqJ']): 감독\n",
      "    링크 2: J.C. 스태프애니메이션 제작\n",
      "      div (class=['OuXf8uf', 'z4xkYZ9']): J.C. 스태프애니메이션 제작\n",
      "      div (class=['ygvbJ2N']): \n",
      "      div (class=['whFyH-k']): \n",
      "      div (class=['H3oaiWl']): \n",
      "      div (class=['nshcU0W']): J.C. 스태프애니메이션 제작\n",
      "      div (class=['C9a9MX4']): J.C. 스태프애니메이션 제작\n",
      "      div (class=['iO6bs1d']): J.C. 스태프\n",
      "      div (class=['_99DZmqJ']): 애니메이션 제작\n",
      "    링크 3: A.C.G.T.애니메이션 제작\n",
      "      div (class=['OuXf8uf', 'z4xkYZ9']): A.C.G.T.애니메이션 제작\n",
      "      div (class=['ygvbJ2N']): \n",
      "      div (class=['whFyH-k']): \n",
      "      div (class=['H3oaiWl']): \n",
      "      div (class=['nshcU0W']): A.C.G.T.애니메이션 제작\n",
      "      div (class=['C9a9MX4']): A.C.G.T.애니메이션 제작\n",
      "      div (class=['iO6bs1d']): A.C.G.T.\n",
      "      div (class=['_99DZmqJ']): 애니메이션 제작\n",
      "    링크 4: TV 도쿄애니메이션 제작\n",
      "      div (class=['OuXf8uf', 'z4xkYZ9']): TV 도쿄애니메이션 제작\n",
      "      div (class=['ygvbJ2N']): \n",
      "      div (class=['whFyH-k']): \n",
      "      div (class=['H3oaiWl']): \n",
      "      div (class=['nshcU0W']): TV 도쿄애니메이션 제작\n",
      "      div (class=['C9a9MX4']): TV 도쿄애니메이션 제작\n",
      "      div (class=['iO6bs1d']): TV 도쿄\n",
      "      div (class=['_99DZmqJ']): 애니메이션 제작\n",
      "    링크 5: ADK 이모션즈애니메이션 제작\n",
      "      div (class=['OuXf8uf', 'z4xkYZ9']): ADK 이모션즈애니메이션 제작\n",
      "      div (class=['ygvbJ2N']): \n",
      "      div (class=['whFyH-k']): \n",
      "      div (class=['H3oaiWl']): \n",
      "      div (class=['nshcU0W']): ADK 이모션즈애니메이션 제작\n",
      "      div (class=['C9a9MX4']): ADK 이모션즈애니메이션 제작\n",
      "      div (class=['iO6bs1d']): ADK 이모션즈\n",
      "      div (class=['_99DZmqJ']): 애니메이션 제작\n",
      "\n",
      "클래스 ['_1coMKET', '-HW4ChD']로 요소 발견\n",
      "  링크 수: 6\n",
      "  - 사쿠라이 히로아키감독\n",
      "  - J.C. 스태프애니메이션 제작\n",
      "  - A.C.G.T.애니메이션 제작\n",
      "\n",
      "================================================================================\n",
      "3. 메타 데이터 확인\n",
      "================================================================================\n",
      "og:title: 꿈속의-뮤 작품 상세 정보\n",
      "og:description: 연애와 우정, 마음의 상냥함을 그리는 귀여운 드리밍 스토리(恋や友情、心のやさしさを描くカワイ - 작품 정보\n",
      "og:type: profile\n",
      "og:url: https://anilife.app/content/110/꿈속의-뮤/info\n",
      "\n",
      "완료!\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "테스트: https://anilife.app/content/119\n",
      "====================================================================================================\n",
      "크롤링 URL: https://anilife.app/content/119?tab=info\n",
      "응답 코드: 200\n",
      "\n",
      "================================================================================\n",
      "1. NUXT 데이터 추출 시도\n",
      "================================================================================\n",
      "Nuxt 데이터를 찾을 수 없음\n",
      "\n",
      "================================================================================\n",
      "2. HTML 직접 파싱\n",
      "================================================================================\n",
      "\n",
      "[방영 정보]\n",
      "클래스 'nBnfiIh': 2021년도 1분기·TV· BD\n",
      "  → 연도: 2021\n",
      "  → 분기: 1분기\n",
      "\n",
      "[연도가 포함된 모든 요소]\n",
      "  - 2021년도 1분기·TV· BD\n",
      "\n",
      "[제작 정보 섹션]\n",
      "제작 관련 h2 발견: 작품 제작\n",
      "  섹션 내 링크 수: 11\n",
      "    링크 1: 야마모토 히데요감독\n",
      "      div (class=['OuXf8uf', 'z4xkYZ9']): 야마모토 히데요감독\n",
      "      div (class=['ygvbJ2N']): \n",
      "      div (class=['whFyH-k']): \n",
      "      div (class=['H3oaiWl']): \n",
      "      div (class=['nshcU0W']): 야마모토 히데요감독\n",
      "      div (class=['C9a9MX4']): 야마모토 히데요감독\n",
      "      div (class=['iO6bs1d']): 야마모토 히데요\n",
      "      div (class=['_99DZmqJ']): 감독\n",
      "    링크 2: 타카하시 유마프로듀서\n",
      "      div (class=['OuXf8uf', 'z4xkYZ9']): 타카하시 유마프로듀서\n",
      "      div (class=['ygvbJ2N']): \n",
      "      div (class=['whFyH-k']): \n",
      "      div (class=['H3oaiWl']): \n",
      "      div (class=['nshcU0W']): 타카하시 유마프로듀서\n",
      "      div (class=['C9a9MX4']): 타카하시 유마프로듀서\n",
      "      div (class=['iO6bs1d']): 타카하시 유마\n",
      "      div (class=['_99DZmqJ']): 프로듀서\n",
      "    링크 3: 이토 요헤이프로듀서\n",
      "      div (class=['OuXf8uf', 'z4xkYZ9']): 이토 요헤이프로듀서\n",
      "      div (class=['ygvbJ2N']): \n",
      "      div (class=['whFyH-k']): \n",
      "      div (class=['H3oaiWl']): \n",
      "      div (class=['nshcU0W']): 이토 요헤이프로듀서\n",
      "      div (class=['C9a9MX4']): 이토 요헤이프로듀서\n",
      "      div (class=['iO6bs1d']): 이토 요헤이\n",
      "      div (class=['_99DZmqJ']): 프로듀서\n",
      "    링크 4: 키타자와 후미타카프로듀서\n",
      "      div (class=['OuXf8uf', 'z4xkYZ9']): 키타자와 후미타카프로듀서\n",
      "      div (class=['ygvbJ2N']): \n",
      "      div (class=['whFyH-k']): \n",
      "      div (class=['H3oaiWl']): \n",
      "      div (class=['nshcU0W']): 키타자와 후미타카프로듀서\n",
      "      div (class=['C9a9MX4']): 키타자와 후미타카프로듀서\n",
      "      div (class=['iO6bs1d']): 키타자와 후미타카\n",
      "      div (class=['_99DZmqJ']): 프로듀서\n",
      "    링크 5: Cong Cao프로듀서\n",
      "      div (class=['OuXf8uf', 'z4xkYZ9']): Cong Cao프로듀서\n",
      "      div (class=['ygvbJ2N']): \n",
      "      div (class=['whFyH-k']): \n",
      "      div (class=['H3oaiWl']): \n",
      "      div (class=['nshcU0W']): Cong Cao프로듀서\n",
      "      div (class=['C9a9MX4']): Cong Cao프로듀서\n",
      "      div (class=['iO6bs1d']): Cong Cao\n",
      "      div (class=['_99DZmqJ']): 프로듀서\n",
      "\n",
      "클래스 ['_1coMKET', '-HW4ChD']로 요소 발견\n",
      "  링크 수: 11\n",
      "  - 야마모토 히데요감독\n",
      "  - 타카하시 유마프로듀서\n",
      "  - 이토 요헤이프로듀서\n",
      "\n",
      "================================================================================\n",
      "3. 메타 데이터 확인\n",
      "================================================================================\n",
      "og:title: 일하는-세포-BLACK 작품 상세 정보\n",
      "og:description: 매일 부지런히 온몸으로 산소를 나르는 신참 적혈구.그러나 그의 직장의 노동환경은, 철저하게 - 작품 정보\n",
      "og:type: profile\n",
      "og:url: https://anilife.app/content/119/일하는-세포-BLACK/info\n",
      "\n",
      "완료!\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T07:55:08.098686Z",
     "start_time": "2025-09-05T07:50:19.824824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "import csv\n",
    "import time\n",
    "from typing import Dict, List, Optional\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from threading import Lock\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# 로깅 설정\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('anilife_scraping.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "class AnilifeScraper:\n",
    "    def __init__(self):\n",
    "        self.headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) StepByStepCrawler/0.1\",\n",
    "            \"Accept-Language\": \"ko-KR,ko;q=0.9,en-US;q=0.8\"\n",
    "        }\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update(self.headers)\n",
    "\n",
    "    def scrape_anime_info(self, url: str) -> Dict:\n",
    "        \"\"\"애니메이션 정보를 크롤링하는 메인 함수\"\"\"\n",
    "        try:\n",
    "            # URL 정규화 - info 탭으로 변경\n",
    "            if \"tab=info\" not in url:\n",
    "                if \"?\" in url:\n",
    "                    url = url.split(\"?\")[0] + \"?tab=info\"\n",
    "                else:\n",
    "                    url = url + \"?tab=info\"\n",
    "\n",
    "            # 웹페이지 요청\n",
    "            resp = self.session.get(url, timeout=20)\n",
    "\n",
    "            if resp.status_code != 200:\n",
    "                return {\"error\": f\"HTTP {resp.status_code} 에러\", \"url\": url}\n",
    "\n",
    "            # BeautifulSoup으로 파싱\n",
    "            soup = BeautifulSoup(resp.text, \"lxml\")\n",
    "\n",
    "            # Nuxt.js 데이터 추출\n",
    "            nuxt_data = self.extract_nuxt_data(resp.text)\n",
    "\n",
    "            # 디버깅: Nuxt 데이터 구조 확인 (첫 몇 개만)\n",
    "            anime_id = int(re.search(r'/content/(\\d+)', url).group(1))\n",
    "            if anime_id <= 105:  # 처음 몇 개만 디버깅\n",
    "                logging.debug(f\"ID {anime_id} - Nuxt data keys: {nuxt_data.keys() if nuxt_data else 'No data'}\")\n",
    "                if nuxt_data and 'pinia' in nuxt_data:\n",
    "                    logging.debug(f\"ID {anime_id} - Pinia keys: {nuxt_data['pinia'].keys()}\")\n",
    "\n",
    "            # 애니메이션 정보 추출\n",
    "            anime_info = {\n",
    "                \"url\": url,\n",
    "                \"id\": anime_id,\n",
    "                \"title\": self.extract_titles(soup, nuxt_data),\n",
    "                \"basic_info\": self.extract_basic_info(soup, nuxt_data),\n",
    "                \"genres\": self.extract_genres(soup, nuxt_data),\n",
    "                \"tags\": self.extract_tags(soup, nuxt_data),\n",
    "                \"synopsis\": self.extract_synopsis(soup, nuxt_data),\n",
    "                \"characters_voice_actors\": self.extract_characters_and_voice_actors(soup, nuxt_data),\n",
    "                \"production_info\": self.extract_production_info(soup, nuxt_data)\n",
    "            }\n",
    "\n",
    "            return anime_info\n",
    "\n",
    "        except requests.RequestException as e:\n",
    "            return {\"error\": f\"요청 에러: {str(e)}\", \"url\": url}\n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"파싱 에러: {str(e)}\", \"url\": url}\n",
    "\n",
    "    def extract_nuxt_data(self, html_content: str) -> Dict:\n",
    "        \"\"\"HTML에서 Nuxt.js __NUXT__ 데이터 추출\"\"\"\n",
    "        try:\n",
    "            pattern = r'window\\.__NUXT__=\\(function\\([^)]*\\)\\{return (.+?)\\}\\)\\([^)]+\\)'\n",
    "            match = re.search(pattern, html_content, re.DOTALL)\n",
    "\n",
    "            if match:\n",
    "                json_str = match.group(1)\n",
    "\n",
    "                replacements = {\n",
    "                    r'\\ba\\b': 'false',\n",
    "                    r'\\bb\\b': '1',\n",
    "                    r'\\bc\\b': 'true',\n",
    "                    r'\\bd\\b': 'null',\n",
    "                    r'\\be\\b': '\"system\"',\n",
    "                    r'\\bf\\b': '\"https://anilife.app\"',\n",
    "                    r'\\bg\\b': '\"N/A\"'\n",
    "                }\n",
    "\n",
    "                for pattern, value in replacements.items():\n",
    "                    json_str = re.sub(pattern, value, json_str)\n",
    "\n",
    "                data = json.loads(json_str)\n",
    "                return data\n",
    "\n",
    "            return {}\n",
    "\n",
    "        except Exception:\n",
    "            return {}\n",
    "\n",
    "    def extract_titles(self, soup: BeautifulSoup, nuxt_data: Dict) -> Dict[str, str]:\n",
    "        \"\"\"제목들 추출 (한국어, 일본어, 영어)\"\"\"\n",
    "        titles = {\"korean\": \"\", \"japanese\": \"\", \"english\": \"\"}\n",
    "\n",
    "        try:\n",
    "            content_detail = nuxt_data.get('pinia', {}).get('content', {}).get('contentDetail', {})\n",
    "            name_data = content_detail.get('name', {})\n",
    "\n",
    "            if name_data.get('kr'):\n",
    "                titles[\"korean\"] = name_data['kr']\n",
    "            if name_data.get('jp'):\n",
    "                titles[\"japanese\"] = name_data['jp']\n",
    "            if name_data.get('en'):\n",
    "                titles[\"english\"] = name_data['en']\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        if not titles[\"korean\"]:\n",
    "            korean_title_tag = soup.find('h1', class_='fpUXWby')\n",
    "            if korean_title_tag:\n",
    "                titles[\"korean\"] = korean_title_tag.get_text(strip=True).replace(\" 에피소드\", \"\").replace(\"정보\", \"\")\n",
    "\n",
    "        if not titles[\"japanese\"] or not titles[\"english\"]:\n",
    "            japanese_title_section = soup.find('h2', class_='visually-hidden')\n",
    "            if japanese_title_section:\n",
    "                span_tags = japanese_title_section.find_all('span')\n",
    "                if len(span_tags) >= 2:\n",
    "                    if not titles[\"japanese\"]:\n",
    "                        titles[\"japanese\"] = span_tags[0].get_text(strip=True)\n",
    "                    if not titles[\"english\"]:\n",
    "                        titles[\"english\"] = span_tags[1].get_text(strip=True)\n",
    "\n",
    "        return titles\n",
    "\n",
    "    def extract_basic_info(self, soup: BeautifulSoup, nuxt_data: Dict) -> Dict[str, str]:\n",
    "        \"\"\"기본 정보 추출\"\"\"\n",
    "        basic_info = {}\n",
    "\n",
    "        try:\n",
    "            content_detail = nuxt_data.get('pinia', {}).get('content', {}).get('contentDetail', {})\n",
    "\n",
    "            if content_detail.get('format'):\n",
    "                basic_info[\"format\"] = content_detail['format']\n",
    "\n",
    "            if content_detail.get('status'):\n",
    "                basic_info[\"status\"] = content_detail['status']\n",
    "\n",
    "            season_data = content_detail.get('season', {})\n",
    "            if season_data:\n",
    "                basic_info[\"year\"] = str(season_data.get('year', ''))\n",
    "                basic_info[\"quarter\"] = f\"{season_data.get('quarter', '')}분기\"\n",
    "\n",
    "            if content_detail.get('startDate'):\n",
    "                basic_info[\"start_date\"] = content_detail['startDate']\n",
    "\n",
    "            if content_detail.get('endDate') and content_detail['endDate'] != \"null\":\n",
    "                basic_info[\"end_date\"] = content_detail['endDate']\n",
    "\n",
    "            if content_detail.get('totalEpisode') and content_detail['totalEpisode'] != \"N/A\":\n",
    "                basic_info[\"total_episodes\"] = str(content_detail['totalEpisode'])\n",
    "\n",
    "            if content_detail.get('duration') and content_detail['duration'] != \"N/A\":\n",
    "                basic_info[\"duration\"] = str(content_detail['duration'])\n",
    "\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        if not basic_info.get('year') or not basic_info.get('quarter'):\n",
    "            quarter_info = soup.find('div', class_='nBnfiIh')\n",
    "            if quarter_info:\n",
    "                full_format = quarter_info.get_text(strip=True)\n",
    "                parts = full_format.split(' · ')\n",
    "\n",
    "                if len(parts) >= 2:\n",
    "                    if not basic_info.get('format'):\n",
    "                        basic_info[\"format\"] = parts[1]\n",
    "\n",
    "                    season_info = parts[0].split(' ')\n",
    "                    if len(season_info) >= 2:\n",
    "                        if not basic_info.get('year'):\n",
    "                            basic_info[\"year\"] = season_info[0]\n",
    "                        if not basic_info.get('quarter'):\n",
    "                            basic_info[\"quarter\"] = season_info[1]\n",
    "\n",
    "        return basic_info\n",
    "\n",
    "    def extract_genres(self, soup: BeautifulSoup, nuxt_data: Dict) -> List[str]:\n",
    "        \"\"\"장르 정보 추출\"\"\"\n",
    "        genres = []\n",
    "\n",
    "        try:\n",
    "            content_detail = nuxt_data.get('pinia', {}).get('content', {}).get('contentDetail', {})\n",
    "            nuxt_genres = content_detail.get('genre', [])\n",
    "            if nuxt_genres:\n",
    "                genres = nuxt_genres\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        if not genres:\n",
    "            genre_tags = soup.select('a[rel=\"genre\"]')\n",
    "            genres = [tag.get_text(strip=True) for tag in genre_tags]\n",
    "\n",
    "        return genres\n",
    "\n",
    "    def extract_tags(self, soup: BeautifulSoup, nuxt_data: Dict) -> List[str]:\n",
    "        \"\"\"태그 정보 추출\"\"\"\n",
    "        tags = []\n",
    "\n",
    "        try:\n",
    "            content_detail = nuxt_data.get('pinia', {}).get('content', {}).get('contentDetail', {})\n",
    "            tag_data = content_detail.get('tag', [])\n",
    "\n",
    "            for tag_item in tag_data:\n",
    "                if isinstance(tag_item, dict) and tag_item.get('name'):\n",
    "                    tag_name = tag_item['name']\n",
    "                    if tag_item.get('spoiler'):\n",
    "                        tag_name += \" (스포일러)\"\n",
    "                    tags.append(tag_name)\n",
    "                elif isinstance(tag_item, str):\n",
    "                    tags.append(tag_item)\n",
    "\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        if not tags:\n",
    "            tag_section = None\n",
    "            for h2 in soup.find_all('h2', class_='wXeFmvm'):\n",
    "                if '작품 태그' in h2.get_text():\n",
    "                    tag_section = h2.find_parent('section')\n",
    "                    break\n",
    "\n",
    "            if tag_section:\n",
    "                tag_container = tag_section.find('div', class_='-mMZ9fV')\n",
    "                if tag_container:\n",
    "                    tag_links = tag_container.find_all('a', class_='MbHceQh')\n",
    "                    for link in tag_links:\n",
    "                        span = link.find('span')\n",
    "                        if span:\n",
    "                            tag_text = span.get_text(strip=True).replace('#', '')\n",
    "                            if 'iYz6NWc' in span.get('class', []):\n",
    "                                tag_text += \" (스포일러)\"\n",
    "                            tags.append(tag_text)\n",
    "\n",
    "        return tags\n",
    "\n",
    "    def extract_synopsis(self, soup: BeautifulSoup, nuxt_data: Dict) -> str:\n",
    "        \"\"\"줄거리 추출\"\"\"\n",
    "        try:\n",
    "            content_detail = nuxt_data.get('pinia', {}).get('content', {}).get('contentDetail', {})\n",
    "            description = content_detail.get('description', '')\n",
    "            if description and description != \"등록된 줄거리가 없습니다.\":\n",
    "                return description\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        description_div = soup.find('div', class_='bnHDzeE')\n",
    "        if description_div:\n",
    "            synopsis = description_div.get_text(strip=True)\n",
    "            if synopsis and synopsis != \"등록된 줄거리가 없습니다.\":\n",
    "                return synopsis\n",
    "\n",
    "        return \"등록된 줄거리가 없습니다.\"\n",
    "\n",
    "    def extract_characters_and_voice_actors(self, soup: BeautifulSoup, nuxt_data: Dict) -> List[Dict]:\n",
    "        \"\"\"캐릭터 및 성우 정보 추출\"\"\"\n",
    "        characters = []\n",
    "        character_cards = soup.find_all('div', class_='otjBFjd')\n",
    "\n",
    "        for card in character_cards:\n",
    "            character_div = card.find('div', class_='OuXf8uf')\n",
    "            voice_actor_link = card.find('a')\n",
    "            character_info = {}\n",
    "\n",
    "            if character_div:\n",
    "                name_elem = character_div.find('div', class_='iO6bs1d')\n",
    "                role_elem = character_div.find('div', class_='_99DZmqJ')\n",
    "\n",
    "                if name_elem:\n",
    "                    character_info['character_name'] = name_elem.get_text(strip=True)\n",
    "                if role_elem:\n",
    "                    character_info['character_role'] = role_elem.get_text(strip=True)\n",
    "\n",
    "                if character_div.get('data-original-title'):\n",
    "                    if not character_info.get('character_name'):\n",
    "                        character_info['character_name'] = character_div['data-original-title']\n",
    "\n",
    "            if voice_actor_link:\n",
    "                voice_actor_div = voice_actor_link.find('div', class_='_0fu6hck')\n",
    "                if voice_actor_div:\n",
    "                    voice_name_elem = voice_actor_div.find('div', class_='iO6bs1d')\n",
    "                    if voice_name_elem:\n",
    "                        character_info['voice_actor'] = voice_name_elem.get_text(strip=True)\n",
    "\n",
    "                    if voice_actor_div.get('title'):\n",
    "                        if not character_info.get('voice_actor'):\n",
    "                            character_info['voice_actor'] = voice_actor_div['title']\n",
    "\n",
    "            if character_info:\n",
    "                characters.append(character_info)\n",
    "\n",
    "        return characters\n",
    "\n",
    "    def extract_production_info(self, soup: BeautifulSoup, nuxt_data: Dict) -> Dict[str, str]:\n",
    "        \"\"\"제작 정보 추출\"\"\"\n",
    "        production_info = {}\n",
    "        production_section = soup.find('div', class_='_1coMKET -HW4ChD')\n",
    "\n",
    "        if production_section:\n",
    "            production_links = production_section.find_all('a', class_='_2hRLd-G')\n",
    "\n",
    "            for link in production_links:\n",
    "                staff_div = link.find('div', class_='OuXf8uf')\n",
    "\n",
    "                if staff_div:\n",
    "                    name_elem = staff_div.find('div', class_='iO6bs1d')\n",
    "                    role_elem = staff_div.find('div', class_='_99DZmqJ')\n",
    "\n",
    "                    if name_elem and role_elem:\n",
    "                        name = name_elem.get_text(strip=True)\n",
    "                        role = role_elem.get_text(strip=True)\n",
    "\n",
    "                        if role not in production_info:\n",
    "                            production_info[role] = []\n",
    "\n",
    "                        if isinstance(production_info[role], list):\n",
    "                            production_info[role].append(name)\n",
    "                        else:\n",
    "                            production_info[role] = [production_info[role], name]\n",
    "\n",
    "                    if staff_div.get('title'):\n",
    "                        if not name_elem:\n",
    "                            name = staff_div['title']\n",
    "                            if role_elem:\n",
    "                                role = role_elem.get_text(strip=True)\n",
    "                                if role not in production_info:\n",
    "                                    production_info[role] = name\n",
    "\n",
    "        for role, names in production_info.items():\n",
    "            if isinstance(names, list):\n",
    "                production_info[role] = ', '.join(names)\n",
    "\n",
    "        return production_info\n",
    "\n",
    "\n",
    "class ParallelAnilifeScraper:\n",
    "    def __init__(self, max_workers=10):\n",
    "        self.max_workers = max_workers\n",
    "        self.results = []\n",
    "        self.errors = []\n",
    "        self.lock = Lock()\n",
    "        self.progress_lock = Lock()\n",
    "        self.completed_count = 0\n",
    "        self.total_count = 0\n",
    "\n",
    "    def scrape_single(self, anime_id: int) -> Dict:\n",
    "        \"\"\"단일 애니메이션 크롤링\"\"\"\n",
    "        url = f\"https://anilife.app/content/{anime_id}?tab=info\"\n",
    "        scraper = AnilifeScraper()\n",
    "\n",
    "        try:\n",
    "            result = scraper.scrape_anime_info(url)\n",
    "\n",
    "            with self.progress_lock:\n",
    "                self.completed_count += 1\n",
    "                if self.completed_count % 10 == 0:\n",
    "                    logging.info(f\"진행률: {self.completed_count}/{self.total_count} ({self.completed_count/self.total_count*100:.1f}%)\")\n",
    "\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            logging.error(f\"ID {anime_id} 크롤링 실패: {str(e)}\")\n",
    "            return {\"error\": str(e), \"id\": anime_id, \"url\": url}\n",
    "\n",
    "    def process_result(self, anime_data: Dict) -> Dict:\n",
    "        \"\"\"크롤링 결과를 CSV용 플랫 딕셔너리로 변환\"\"\"\n",
    "        if \"error\" in anime_data:\n",
    "            return {\"id\": anime_data.get(\"id\", \"\"), \"error\": anime_data[\"error\"]}\n",
    "\n",
    "        flat_data = {\n",
    "            \"id\": anime_data.get(\"id\", \"\"),\n",
    "            \"url\": anime_data.get(\"url\", \"\"),\n",
    "            \"title_korean\": anime_data.get(\"title\", {}).get(\"korean\", \"\"),\n",
    "            \"title_japanese\": anime_data.get(\"title\", {}).get(\"japanese\", \"\"),\n",
    "            \"title_english\": anime_data.get(\"title\", {}).get(\"english\", \"\"),\n",
    "            \"format\": anime_data.get(\"basic_info\", {}).get(\"format\", \"\"),\n",
    "            \"status\": anime_data.get(\"basic_info\", {}).get(\"status\", \"\"),\n",
    "            \"year\": anime_data.get(\"basic_info\", {}).get(\"year\", \"\"),\n",
    "            \"quarter\": anime_data.get(\"basic_info\", {}).get(\"quarter\", \"\"),\n",
    "            \"start_date\": anime_data.get(\"basic_info\", {}).get(\"start_date\", \"\"),\n",
    "            \"end_date\": anime_data.get(\"basic_info\", {}).get(\"end_date\", \"\"),\n",
    "            \"total_episodes\": anime_data.get(\"basic_info\", {}).get(\"total_episodes\", \"\"),\n",
    "            \"duration\": anime_data.get(\"basic_info\", {}).get(\"duration\", \"\"),\n",
    "            \"genres\": \"|\".join(anime_data.get(\"genres\", [])),\n",
    "            \"tags\": \"|\".join(anime_data.get(\"tags\", [])),\n",
    "            \"synopsis\": anime_data.get(\"synopsis\", \"\"),\n",
    "            \"num_characters\": len(anime_data.get(\"characters_voice_actors\", [])),\n",
    "            \"main_characters\": \"|\".join([\n",
    "                f\"{c.get('character_name', '')}({c.get('voice_actor', '')})\"\n",
    "                for c in anime_data.get(\"characters_voice_actors\", [])[:5]\n",
    "            ]),\n",
    "            \"director\": anime_data.get(\"production_info\", {}).get(\"감독\", \"\"),\n",
    "            \"studio\": anime_data.get(\"production_info\", {}).get(\"애니메이션 제작\", \"\"),\n",
    "            \"original_work\": anime_data.get(\"production_info\", {}).get(\"원작자\", \"\") or anime_data.get(\"production_info\", {}).get(\"원작\", \"\"),\n",
    "            \"error\": \"\"\n",
    "        }\n",
    "\n",
    "        return flat_data\n",
    "\n",
    "    def scrape_range(self, start_id: int, end_id: int, batch_size: int = 100):\n",
    "        \"\"\"지정된 범위의 애니메이션 병렬 크롤링\"\"\"\n",
    "        self.total_count = end_id - start_id + 1\n",
    "        self.completed_count = 0\n",
    "\n",
    "        logging.info(f\"크롤링 시작: ID {start_id}부터 {end_id}까지 (총 {self.total_count}개)\")\n",
    "\n",
    "        # 배치 단위로 처리\n",
    "        for batch_start in range(start_id, end_id + 1, batch_size):\n",
    "            batch_end = min(batch_start + batch_size - 1, end_id)\n",
    "            batch_ids = list(range(batch_start, batch_end + 1))\n",
    "\n",
    "            logging.info(f\"배치 처리 중: ID {batch_start} ~ {batch_end}\")\n",
    "\n",
    "            with ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n",
    "                futures = {executor.submit(self.scrape_single, anime_id): anime_id\n",
    "                          for anime_id in batch_ids}\n",
    "\n",
    "                for future in as_completed(futures):\n",
    "                    anime_id = futures[future]\n",
    "                    try:\n",
    "                        result = future.result(timeout=30)\n",
    "                        processed_result = self.process_result(result)\n",
    "\n",
    "                        with self.lock:\n",
    "                            if processed_result.get(\"error\"):\n",
    "                                self.errors.append(processed_result)\n",
    "                            else:\n",
    "                                self.results.append(processed_result)\n",
    "\n",
    "                    except Exception as e:\n",
    "                        logging.error(f\"ID {anime_id} 처리 실패: {str(e)}\")\n",
    "                        with self.lock:\n",
    "                            self.errors.append({\"id\": anime_id, \"error\": str(e)})\n",
    "\n",
    "            # 배치 간 대기 시간 (서버 부하 방지)\n",
    "            time.sleep(2)\n",
    "\n",
    "            # 중간 저장 (매 500개마다)\n",
    "            if len(self.results) % 500 == 0 and self.results:\n",
    "                self.save_intermediate_results()\n",
    "\n",
    "    def save_intermediate_results(self):\n",
    "        \"\"\"중간 결과 저장\"\"\"\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        filename = f\"anilife_intermediate_{timestamp}.csv\"\n",
    "\n",
    "        with self.lock:\n",
    "            if self.results:\n",
    "                self.save_to_csv(filename, self.results)\n",
    "                logging.info(f\"중간 결과 저장: {filename} ({len(self.results)}개 항목)\")\n",
    "\n",
    "    def save_to_csv(self, filename: str, data: List[Dict]):\n",
    "        \"\"\"결과를 CSV 파일로 저장\"\"\"\n",
    "        if not data:\n",
    "            logging.warning(\"저장할 데이터가 없습니다.\")\n",
    "            return\n",
    "\n",
    "        fieldnames = [\n",
    "            \"id\", \"url\", \"title_korean\", \"title_japanese\", \"title_english\",\n",
    "            \"format\", \"status\", \"year\", \"quarter\", \"start_date\", \"end_date\",\n",
    "            \"total_episodes\", \"duration\", \"genres\", \"tags\", \"synopsis\",\n",
    "            \"num_characters\", \"main_characters\", \"director\", \"studio\",\n",
    "            \"original_work\", \"error\"\n",
    "        ]\n",
    "\n",
    "        with open(filename, 'w', newline='', encoding='utf-8-sig') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(data)\n",
    "\n",
    "        logging.info(f\"CSV 파일 저장 완료: {filename}\")\n",
    "\n",
    "    def save_all_results(self):\n",
    "        \"\"\"모든 결과 저장\"\"\"\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "        # 성공 데이터 저장\n",
    "        if self.results:\n",
    "            success_filename = f\"anilife_data_{timestamp}.csv\"\n",
    "            self.save_to_csv(success_filename, self.results)\n",
    "            logging.info(f\"성공 데이터: {len(self.results)}개 항목\")\n",
    "\n",
    "        # 에러 데이터 저장\n",
    "        if self.errors:\n",
    "            error_filename = f\"anilife_errors_{timestamp}.csv\"\n",
    "            self.save_to_csv(error_filename, self.errors)\n",
    "            logging.info(f\"에러 데이터: {len(self.errors)}개 항목\")\n",
    "\n",
    "        # 통계 출력\n",
    "        total = len(self.results) + len(self.errors)\n",
    "        success_rate = (len(self.results) / total * 100) if total > 0 else 0\n",
    "\n",
    "        logging.info(f\"\\n크롤링 완료 통계:\")\n",
    "        logging.info(f\"- 전체: {total}개\")\n",
    "        logging.info(f\"- 성공: {len(self.results)}개\")\n",
    "        logging.info(f\"- 실패: {len(self.errors)}개\")\n",
    "        logging.info(f\"- 성공률: {success_rate:.1f}%\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"메인 실행 함수\"\"\"\n",
    "    # 설정\n",
    "    START_ID = 101\n",
    "    END_ID = 7000\n",
    "    MAX_WORKERS = 30  # 동시 실행 스레드 수 (서버 부하 고려하여 조정)\n",
    "    BATCH_SIZE = 100  # 한 번에 처리할 항목 수\n",
    "    USE_BATCH = True  # True: 배치 처리, False: 전체 동시 처리\n",
    "\n",
    "    # 스크래퍼 초기화\n",
    "    scraper = ParallelAnilifeScraper(max_workers=MAX_WORKERS)\n",
    "\n",
    "    # 시작 시간 기록\n",
    "    start_time = time.time()\n",
    "\n",
    "    try:\n",
    "        # 크롤링 실행\n",
    "        if USE_BATCH:\n",
    "            # 배치 단위로 처리 (안정적, 권장)\n",
    "            scraper.scrape_range(START_ID, END_ID, batch_size=BATCH_SIZE)\n",
    "        else:\n",
    "            # 모든 ID를 한 번에 처리 (빠르지만 부하 높음)\n",
    "            scraper.scrape_range_all_at_once(START_ID, END_ID)\n",
    "\n",
    "        # 결과 저장\n",
    "        scraper.save_all_results()\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        logging.info(\"\\n크롤링이 사용자에 의해 중단되었습니다.\")\n",
    "        scraper.save_all_results()\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"크롤링 중 오류 발생: {str(e)}\")\n",
    "        scraper.save_all_results()\n",
    "\n",
    "    finally:\n",
    "        # 소요 시간 출력\n",
    "        elapsed_time = time.time() - start_time\n",
    "        hours = int(elapsed_time // 3600)\n",
    "        minutes = int((elapsed_time % 3600) // 60)\n",
    "        seconds = int(elapsed_time % 60)\n",
    "\n",
    "        logging.info(f\"\\n총 소요 시간: {hours}시간 {minutes}분 {seconds}초\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "25615e4ea1e48e3f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-05 16:50:19,863 - INFO - 크롤링 시작: ID 101부터 7000까지 (총 6900개)\n",
      "2025-09-05 16:50:19,864 - INFO - 배치 처리 중: ID 101 ~ 200\n",
      "2025-09-05 16:50:20,649 - INFO - 진행률: 10/6900 (0.1%)\n",
      "2025-09-05 16:50:20,889 - INFO - 진행률: 20/6900 (0.3%)\n",
      "2025-09-05 16:50:21,035 - INFO - 진행률: 30/6900 (0.4%)\n",
      "2025-09-05 16:50:21,194 - INFO - 진행률: 40/6900 (0.6%)\n",
      "2025-09-05 16:50:21,510 - INFO - 진행률: 50/6900 (0.7%)\n",
      "2025-09-05 16:50:21,773 - INFO - 진행률: 60/6900 (0.9%)\n",
      "2025-09-05 16:50:21,932 - INFO - 진행률: 70/6900 (1.0%)\n",
      "2025-09-05 16:50:22,246 - INFO - 진행률: 80/6900 (1.2%)\n",
      "2025-09-05 16:50:22,496 - INFO - 진행률: 90/6900 (1.3%)\n",
      "2025-09-05 16:50:22,618 - INFO - 진행률: 100/6900 (1.4%)\n",
      "2025-09-05 16:50:24,620 - INFO - 배치 처리 중: ID 201 ~ 300\n",
      "2025-09-05 16:50:25,243 - INFO - 진행률: 110/6900 (1.6%)\n",
      "2025-09-05 16:50:25,424 - INFO - 진행률: 120/6900 (1.7%)\n",
      "2025-09-05 16:50:25,576 - INFO - 진행률: 130/6900 (1.9%)\n",
      "2025-09-05 16:50:25,791 - INFO - 진행률: 140/6900 (2.0%)\n",
      "2025-09-05 16:50:26,050 - INFO - 진행률: 150/6900 (2.2%)\n",
      "2025-09-05 16:50:26,481 - INFO - 진행률: 160/6900 (2.3%)\n",
      "2025-09-05 16:50:26,663 - INFO - 진행률: 170/6900 (2.5%)\n",
      "2025-09-05 16:50:26,817 - INFO - 진행률: 180/6900 (2.6%)\n",
      "2025-09-05 16:50:27,003 - INFO - 진행률: 190/6900 (2.8%)\n",
      "2025-09-05 16:50:27,147 - INFO - 진행률: 200/6900 (2.9%)\n",
      "2025-09-05 16:50:29,156 - INFO - 배치 처리 중: ID 301 ~ 400\n",
      "2025-09-05 16:50:29,891 - INFO - 진행률: 210/6900 (3.0%)\n",
      "2025-09-05 16:50:30,107 - INFO - 진행률: 220/6900 (3.2%)\n",
      "2025-09-05 16:50:30,447 - INFO - 진행률: 230/6900 (3.3%)\n",
      "2025-09-05 16:50:30,603 - INFO - 진행률: 240/6900 (3.5%)\n",
      "2025-09-05 16:50:30,743 - INFO - 진행률: 250/6900 (3.6%)\n",
      "2025-09-05 16:50:30,977 - INFO - 진행률: 260/6900 (3.8%)\n",
      "2025-09-05 16:50:31,195 - INFO - 진행률: 270/6900 (3.9%)\n",
      "2025-09-05 16:50:31,480 - INFO - 진행률: 280/6900 (4.1%)\n",
      "2025-09-05 16:50:31,624 - INFO - 진행률: 290/6900 (4.2%)\n",
      "2025-09-05 16:50:31,721 - INFO - 진행률: 300/6900 (4.3%)\n",
      "2025-09-05 16:50:33,725 - INFO - 배치 처리 중: ID 401 ~ 500\n",
      "2025-09-05 16:50:34,563 - INFO - 진행률: 310/6900 (4.5%)\n",
      "2025-09-05 16:50:34,693 - INFO - 진행률: 320/6900 (4.6%)\n",
      "2025-09-05 16:50:34,815 - INFO - 진행률: 330/6900 (4.8%)\n",
      "2025-09-05 16:50:35,113 - INFO - 진행률: 340/6900 (4.9%)\n",
      "2025-09-05 16:50:35,353 - INFO - 진행률: 350/6900 (5.1%)\n",
      "2025-09-05 16:50:35,508 - INFO - 진행률: 360/6900 (5.2%)\n",
      "2025-09-05 16:50:35,726 - INFO - 진행률: 370/6900 (5.4%)\n",
      "2025-09-05 16:50:35,941 - INFO - 진행률: 380/6900 (5.5%)\n",
      "2025-09-05 16:50:36,211 - INFO - 진행률: 390/6900 (5.7%)\n",
      "2025-09-05 16:50:36,283 - INFO - 진행률: 400/6900 (5.8%)\n",
      "2025-09-05 16:50:38,285 - INFO - 배치 처리 중: ID 501 ~ 600\n",
      "2025-09-05 16:50:38,927 - INFO - 진행률: 410/6900 (5.9%)\n",
      "2025-09-05 16:50:39,109 - INFO - 진행률: 420/6900 (6.1%)\n",
      "2025-09-05 16:50:39,302 - INFO - 진행률: 430/6900 (6.2%)\n",
      "2025-09-05 16:50:39,533 - INFO - 진행률: 440/6900 (6.4%)\n",
      "2025-09-05 16:50:39,785 - INFO - 진행률: 450/6900 (6.5%)\n",
      "2025-09-05 16:50:39,922 - INFO - 진행률: 460/6900 (6.7%)\n",
      "2025-09-05 16:50:40,260 - INFO - 진행률: 470/6900 (6.8%)\n",
      "2025-09-05 16:50:40,475 - INFO - 진행률: 480/6900 (7.0%)\n",
      "2025-09-05 16:50:40,614 - INFO - 진행률: 490/6900 (7.1%)\n",
      "2025-09-05 16:50:40,735 - INFO - 진행률: 500/6900 (7.2%)\n",
      "2025-09-05 16:50:42,740 - INFO - 배치 처리 중: ID 601 ~ 700\n",
      "2025-09-05 16:50:43,384 - INFO - 진행률: 510/6900 (7.4%)\n",
      "2025-09-05 16:50:43,515 - INFO - 진행률: 520/6900 (7.5%)\n",
      "2025-09-05 16:50:43,654 - INFO - 진행률: 530/6900 (7.7%)\n",
      "2025-09-05 16:50:43,933 - INFO - 진행률: 540/6900 (7.8%)\n",
      "2025-09-05 16:50:44,366 - INFO - 진행률: 550/6900 (8.0%)\n",
      "2025-09-05 16:50:44,556 - INFO - 진행률: 560/6900 (8.1%)\n",
      "2025-09-05 16:50:44,682 - INFO - 진행률: 570/6900 (8.3%)\n",
      "2025-09-05 16:50:44,881 - INFO - 진행률: 580/6900 (8.4%)\n",
      "2025-09-05 16:50:45,044 - INFO - 진행률: 590/6900 (8.6%)\n",
      "2025-09-05 16:50:45,187 - INFO - 진행률: 600/6900 (8.7%)\n",
      "2025-09-05 16:50:47,214 - INFO - 배치 처리 중: ID 701 ~ 800\n",
      "2025-09-05 16:50:47,899 - INFO - 진행률: 610/6900 (8.8%)\n",
      "2025-09-05 16:50:48,069 - INFO - 진행률: 620/6900 (9.0%)\n",
      "2025-09-05 16:50:48,609 - INFO - 진행률: 630/6900 (9.1%)\n",
      "2025-09-05 16:50:49,014 - INFO - 진행률: 640/6900 (9.3%)\n",
      "2025-09-05 16:50:49,166 - INFO - 진행률: 650/6900 (9.4%)\n",
      "2025-09-05 16:50:49,353 - INFO - 진행률: 660/6900 (9.6%)\n",
      "2025-09-05 16:50:49,573 - INFO - 진행률: 670/6900 (9.7%)\n",
      "2025-09-05 16:50:49,728 - INFO - 진행률: 680/6900 (9.9%)\n",
      "2025-09-05 16:50:49,938 - INFO - 진행률: 690/6900 (10.0%)\n",
      "2025-09-05 16:50:50,059 - INFO - 진행률: 700/6900 (10.1%)\n",
      "2025-09-05 16:50:52,183 - INFO - 배치 처리 중: ID 801 ~ 900\n",
      "2025-09-05 16:50:53,077 - INFO - 진행률: 710/6900 (10.3%)\n",
      "2025-09-05 16:50:53,184 - INFO - 진행률: 720/6900 (10.4%)\n",
      "2025-09-05 16:50:53,298 - INFO - 진행률: 730/6900 (10.6%)\n",
      "2025-09-05 16:50:53,539 - INFO - 진행률: 740/6900 (10.7%)\n",
      "2025-09-05 16:50:53,800 - INFO - 진행률: 750/6900 (10.9%)\n",
      "2025-09-05 16:50:53,925 - INFO - 진행률: 760/6900 (11.0%)\n",
      "2025-09-05 16:50:54,126 - INFO - 진행률: 770/6900 (11.2%)\n",
      "2025-09-05 16:50:54,597 - INFO - 진행률: 780/6900 (11.3%)\n",
      "2025-09-05 16:50:54,695 - INFO - 진행률: 790/6900 (11.4%)\n",
      "2025-09-05 16:50:54,778 - INFO - 진행률: 800/6900 (11.6%)\n",
      "2025-09-05 16:50:56,783 - INFO - 배치 처리 중: ID 901 ~ 1000\n",
      "2025-09-05 16:50:57,457 - INFO - 진행률: 810/6900 (11.7%)\n",
      "2025-09-05 16:50:57,599 - INFO - 진행률: 820/6900 (11.9%)\n",
      "2025-09-05 16:50:57,731 - INFO - 진행률: 830/6900 (12.0%)\n",
      "2025-09-05 16:50:57,889 - INFO - 진행률: 840/6900 (12.2%)\n",
      "2025-09-05 16:50:58,384 - INFO - 진행률: 850/6900 (12.3%)\n",
      "2025-09-05 16:50:58,670 - INFO - 진행률: 860/6900 (12.5%)\n",
      "2025-09-05 16:50:58,822 - INFO - 진행률: 870/6900 (12.6%)\n",
      "2025-09-05 16:50:59,040 - INFO - 진행률: 880/6900 (12.8%)\n",
      "2025-09-05 16:50:59,233 - INFO - 진행률: 890/6900 (12.9%)\n",
      "2025-09-05 16:50:59,346 - INFO - 진행률: 900/6900 (13.0%)\n",
      "2025-09-05 16:51:01,463 - INFO - 배치 처리 중: ID 1001 ~ 1100\n",
      "2025-09-05 16:51:02,371 - INFO - 진행률: 910/6900 (13.2%)\n",
      "2025-09-05 16:51:02,914 - INFO - 진행률: 920/6900 (13.3%)\n",
      "2025-09-05 16:51:03,097 - INFO - 진행률: 930/6900 (13.5%)\n",
      "2025-09-05 16:51:03,218 - INFO - 진행률: 940/6900 (13.6%)\n",
      "2025-09-05 16:51:03,392 - INFO - 진행률: 950/6900 (13.8%)\n",
      "2025-09-05 16:51:03,657 - INFO - 진행률: 960/6900 (13.9%)\n",
      "2025-09-05 16:51:03,825 - INFO - 진행률: 970/6900 (14.1%)\n",
      "2025-09-05 16:51:03,988 - INFO - 진행률: 980/6900 (14.2%)\n",
      "2025-09-05 16:51:04,175 - INFO - 진행률: 990/6900 (14.3%)\n",
      "2025-09-05 16:51:04,290 - INFO - 진행률: 1000/6900 (14.5%)\n",
      "2025-09-05 16:51:06,293 - INFO - 배치 처리 중: ID 1101 ~ 1200\n",
      "2025-09-05 16:51:07,019 - INFO - 진행률: 1010/6900 (14.6%)\n",
      "2025-09-05 16:51:07,175 - INFO - 진행률: 1020/6900 (14.8%)\n",
      "2025-09-05 16:51:07,257 - INFO - 진행률: 1030/6900 (14.9%)\n",
      "2025-09-05 16:51:07,462 - INFO - 진행률: 1040/6900 (15.1%)\n",
      "2025-09-05 16:51:07,696 - INFO - 진행률: 1050/6900 (15.2%)\n",
      "2025-09-05 16:51:07,912 - INFO - 진행률: 1060/6900 (15.4%)\n",
      "2025-09-05 16:51:08,107 - INFO - 진행률: 1070/6900 (15.5%)\n",
      "2025-09-05 16:51:08,299 - INFO - 진행률: 1080/6900 (15.7%)\n",
      "2025-09-05 16:51:08,475 - INFO - 진행률: 1090/6900 (15.8%)\n",
      "2025-09-05 16:51:08,782 - INFO - 진행률: 1100/6900 (15.9%)\n",
      "2025-09-05 16:51:10,787 - INFO - 배치 처리 중: ID 1201 ~ 1300\n",
      "2025-09-05 16:51:11,445 - INFO - 진행률: 1110/6900 (16.1%)\n",
      "2025-09-05 16:51:11,598 - INFO - 진행률: 1120/6900 (16.2%)\n",
      "2025-09-05 16:51:11,749 - INFO - 진행률: 1130/6900 (16.4%)\n",
      "2025-09-05 16:51:11,926 - INFO - 진행률: 1140/6900 (16.5%)\n",
      "2025-09-05 16:51:12,193 - INFO - 진행률: 1150/6900 (16.7%)\n",
      "2025-09-05 16:51:12,420 - INFO - 진행률: 1160/6900 (16.8%)\n",
      "2025-09-05 16:51:12,811 - INFO - 진행률: 1170/6900 (17.0%)\n",
      "2025-09-05 16:51:12,976 - INFO - 진행률: 1180/6900 (17.1%)\n",
      "2025-09-05 16:51:13,119 - INFO - 진행률: 1190/6900 (17.2%)\n",
      "2025-09-05 16:51:13,212 - INFO - 진행률: 1200/6900 (17.4%)\n",
      "2025-09-05 16:51:15,215 - INFO - 배치 처리 중: ID 1301 ~ 1400\n",
      "2025-09-05 16:51:15,854 - INFO - 진행률: 1210/6900 (17.5%)\n",
      "2025-09-05 16:51:16,028 - INFO - 진행률: 1220/6900 (17.7%)\n",
      "2025-09-05 16:51:16,147 - INFO - 진행률: 1230/6900 (17.8%)\n",
      "2025-09-05 16:51:16,350 - INFO - 진행률: 1240/6900 (18.0%)\n",
      "2025-09-05 16:51:16,534 - INFO - 진행률: 1250/6900 (18.1%)\n",
      "2025-09-05 16:51:17,017 - INFO - 진행률: 1260/6900 (18.3%)\n",
      "2025-09-05 16:51:17,152 - INFO - 진행률: 1270/6900 (18.4%)\n",
      "2025-09-05 16:51:17,278 - INFO - 진행률: 1280/6900 (18.6%)\n",
      "2025-09-05 16:51:17,481 - INFO - 진행률: 1290/6900 (18.7%)\n",
      "2025-09-05 16:51:17,598 - INFO - 진행률: 1300/6900 (18.8%)\n",
      "2025-09-05 16:51:19,600 - INFO - 배치 처리 중: ID 1401 ~ 1500\n",
      "2025-09-05 16:51:20,236 - INFO - 진행률: 1310/6900 (19.0%)\n",
      "2025-09-05 16:51:20,396 - INFO - 진행률: 1320/6900 (19.1%)\n",
      "2025-09-05 16:51:20,517 - INFO - 진행률: 1330/6900 (19.3%)\n",
      "2025-09-05 16:51:21,073 - INFO - 진행률: 1340/6900 (19.4%)\n",
      "2025-09-05 16:51:21,194 - INFO - 진행률: 1350/6900 (19.6%)\n",
      "2025-09-05 16:51:21,341 - INFO - 진행률: 1360/6900 (19.7%)\n",
      "2025-09-05 16:51:21,560 - INFO - 진행률: 1370/6900 (19.9%)\n",
      "2025-09-05 16:51:21,842 - INFO - 진행률: 1380/6900 (20.0%)\n",
      "2025-09-05 16:51:22,013 - INFO - 진행률: 1390/6900 (20.1%)\n",
      "2025-09-05 16:51:22,100 - INFO - 진행률: 1400/6900 (20.3%)\n",
      "2025-09-05 16:51:24,103 - INFO - 배치 처리 중: ID 1501 ~ 1600\n",
      "2025-09-05 16:51:24,896 - INFO - 진행률: 1410/6900 (20.4%)\n",
      "2025-09-05 16:51:25,043 - INFO - 진행률: 1420/6900 (20.6%)\n",
      "2025-09-05 16:51:25,167 - INFO - 진행률: 1430/6900 (20.7%)\n",
      "2025-09-05 16:51:25,375 - INFO - 진행률: 1440/6900 (20.9%)\n",
      "2025-09-05 16:51:25,608 - INFO - 진행률: 1450/6900 (21.0%)\n",
      "2025-09-05 16:51:25,832 - INFO - 진행률: 1460/6900 (21.2%)\n",
      "2025-09-05 16:51:26,042 - INFO - 진행률: 1470/6900 (21.3%)\n",
      "2025-09-05 16:51:26,188 - INFO - 진행률: 1480/6900 (21.4%)\n",
      "2025-09-05 16:51:26,336 - INFO - 진행률: 1490/6900 (21.6%)\n",
      "2025-09-05 16:51:27,259 - INFO - 진행률: 1500/6900 (21.7%)\n",
      "2025-09-05 16:51:29,264 - INFO - 배치 처리 중: ID 1601 ~ 1700\n",
      "2025-09-05 16:51:29,880 - INFO - 진행률: 1510/6900 (21.9%)\n",
      "2025-09-05 16:51:30,076 - INFO - 진행률: 1520/6900 (22.0%)\n",
      "2025-09-05 16:51:30,276 - INFO - 진행률: 1530/6900 (22.2%)\n",
      "2025-09-05 16:51:30,456 - INFO - 진행률: 1540/6900 (22.3%)\n",
      "2025-09-05 16:51:30,684 - INFO - 진행률: 1550/6900 (22.5%)\n",
      "2025-09-05 16:51:30,935 - INFO - 진행률: 1560/6900 (22.6%)\n",
      "2025-09-05 16:51:31,416 - INFO - 진행률: 1570/6900 (22.8%)\n",
      "2025-09-05 16:51:31,615 - INFO - 진행률: 1580/6900 (22.9%)\n",
      "2025-09-05 16:51:31,732 - INFO - 진행률: 1590/6900 (23.0%)\n",
      "2025-09-05 16:51:31,866 - INFO - 진행률: 1600/6900 (23.2%)\n",
      "2025-09-05 16:51:33,871 - INFO - 배치 처리 중: ID 1701 ~ 1800\n",
      "2025-09-05 16:51:34,527 - INFO - 진행률: 1610/6900 (23.3%)\n",
      "2025-09-05 16:51:34,683 - INFO - 진행률: 1620/6900 (23.5%)\n",
      "2025-09-05 16:51:34,828 - INFO - 진행률: 1630/6900 (23.6%)\n",
      "2025-09-05 16:51:35,335 - INFO - 진행률: 1640/6900 (23.8%)\n",
      "2025-09-05 16:51:35,547 - INFO - 진행률: 1650/6900 (23.9%)\n",
      "2025-09-05 16:51:35,688 - INFO - 진행률: 1660/6900 (24.1%)\n",
      "2025-09-05 16:51:35,878 - INFO - 진행률: 1670/6900 (24.2%)\n",
      "2025-09-05 16:51:36,041 - INFO - 진행률: 1680/6900 (24.3%)\n",
      "2025-09-05 16:51:36,223 - INFO - 진행률: 1690/6900 (24.5%)\n",
      "2025-09-05 16:51:36,301 - INFO - 진행률: 1700/6900 (24.6%)\n",
      "2025-09-05 16:51:38,303 - INFO - 배치 처리 중: ID 1801 ~ 1900\n",
      "2025-09-05 16:51:38,792 - INFO - 진행률: 1710/6900 (24.8%)\n",
      "2025-09-05 16:51:38,993 - INFO - 진행률: 1720/6900 (24.9%)\n",
      "2025-09-05 16:51:39,429 - INFO - 진행률: 1730/6900 (25.1%)\n",
      "2025-09-05 16:51:39,649 - INFO - 진행률: 1740/6900 (25.2%)\n",
      "2025-09-05 16:51:39,767 - INFO - 진행률: 1750/6900 (25.4%)\n",
      "2025-09-05 16:51:39,954 - INFO - 진행률: 1760/6900 (25.5%)\n",
      "2025-09-05 16:51:40,178 - INFO - 진행률: 1770/6900 (25.7%)\n",
      "2025-09-05 16:51:40,429 - INFO - 진행률: 1780/6900 (25.8%)\n",
      "2025-09-05 16:51:40,620 - INFO - 진행률: 1790/6900 (25.9%)\n",
      "2025-09-05 16:51:40,771 - INFO - 진행률: 1800/6900 (26.1%)\n",
      "2025-09-05 16:51:42,774 - INFO - 배치 처리 중: ID 1901 ~ 2000\n",
      "2025-09-05 16:51:43,610 - INFO - 진행률: 1810/6900 (26.2%)\n",
      "2025-09-05 16:51:43,737 - INFO - 진행률: 1820/6900 (26.4%)\n",
      "2025-09-05 16:51:43,916 - INFO - 진행률: 1830/6900 (26.5%)\n",
      "2025-09-05 16:51:44,203 - INFO - 진행률: 1840/6900 (26.7%)\n",
      "2025-09-05 16:51:44,419 - INFO - 진행률: 1850/6900 (26.8%)\n",
      "2025-09-05 16:51:44,610 - INFO - 진행률: 1860/6900 (27.0%)\n",
      "2025-09-05 16:51:44,760 - INFO - 진행률: 1870/6900 (27.1%)\n",
      "2025-09-05 16:51:45,090 - INFO - 진행률: 1880/6900 (27.2%)\n",
      "2025-09-05 16:51:45,327 - INFO - 진행률: 1890/6900 (27.4%)\n",
      "2025-09-05 16:51:45,399 - INFO - 진행률: 1900/6900 (27.5%)\n",
      "2025-09-05 16:51:47,402 - INFO - 배치 처리 중: ID 2001 ~ 2100\n",
      "2025-09-05 16:51:47,990 - INFO - 진행률: 1910/6900 (27.7%)\n",
      "2025-09-05 16:51:48,149 - INFO - 진행률: 1920/6900 (27.8%)\n",
      "2025-09-05 16:51:48,292 - INFO - 진행률: 1930/6900 (28.0%)\n",
      "2025-09-05 16:51:48,531 - INFO - 진행률: 1940/6900 (28.1%)\n",
      "2025-09-05 16:51:48,768 - INFO - 진행률: 1950/6900 (28.3%)\n",
      "2025-09-05 16:51:49,132 - INFO - 진행률: 1960/6900 (28.4%)\n",
      "2025-09-05 16:51:49,275 - INFO - 진행률: 1970/6900 (28.6%)\n",
      "2025-09-05 16:51:49,469 - INFO - 진행률: 1980/6900 (28.7%)\n",
      "2025-09-05 16:51:49,646 - INFO - 진행률: 1990/6900 (28.8%)\n",
      "2025-09-05 16:51:49,781 - INFO - 진행률: 2000/6900 (29.0%)\n",
      "2025-09-05 16:51:51,784 - INFO - 배치 처리 중: ID 2101 ~ 2200\n",
      "2025-09-05 16:51:52,380 - INFO - 진행률: 2010/6900 (29.1%)\n",
      "2025-09-05 16:51:52,501 - INFO - 진행률: 2020/6900 (29.3%)\n",
      "2025-09-05 16:51:52,637 - INFO - 진행률: 2030/6900 (29.4%)\n",
      "2025-09-05 16:51:53,191 - INFO - 진행률: 2040/6900 (29.6%)\n",
      "2025-09-05 16:51:53,353 - INFO - 진행률: 2050/6900 (29.7%)\n",
      "2025-09-05 16:51:53,458 - INFO - 진행률: 2060/6900 (29.9%)\n",
      "2025-09-05 16:51:53,645 - INFO - 진행률: 2070/6900 (30.0%)\n",
      "2025-09-05 16:51:53,996 - INFO - 진행률: 2080/6900 (30.1%)\n",
      "2025-09-05 16:51:54,128 - INFO - 진행률: 2090/6900 (30.3%)\n",
      "2025-09-05 16:51:54,205 - INFO - 진행률: 2100/6900 (30.4%)\n",
      "2025-09-05 16:51:56,208 - INFO - 배치 처리 중: ID 2201 ~ 2300\n",
      "2025-09-05 16:51:56,791 - INFO - 진행률: 2110/6900 (30.6%)\n",
      "2025-09-05 16:51:57,207 - INFO - 진행률: 2120/6900 (30.7%)\n",
      "2025-09-05 16:51:57,348 - INFO - 진행률: 2130/6900 (30.9%)\n",
      "2025-09-05 16:51:57,521 - INFO - 진행률: 2140/6900 (31.0%)\n",
      "2025-09-05 16:51:57,698 - INFO - 진행률: 2150/6900 (31.2%)\n",
      "2025-09-05 16:51:57,920 - INFO - 진행률: 2160/6900 (31.3%)\n",
      "2025-09-05 16:51:58,149 - INFO - 진행률: 2170/6900 (31.4%)\n",
      "2025-09-05 16:51:58,328 - INFO - 진행률: 2180/6900 (31.6%)\n",
      "2025-09-05 16:51:58,478 - INFO - 진행률: 2190/6900 (31.7%)\n",
      "2025-09-05 16:51:58,582 - INFO - 진행률: 2200/6900 (31.9%)\n",
      "2025-09-05 16:52:00,586 - INFO - 배치 처리 중: ID 2301 ~ 2400\n",
      "2025-09-05 16:52:01,409 - INFO - 진행률: 2210/6900 (32.0%)\n",
      "2025-09-05 16:52:01,554 - INFO - 진행률: 2220/6900 (32.2%)\n",
      "2025-09-05 16:52:01,669 - INFO - 진행률: 2230/6900 (32.3%)\n",
      "2025-09-05 16:52:01,838 - INFO - 진행률: 2240/6900 (32.5%)\n",
      "2025-09-05 16:52:02,058 - INFO - 진행률: 2250/6900 (32.6%)\n",
      "2025-09-05 16:52:02,240 - INFO - 진행률: 2260/6900 (32.8%)\n",
      "2025-09-05 16:52:02,431 - INFO - 진행률: 2270/6900 (32.9%)\n",
      "2025-09-05 16:52:02,587 - INFO - 진행률: 2280/6900 (33.0%)\n",
      "2025-09-05 16:52:02,879 - INFO - 진행률: 2290/6900 (33.2%)\n",
      "2025-09-05 16:52:03,020 - INFO - 진행률: 2300/6900 (33.3%)\n",
      "2025-09-05 16:52:05,024 - INFO - 배치 처리 중: ID 2401 ~ 2500\n",
      "2025-09-05 16:52:05,553 - INFO - 진행률: 2310/6900 (33.5%)\n",
      "2025-09-05 16:52:05,735 - INFO - 진행률: 2320/6900 (33.6%)\n",
      "2025-09-05 16:52:05,875 - INFO - 진행률: 2330/6900 (33.8%)\n",
      "2025-09-05 16:52:06,080 - INFO - 진행률: 2340/6900 (33.9%)\n",
      "2025-09-05 16:52:06,251 - INFO - 진행률: 2350/6900 (34.1%)\n",
      "2025-09-05 16:52:06,455 - INFO - 진행률: 2360/6900 (34.2%)\n",
      "2025-09-05 16:52:06,604 - INFO - 진행률: 2370/6900 (34.3%)\n",
      "2025-09-05 16:52:06,989 - INFO - 진행률: 2380/6900 (34.5%)\n",
      "2025-09-05 16:52:07,203 - INFO - 진행률: 2390/6900 (34.6%)\n",
      "2025-09-05 16:52:07,281 - INFO - 진행률: 2400/6900 (34.8%)\n",
      "2025-09-05 16:52:09,285 - INFO - 배치 처리 중: ID 2501 ~ 2600\n",
      "2025-09-05 16:52:09,868 - INFO - 진행률: 2410/6900 (34.9%)\n",
      "2025-09-05 16:52:09,948 - INFO - 진행률: 2420/6900 (35.1%)\n",
      "2025-09-05 16:52:10,105 - INFO - 진행률: 2430/6900 (35.2%)\n",
      "2025-09-05 16:52:10,216 - INFO - 진행률: 2440/6900 (35.4%)\n",
      "2025-09-05 16:52:10,435 - INFO - 진행률: 2450/6900 (35.5%)\n",
      "2025-09-05 16:52:10,641 - INFO - 진행률: 2460/6900 (35.7%)\n",
      "2025-09-05 16:52:10,970 - INFO - 진행률: 2470/6900 (35.8%)\n",
      "2025-09-05 16:52:11,097 - INFO - 진행률: 2480/6900 (35.9%)\n",
      "2025-09-05 16:52:11,193 - INFO - 진행률: 2490/6900 (36.1%)\n",
      "2025-09-05 16:52:11,328 - INFO - 진행률: 2500/6900 (36.2%)\n",
      "2025-09-05 16:52:13,330 - INFO - 배치 처리 중: ID 2601 ~ 2700\n",
      "2025-09-05 16:52:13,807 - INFO - 진행률: 2510/6900 (36.4%)\n",
      "2025-09-05 16:52:13,963 - INFO - 진행률: 2520/6900 (36.5%)\n",
      "2025-09-05 16:52:14,093 - INFO - 진행률: 2530/6900 (36.7%)\n",
      "2025-09-05 16:52:14,238 - INFO - 진행률: 2540/6900 (36.8%)\n",
      "2025-09-05 16:52:14,397 - INFO - 진행률: 2550/6900 (37.0%)\n",
      "2025-09-05 16:52:14,562 - INFO - 진행률: 2560/6900 (37.1%)\n",
      "2025-09-05 16:52:14,721 - INFO - 진행률: 2570/6900 (37.2%)\n",
      "2025-09-05 16:52:15,077 - INFO - 진행률: 2580/6900 (37.4%)\n",
      "2025-09-05 16:52:15,182 - INFO - 진행률: 2590/6900 (37.5%)\n",
      "2025-09-05 16:52:15,276 - INFO - 진행률: 2600/6900 (37.7%)\n",
      "2025-09-05 16:52:17,282 - INFO - 배치 처리 중: ID 2701 ~ 2800\n",
      "2025-09-05 16:52:17,801 - INFO - 진행률: 2610/6900 (37.8%)\n",
      "2025-09-05 16:52:17,909 - INFO - 진행률: 2620/6900 (38.0%)\n",
      "2025-09-05 16:52:18,077 - INFO - 진행률: 2630/6900 (38.1%)\n",
      "2025-09-05 16:52:18,229 - INFO - 진행률: 2640/6900 (38.3%)\n",
      "2025-09-05 16:52:18,422 - INFO - 진행률: 2650/6900 (38.4%)\n",
      "2025-09-05 16:52:18,573 - INFO - 진행률: 2660/6900 (38.6%)\n",
      "2025-09-05 16:52:18,698 - INFO - 진행률: 2670/6900 (38.7%)\n",
      "2025-09-05 16:52:19,119 - INFO - 진행률: 2680/6900 (38.8%)\n",
      "2025-09-05 16:52:19,185 - INFO - 진행률: 2690/6900 (39.0%)\n",
      "2025-09-05 16:52:19,277 - INFO - 진행률: 2700/6900 (39.1%)\n",
      "2025-09-05 16:52:21,282 - INFO - 배치 처리 중: ID 2801 ~ 2900\n",
      "2025-09-05 16:52:21,677 - INFO - 진행률: 2710/6900 (39.3%)\n",
      "2025-09-05 16:52:21,823 - INFO - 진행률: 2720/6900 (39.4%)\n",
      "2025-09-05 16:52:21,943 - INFO - 진행률: 2730/6900 (39.6%)\n",
      "2025-09-05 16:52:22,071 - INFO - 진행률: 2740/6900 (39.7%)\n",
      "2025-09-05 16:52:22,182 - INFO - 진행률: 2750/6900 (39.9%)\n",
      "2025-09-05 16:52:22,366 - INFO - 진행률: 2760/6900 (40.0%)\n",
      "2025-09-05 16:52:22,530 - INFO - 진행률: 2770/6900 (40.1%)\n",
      "2025-09-05 16:52:22,675 - INFO - 진행률: 2780/6900 (40.3%)\n",
      "2025-09-05 16:52:22,789 - INFO - 진행률: 2790/6900 (40.4%)\n",
      "2025-09-05 16:52:22,911 - INFO - 진행률: 2800/6900 (40.6%)\n",
      "2025-09-05 16:52:24,916 - INFO - 배치 처리 중: ID 2901 ~ 3000\n",
      "2025-09-05 16:52:25,570 - INFO - 진행률: 2810/6900 (40.7%)\n",
      "2025-09-05 16:52:25,766 - INFO - 진행률: 2820/6900 (40.9%)\n",
      "2025-09-05 16:52:25,883 - INFO - 진행률: 2830/6900 (41.0%)\n",
      "2025-09-05 16:52:26,012 - INFO - 진행률: 2840/6900 (41.2%)\n",
      "2025-09-05 16:52:26,259 - INFO - 진행률: 2850/6900 (41.3%)\n",
      "2025-09-05 16:52:26,429 - INFO - 진행률: 2860/6900 (41.4%)\n",
      "2025-09-05 16:52:26,548 - INFO - 진행률: 2870/6900 (41.6%)\n",
      "2025-09-05 16:52:26,733 - INFO - 진행률: 2880/6900 (41.7%)\n",
      "2025-09-05 16:52:26,890 - INFO - 진행률: 2890/6900 (41.9%)\n",
      "2025-09-05 16:52:27,014 - INFO - 진행률: 2900/6900 (42.0%)\n",
      "2025-09-05 16:52:29,019 - INFO - 배치 처리 중: ID 3001 ~ 3100\n",
      "2025-09-05 16:52:29,758 - INFO - 진행률: 2910/6900 (42.2%)\n",
      "2025-09-05 16:52:29,938 - INFO - 진행률: 2920/6900 (42.3%)\n",
      "2025-09-05 16:52:30,050 - INFO - 진행률: 2930/6900 (42.5%)\n",
      "2025-09-05 16:52:30,231 - INFO - 진행률: 2940/6900 (42.6%)\n",
      "2025-09-05 16:52:30,335 - INFO - 진행률: 2950/6900 (42.8%)\n",
      "2025-09-05 16:52:30,472 - INFO - 진행률: 2960/6900 (42.9%)\n",
      "2025-09-05 16:52:30,663 - INFO - 진행률: 2970/6900 (43.0%)\n",
      "2025-09-05 16:52:30,820 - INFO - 진행률: 2980/6900 (43.2%)\n",
      "2025-09-05 16:52:30,908 - INFO - 진행률: 2990/6900 (43.3%)\n",
      "2025-09-05 16:52:31,035 - INFO - 진행률: 3000/6900 (43.5%)\n",
      "2025-09-05 16:52:33,055 - INFO - 배치 처리 중: ID 3101 ~ 3200\n",
      "2025-09-05 16:52:33,741 - INFO - 진행률: 3010/6900 (43.6%)\n",
      "2025-09-05 16:52:33,873 - INFO - 진행률: 3020/6900 (43.8%)\n",
      "2025-09-05 16:52:34,036 - INFO - 진행률: 3030/6900 (43.9%)\n",
      "2025-09-05 16:52:34,185 - INFO - 진행률: 3040/6900 (44.1%)\n",
      "2025-09-05 16:52:34,368 - INFO - 진행률: 3050/6900 (44.2%)\n",
      "2025-09-05 16:52:34,486 - INFO - 진행률: 3060/6900 (44.3%)\n",
      "2025-09-05 16:52:34,648 - INFO - 진행률: 3070/6900 (44.5%)\n",
      "2025-09-05 16:52:34,771 - INFO - 진행률: 3080/6900 (44.6%)\n",
      "2025-09-05 16:52:34,940 - INFO - 진행률: 3090/6900 (44.8%)\n",
      "2025-09-05 16:52:35,045 - INFO - 진행률: 3100/6900 (44.9%)\n",
      "2025-09-05 16:52:37,047 - INFO - 배치 처리 중: ID 3201 ~ 3300\n",
      "2025-09-05 16:52:37,414 - INFO - 진행률: 3110/6900 (45.1%)\n",
      "2025-09-05 16:52:37,752 - INFO - 진행률: 3120/6900 (45.2%)\n",
      "2025-09-05 16:52:37,905 - INFO - 진행률: 3130/6900 (45.4%)\n",
      "2025-09-05 16:52:37,971 - INFO - 진행률: 3140/6900 (45.5%)\n",
      "2025-09-05 16:52:38,063 - INFO - 진행률: 3150/6900 (45.7%)\n",
      "2025-09-05 16:52:38,217 - INFO - 진행률: 3160/6900 (45.8%)\n",
      "2025-09-05 16:52:38,446 - INFO - 진행률: 3170/6900 (45.9%)\n",
      "2025-09-05 16:52:38,764 - INFO - 진행률: 3180/6900 (46.1%)\n",
      "2025-09-05 16:52:38,893 - INFO - 진행률: 3190/6900 (46.2%)\n",
      "2025-09-05 16:52:39,004 - INFO - 진행률: 3200/6900 (46.4%)\n",
      "2025-09-05 16:52:41,008 - INFO - 배치 처리 중: ID 3301 ~ 3400\n",
      "2025-09-05 16:52:41,860 - INFO - 진행률: 3210/6900 (46.5%)\n",
      "2025-09-05 16:52:42,006 - INFO - 진행률: 3220/6900 (46.7%)\n",
      "2025-09-05 16:52:42,146 - INFO - 진행률: 3230/6900 (46.8%)\n",
      "2025-09-05 16:52:42,352 - INFO - 진행률: 3240/6900 (47.0%)\n",
      "2025-09-05 16:52:42,595 - INFO - 진행률: 3250/6900 (47.1%)\n",
      "2025-09-05 16:52:42,782 - INFO - 진행률: 3260/6900 (47.2%)\n",
      "2025-09-05 16:52:42,987 - INFO - 진행률: 3270/6900 (47.4%)\n",
      "2025-09-05 16:52:43,180 - INFO - 진행률: 3280/6900 (47.5%)\n",
      "2025-09-05 16:52:43,350 - INFO - 진행률: 3290/6900 (47.7%)\n",
      "2025-09-05 16:52:43,682 - INFO - 진행률: 3300/6900 (47.8%)\n",
      "2025-09-05 16:52:45,686 - INFO - 배치 처리 중: ID 3401 ~ 3500\n",
      "2025-09-05 16:52:46,233 - INFO - 진행률: 3310/6900 (48.0%)\n",
      "2025-09-05 16:52:46,488 - INFO - 진행률: 3320/6900 (48.1%)\n",
      "2025-09-05 16:52:46,650 - INFO - 진행률: 3330/6900 (48.3%)\n",
      "2025-09-05 16:52:46,806 - INFO - 진행률: 3340/6900 (48.4%)\n",
      "2025-09-05 16:52:47,064 - INFO - 진행률: 3350/6900 (48.6%)\n",
      "2025-09-05 16:52:47,298 - INFO - 진행률: 3360/6900 (48.7%)\n",
      "2025-09-05 16:52:47,778 - INFO - 진행률: 3370/6900 (48.8%)\n",
      "2025-09-05 16:52:47,930 - INFO - 진행률: 3380/6900 (49.0%)\n",
      "2025-09-05 16:52:48,101 - INFO - 진행률: 3390/6900 (49.1%)\n",
      "2025-09-05 16:52:48,216 - INFO - 진행률: 3400/6900 (49.3%)\n",
      "2025-09-05 16:52:50,222 - INFO - 배치 처리 중: ID 3501 ~ 3600\n",
      "2025-09-05 16:52:50,737 - INFO - 진행률: 3410/6900 (49.4%)\n",
      "2025-09-05 16:52:50,847 - INFO - 진행률: 3420/6900 (49.6%)\n",
      "2025-09-05 16:52:50,947 - INFO - 진행률: 3430/6900 (49.7%)\n",
      "2025-09-05 16:52:51,040 - INFO - 진행률: 3440/6900 (49.9%)\n",
      "2025-09-05 16:52:51,115 - INFO - 진행률: 3450/6900 (50.0%)\n",
      "2025-09-05 16:52:51,196 - INFO - 진행률: 3460/6900 (50.1%)\n",
      "2025-09-05 16:52:51,259 - INFO - 진행률: 3470/6900 (50.3%)\n",
      "2025-09-05 16:52:51,333 - INFO - 진행률: 3480/6900 (50.4%)\n",
      "2025-09-05 16:52:51,400 - INFO - 진행률: 3490/6900 (50.6%)\n",
      "2025-09-05 16:52:51,551 - INFO - 진행률: 3500/6900 (50.7%)\n",
      "2025-09-05 16:52:53,555 - INFO - 배치 처리 중: ID 3601 ~ 3700\n",
      "2025-09-05 16:52:54,307 - INFO - 진행률: 3510/6900 (50.9%)\n",
      "2025-09-05 16:52:54,418 - INFO - 진행률: 3520/6900 (51.0%)\n",
      "2025-09-05 16:52:54,512 - INFO - 진행률: 3530/6900 (51.2%)\n",
      "2025-09-05 16:52:54,688 - INFO - 진행률: 3540/6900 (51.3%)\n",
      "2025-09-05 16:52:54,931 - INFO - 진행률: 3550/6900 (51.4%)\n",
      "2025-09-05 16:52:55,102 - INFO - 진행률: 3560/6900 (51.6%)\n",
      "2025-09-05 16:52:55,258 - INFO - 진행률: 3570/6900 (51.7%)\n",
      "2025-09-05 16:52:55,434 - INFO - 진행률: 3580/6900 (51.9%)\n",
      "2025-09-05 16:52:55,553 - INFO - 진행률: 3590/6900 (52.0%)\n",
      "2025-09-05 16:52:55,668 - INFO - 진행률: 3600/6900 (52.2%)\n",
      "2025-09-05 16:52:57,672 - INFO - 배치 처리 중: ID 3701 ~ 3800\n",
      "2025-09-05 16:52:58,179 - INFO - 진행률: 3610/6900 (52.3%)\n",
      "2025-09-05 16:52:58,630 - INFO - 진행률: 3620/6900 (52.5%)\n",
      "2025-09-05 16:52:58,806 - INFO - 진행률: 3630/6900 (52.6%)\n",
      "2025-09-05 16:52:58,979 - INFO - 진행률: 3640/6900 (52.8%)\n",
      "2025-09-05 16:52:59,062 - INFO - 진행률: 3650/6900 (52.9%)\n",
      "2025-09-05 16:52:59,171 - INFO - 진행률: 3660/6900 (53.0%)\n",
      "2025-09-05 16:52:59,218 - INFO - 진행률: 3670/6900 (53.2%)\n",
      "2025-09-05 16:52:59,304 - INFO - 진행률: 3680/6900 (53.3%)\n",
      "2025-09-05 16:52:59,396 - INFO - 진행률: 3690/6900 (53.5%)\n",
      "2025-09-05 16:52:59,516 - INFO - 진행률: 3700/6900 (53.6%)\n",
      "2025-09-05 16:53:01,519 - INFO - 배치 처리 중: ID 3801 ~ 3900\n",
      "2025-09-05 16:53:01,722 - INFO - 진행률: 3710/6900 (53.8%)\n",
      "2025-09-05 16:53:01,826 - INFO - 진행률: 3720/6900 (53.9%)\n",
      "2025-09-05 16:53:01,865 - INFO - 진행률: 3730/6900 (54.1%)\n",
      "2025-09-05 16:53:01,899 - INFO - 진행률: 3740/6900 (54.2%)\n",
      "2025-09-05 16:53:02,027 - INFO - 진행률: 3750/6900 (54.3%)\n",
      "2025-09-05 16:53:02,110 - INFO - 진행률: 3760/6900 (54.5%)\n",
      "2025-09-05 16:53:02,205 - INFO - 진행률: 3770/6900 (54.6%)\n",
      "2025-09-05 16:53:02,237 - INFO - 진행률: 3780/6900 (54.8%)\n",
      "2025-09-05 16:53:02,311 - INFO - 진행률: 3790/6900 (54.9%)\n",
      "2025-09-05 16:53:02,366 - INFO - 진행률: 3800/6900 (55.1%)\n",
      "2025-09-05 16:53:04,368 - INFO - 배치 처리 중: ID 3901 ~ 4000\n",
      "2025-09-05 16:53:04,570 - INFO - 진행률: 3810/6900 (55.2%)\n",
      "2025-09-05 16:53:04,701 - INFO - 진행률: 3820/6900 (55.4%)\n",
      "2025-09-05 16:53:04,725 - INFO - 진행률: 3830/6900 (55.5%)\n",
      "2025-09-05 16:53:04,853 - INFO - 진행률: 3840/6900 (55.7%)\n",
      "2025-09-05 16:53:04,880 - INFO - 진행률: 3850/6900 (55.8%)\n",
      "2025-09-05 16:53:04,913 - INFO - 진행률: 3860/6900 (55.9%)\n",
      "2025-09-05 16:53:05,048 - INFO - 진행률: 3870/6900 (56.1%)\n",
      "2025-09-05 16:53:05,070 - INFO - 진행률: 3880/6900 (56.2%)\n",
      "2025-09-05 16:53:05,189 - INFO - 진행률: 3890/6900 (56.4%)\n",
      "2025-09-05 16:53:05,336 - INFO - 진행률: 3900/6900 (56.5%)\n",
      "2025-09-05 16:53:07,339 - INFO - 배치 처리 중: ID 4001 ~ 4100\n",
      "2025-09-05 16:53:07,542 - INFO - 진행률: 3910/6900 (56.7%)\n",
      "2025-09-05 16:53:07,646 - INFO - 진행률: 3920/6900 (56.8%)\n",
      "2025-09-05 16:53:07,674 - INFO - 진행률: 3930/6900 (57.0%)\n",
      "2025-09-05 16:53:07,797 - INFO - 진행률: 3940/6900 (57.1%)\n",
      "2025-09-05 16:53:07,841 - INFO - 진행률: 3950/6900 (57.2%)\n",
      "2025-09-05 16:53:07,864 - INFO - 진행률: 3960/6900 (57.4%)\n",
      "2025-09-05 16:53:07,989 - INFO - 진행률: 3970/6900 (57.5%)\n",
      "2025-09-05 16:53:08,033 - INFO - 진행률: 3980/6900 (57.7%)\n",
      "2025-09-05 16:53:08,144 - INFO - 진행률: 3990/6900 (57.8%)\n",
      "2025-09-05 16:53:08,294 - INFO - 진행률: 4000/6900 (58.0%)\n",
      "2025-09-05 16:53:10,296 - INFO - 배치 처리 중: ID 4101 ~ 4200\n",
      "2025-09-05 16:53:10,497 - INFO - 진행률: 4010/6900 (58.1%)\n",
      "2025-09-05 16:53:10,603 - INFO - 진행률: 4020/6900 (58.3%)\n",
      "2025-09-05 16:53:10,630 - INFO - 진행률: 4030/6900 (58.4%)\n",
      "2025-09-05 16:53:10,767 - INFO - 진행률: 4040/6900 (58.6%)\n",
      "2025-09-05 16:53:10,797 - INFO - 진행률: 4050/6900 (58.7%)\n",
      "2025-09-05 16:53:10,831 - INFO - 진행률: 4060/6900 (58.8%)\n",
      "2025-09-05 16:53:10,942 - INFO - 진행률: 4070/6900 (59.0%)\n",
      "2025-09-05 16:53:10,968 - INFO - 진행률: 4080/6900 (59.1%)\n",
      "2025-09-05 16:53:11,093 - INFO - 진행률: 4090/6900 (59.3%)\n",
      "2025-09-05 16:53:11,240 - INFO - 진행률: 4100/6900 (59.4%)\n",
      "2025-09-05 16:53:13,244 - INFO - 배치 처리 중: ID 4201 ~ 4300\n",
      "2025-09-05 16:53:13,445 - INFO - 진행률: 4110/6900 (59.6%)\n",
      "2025-09-05 16:53:13,546 - INFO - 진행률: 4120/6900 (59.7%)\n",
      "2025-09-05 16:53:13,585 - INFO - 진행률: 4130/6900 (59.9%)\n",
      "2025-09-05 16:53:13,637 - INFO - 진행률: 4140/6900 (60.0%)\n",
      "2025-09-05 16:53:13,743 - INFO - 진행률: 4150/6900 (60.1%)\n",
      "2025-09-05 16:53:13,771 - INFO - 진행률: 4160/6900 (60.3%)\n",
      "2025-09-05 16:53:13,876 - INFO - 진행률: 4170/6900 (60.4%)\n",
      "2025-09-05 16:53:13,924 - INFO - 진행률: 4180/6900 (60.6%)\n",
      "2025-09-05 16:53:14,033 - INFO - 진행률: 4190/6900 (60.7%)\n",
      "2025-09-05 16:53:14,177 - INFO - 진행률: 4200/6900 (60.9%)\n",
      "2025-09-05 16:53:16,180 - INFO - 배치 처리 중: ID 4301 ~ 4400\n",
      "2025-09-05 16:53:16,380 - INFO - 진행률: 4210/6900 (61.0%)\n",
      "2025-09-05 16:53:16,507 - INFO - 진행률: 4220/6900 (61.2%)\n",
      "2025-09-05 16:53:16,523 - INFO - 진행률: 4230/6900 (61.3%)\n",
      "2025-09-05 16:53:16,665 - INFO - 진행률: 4240/6900 (61.4%)\n",
      "2025-09-05 16:53:16,688 - INFO - 진행률: 4250/6900 (61.6%)\n",
      "2025-09-05 16:53:16,803 - INFO - 진행률: 4260/6900 (61.7%)\n",
      "2025-09-05 16:53:16,852 - INFO - 진행률: 4270/6900 (61.9%)\n",
      "2025-09-05 16:53:16,962 - INFO - 진행률: 4280/6900 (62.0%)\n",
      "2025-09-05 16:53:16,996 - INFO - 진행률: 4290/6900 (62.2%)\n",
      "2025-09-05 16:53:17,184 - INFO - 진행률: 4300/6900 (62.3%)\n",
      "2025-09-05 16:53:19,187 - INFO - 배치 처리 중: ID 4401 ~ 4500\n",
      "2025-09-05 16:53:19,395 - INFO - 진행률: 4310/6900 (62.5%)\n",
      "2025-09-05 16:53:19,424 - INFO - 진행률: 4320/6900 (62.6%)\n",
      "2025-09-05 16:53:19,524 - INFO - 진행률: 4330/6900 (62.8%)\n",
      "2025-09-05 16:53:19,578 - INFO - 진행률: 4340/6900 (62.9%)\n",
      "2025-09-05 16:53:19,678 - INFO - 진행률: 4350/6900 (63.0%)\n",
      "2025-09-05 16:53:19,720 - INFO - 진행률: 4360/6900 (63.2%)\n",
      "2025-09-05 16:53:19,827 - INFO - 진행률: 4370/6900 (63.3%)\n",
      "2025-09-05 16:53:19,876 - INFO - 진행률: 4380/6900 (63.5%)\n",
      "2025-09-05 16:53:19,987 - INFO - 진행률: 4390/6900 (63.6%)\n",
      "2025-09-05 16:53:20,130 - INFO - 진행률: 4400/6900 (63.8%)\n",
      "2025-09-05 16:53:22,154 - INFO - 배치 처리 중: ID 4501 ~ 4600\n",
      "2025-09-05 16:53:22,358 - INFO - 진행률: 4410/6900 (63.9%)\n",
      "2025-09-05 16:53:22,378 - INFO - 진행률: 4420/6900 (64.1%)\n",
      "2025-09-05 16:53:22,494 - INFO - 진행률: 4430/6900 (64.2%)\n",
      "2025-09-05 16:53:22,563 - INFO - 진행률: 4440/6900 (64.3%)\n",
      "2025-09-05 16:53:22,659 - INFO - 진행률: 4450/6900 (64.5%)\n",
      "2025-09-05 16:53:22,689 - INFO - 진행률: 4460/6900 (64.6%)\n",
      "2025-09-05 16:53:22,765 - INFO - 진행률: 4470/6900 (64.8%)\n",
      "2025-09-05 16:53:22,840 - INFO - 진행률: 4480/6900 (64.9%)\n",
      "2025-09-05 16:53:22,872 - INFO - 진행률: 4490/6900 (65.1%)\n",
      "2025-09-05 16:53:23,066 - INFO - 진행률: 4500/6900 (65.2%)\n",
      "2025-09-05 16:53:25,070 - INFO - 배치 처리 중: ID 4601 ~ 4700\n",
      "2025-09-05 16:53:25,266 - INFO - 진행률: 4510/6900 (65.4%)\n",
      "2025-09-05 16:53:25,288 - INFO - 진행률: 4520/6900 (65.5%)\n",
      "2025-09-05 16:53:25,406 - INFO - 진행률: 4530/6900 (65.7%)\n",
      "2025-09-05 16:53:25,544 - INFO - 진행률: 4540/6900 (65.8%)\n",
      "2025-09-05 16:53:25,574 - INFO - 진행률: 4550/6900 (65.9%)\n",
      "2025-09-05 16:53:25,592 - INFO - 진행률: 4560/6900 (66.1%)\n",
      "2025-09-05 16:53:25,733 - INFO - 진행률: 4570/6900 (66.2%)\n",
      "2025-09-05 16:53:25,852 - INFO - 진행률: 4580/6900 (66.4%)\n",
      "2025-09-05 16:53:25,889 - INFO - 진행률: 4590/6900 (66.5%)\n",
      "2025-09-05 16:53:26,041 - INFO - 진행률: 4600/6900 (66.7%)\n",
      "2025-09-05 16:53:28,043 - INFO - 배치 처리 중: ID 4701 ~ 4800\n",
      "2025-09-05 16:53:28,240 - INFO - 진행률: 4610/6900 (66.8%)\n",
      "2025-09-05 16:53:28,340 - INFO - 진행률: 4620/6900 (67.0%)\n",
      "2025-09-05 16:53:28,380 - INFO - 진행률: 4630/6900 (67.1%)\n",
      "2025-09-05 16:53:28,436 - INFO - 진행률: 4640/6900 (67.2%)\n",
      "2025-09-05 16:53:28,529 - INFO - 진행률: 4650/6900 (67.4%)\n",
      "2025-09-05 16:53:28,564 - INFO - 진행률: 4660/6900 (67.5%)\n",
      "2025-09-05 16:53:28,653 - INFO - 진행률: 4670/6900 (67.7%)\n",
      "2025-09-05 16:53:28,704 - INFO - 진행률: 4680/6900 (67.8%)\n",
      "2025-09-05 16:53:28,819 - INFO - 진행률: 4690/6900 (68.0%)\n",
      "2025-09-05 16:53:28,949 - INFO - 진행률: 4700/6900 (68.1%)\n",
      "2025-09-05 16:53:30,954 - INFO - 배치 처리 중: ID 4801 ~ 4900\n",
      "2025-09-05 16:53:31,146 - INFO - 진행률: 4710/6900 (68.3%)\n",
      "2025-09-05 16:53:31,288 - INFO - 진행률: 4720/6900 (68.4%)\n",
      "2025-09-05 16:53:31,307 - INFO - 진행률: 4730/6900 (68.6%)\n",
      "2025-09-05 16:53:31,439 - INFO - 진행률: 4740/6900 (68.7%)\n",
      "2025-09-05 16:53:31,467 - INFO - 진행률: 4750/6900 (68.8%)\n",
      "2025-09-05 16:53:31,597 - INFO - 진행률: 4760/6900 (69.0%)\n",
      "2025-09-05 16:53:31,633 - INFO - 진행률: 4770/6900 (69.1%)\n",
      "2025-09-05 16:53:31,733 - INFO - 진행률: 4780/6900 (69.3%)\n",
      "2025-09-05 16:53:31,794 - INFO - 진행률: 4790/6900 (69.4%)\n",
      "2025-09-05 16:53:32,307 - INFO - 진행률: 4800/6900 (69.6%)\n",
      "2025-09-05 16:53:34,311 - INFO - 배치 처리 중: ID 4901 ~ 5000\n",
      "2025-09-05 16:53:34,512 - INFO - 진행률: 4810/6900 (69.7%)\n",
      "2025-09-05 16:53:34,530 - INFO - 진행률: 4820/6900 (69.9%)\n",
      "2025-09-05 16:53:34,635 - INFO - 진행률: 4830/6900 (70.0%)\n",
      "2025-09-05 16:53:34,688 - INFO - 진행률: 4840/6900 (70.1%)\n",
      "2025-09-05 16:53:34,783 - INFO - 진행률: 4850/6900 (70.3%)\n",
      "2025-09-05 16:53:34,835 - INFO - 진행률: 4860/6900 (70.4%)\n",
      "2025-09-05 16:53:34,913 - INFO - 진행률: 4870/6900 (70.6%)\n",
      "2025-09-05 16:53:34,961 - INFO - 진행률: 4880/6900 (70.7%)\n",
      "2025-09-05 16:53:35,010 - INFO - 진행률: 4890/6900 (70.9%)\n",
      "2025-09-05 16:53:35,166 - INFO - 진행률: 4900/6900 (71.0%)\n",
      "2025-09-05 16:53:37,169 - INFO - 배치 처리 중: ID 5001 ~ 5100\n",
      "2025-09-05 16:53:37,367 - INFO - 진행률: 4910/6900 (71.2%)\n",
      "2025-09-05 16:53:37,487 - INFO - 진행률: 4920/6900 (71.3%)\n",
      "2025-09-05 16:53:37,512 - INFO - 진행률: 4930/6900 (71.4%)\n",
      "2025-09-05 16:53:37,646 - INFO - 진행률: 4940/6900 (71.6%)\n",
      "2025-09-05 16:53:37,677 - INFO - 진행률: 4950/6900 (71.7%)\n",
      "2025-09-05 16:53:37,798 - INFO - 진행률: 4960/6900 (71.9%)\n",
      "2025-09-05 16:53:37,826 - INFO - 진행률: 4970/6900 (72.0%)\n",
      "2025-09-05 16:53:37,935 - INFO - 진행률: 4980/6900 (72.2%)\n",
      "2025-09-05 16:53:37,978 - INFO - 진행률: 4990/6900 (72.3%)\n",
      "2025-09-05 16:53:38,132 - INFO - 진행률: 5000/6900 (72.5%)\n",
      "2025-09-05 16:53:40,136 - INFO - 배치 처리 중: ID 5101 ~ 5200\n",
      "2025-09-05 16:53:40,338 - INFO - 진행률: 5010/6900 (72.6%)\n",
      "2025-09-05 16:53:40,454 - INFO - 진행률: 5020/6900 (72.8%)\n",
      "2025-09-05 16:53:40,476 - INFO - 진행률: 5030/6900 (72.9%)\n",
      "2025-09-05 16:53:40,511 - INFO - 진행률: 5040/6900 (73.0%)\n",
      "2025-09-05 16:53:40,640 - INFO - 진행률: 5050/6900 (73.2%)\n",
      "2025-09-05 16:53:40,676 - INFO - 진행률: 5060/6900 (73.3%)\n",
      "2025-09-05 16:53:40,771 - INFO - 진행률: 5070/6900 (73.5%)\n",
      "2025-09-05 16:53:40,803 - INFO - 진행률: 5080/6900 (73.6%)\n",
      "2025-09-05 16:53:40,933 - INFO - 진행률: 5090/6900 (73.8%)\n",
      "2025-09-05 16:53:41,039 - INFO - 진행률: 5100/6900 (73.9%)\n",
      "2025-09-05 16:53:43,043 - INFO - 배치 처리 중: ID 5201 ~ 5300\n",
      "2025-09-05 16:53:43,242 - INFO - 진행률: 5110/6900 (74.1%)\n",
      "2025-09-05 16:53:43,259 - INFO - 진행률: 5120/6900 (74.2%)\n",
      "2025-09-05 16:53:43,381 - INFO - 진행률: 5130/6900 (74.3%)\n",
      "2025-09-05 16:53:43,426 - INFO - 진행률: 5140/6900 (74.5%)\n",
      "2025-09-05 16:53:43,540 - INFO - 진행률: 5150/6900 (74.6%)\n",
      "2025-09-05 16:53:43,571 - INFO - 진행률: 5160/6900 (74.8%)\n",
      "2025-09-05 16:53:43,697 - INFO - 진행률: 5170/6900 (74.9%)\n",
      "2025-09-05 16:53:43,721 - INFO - 진행률: 5180/6900 (75.1%)\n",
      "2025-09-05 16:53:43,818 - INFO - 진행률: 5190/6900 (75.2%)\n",
      "2025-09-05 16:53:44,000 - INFO - 진행률: 5200/6900 (75.4%)\n",
      "2025-09-05 16:53:46,002 - INFO - 배치 처리 중: ID 5301 ~ 5400\n",
      "2025-09-05 16:53:46,222 - INFO - 진행률: 5210/6900 (75.5%)\n",
      "2025-09-05 16:53:46,244 - INFO - 진행률: 5220/6900 (75.7%)\n",
      "2025-09-05 16:53:46,322 - INFO - 진행률: 5230/6900 (75.8%)\n",
      "2025-09-05 16:53:46,402 - INFO - 진행률: 5240/6900 (75.9%)\n",
      "2025-09-05 16:53:46,480 - INFO - 진행률: 5250/6900 (76.1%)\n",
      "2025-09-05 16:53:46,537 - INFO - 진행률: 5260/6900 (76.2%)\n",
      "2025-09-05 16:53:46,617 - INFO - 진행률: 5270/6900 (76.4%)\n",
      "2025-09-05 16:53:46,670 - INFO - 진행률: 5280/6900 (76.5%)\n",
      "2025-09-05 16:53:46,746 - INFO - 진행률: 5290/6900 (76.7%)\n",
      "2025-09-05 16:53:46,840 - INFO - 진행률: 5300/6900 (76.8%)\n",
      "2025-09-05 16:53:48,844 - INFO - 배치 처리 중: ID 5401 ~ 5500\n",
      "2025-09-05 16:53:49,048 - INFO - 진행률: 5310/6900 (77.0%)\n",
      "2025-09-05 16:53:49,070 - INFO - 진행률: 5320/6900 (77.1%)\n",
      "2025-09-05 16:53:49,173 - INFO - 진행률: 5330/6900 (77.2%)\n",
      "2025-09-05 16:53:49,228 - INFO - 진행률: 5340/6900 (77.4%)\n",
      "2025-09-05 16:53:49,346 - INFO - 진행률: 5350/6900 (77.5%)\n",
      "2025-09-05 16:53:49,361 - INFO - 진행률: 5360/6900 (77.7%)\n",
      "2025-09-05 16:53:49,463 - INFO - 진행률: 5370/6900 (77.8%)\n",
      "2025-09-05 16:53:49,547 - INFO - 진행률: 5380/6900 (78.0%)\n",
      "2025-09-05 16:53:49,641 - INFO - 진행률: 5390/6900 (78.1%)\n",
      "2025-09-05 16:53:49,757 - INFO - 진행률: 5400/6900 (78.3%)\n",
      "2025-09-05 16:53:51,761 - INFO - 배치 처리 중: ID 5501 ~ 5600\n",
      "2025-09-05 16:53:51,968 - INFO - 진행률: 5410/6900 (78.4%)\n",
      "2025-09-05 16:53:51,983 - INFO - 진행률: 5420/6900 (78.6%)\n",
      "2025-09-05 16:53:52,085 - INFO - 진행률: 5430/6900 (78.7%)\n",
      "2025-09-05 16:53:52,135 - INFO - 진행률: 5440/6900 (78.8%)\n",
      "2025-09-05 16:53:52,246 - INFO - 진행률: 5450/6900 (79.0%)\n",
      "2025-09-05 16:53:52,302 - INFO - 진행률: 5460/6900 (79.1%)\n",
      "2025-09-05 16:53:52,383 - INFO - 진행률: 5470/6900 (79.3%)\n",
      "2025-09-05 16:53:52,449 - INFO - 진행률: 5480/6900 (79.4%)\n",
      "2025-09-05 16:53:52,510 - INFO - 진행률: 5490/6900 (79.6%)\n",
      "2025-09-05 16:53:52,682 - INFO - 진행률: 5500/6900 (79.7%)\n",
      "2025-09-05 16:53:54,686 - INFO - 배치 처리 중: ID 5601 ~ 5700\n",
      "2025-09-05 16:53:54,891 - INFO - 진행률: 5510/6900 (79.9%)\n",
      "2025-09-05 16:53:55,015 - INFO - 진행률: 5520/6900 (80.0%)\n",
      "2025-09-05 16:53:55,032 - INFO - 진행률: 5530/6900 (80.1%)\n",
      "2025-09-05 16:53:55,049 - INFO - 진행률: 5540/6900 (80.3%)\n",
      "2025-09-05 16:53:55,191 - INFO - 진행률: 5550/6900 (80.4%)\n",
      "2025-09-05 16:53:55,250 - INFO - 진행률: 5560/6900 (80.6%)\n",
      "2025-09-05 16:53:55,337 - INFO - 진행률: 5570/6900 (80.7%)\n",
      "2025-09-05 16:53:55,375 - INFO - 진행률: 5580/6900 (80.9%)\n",
      "2025-09-05 16:53:55,495 - INFO - 진행률: 5590/6900 (81.0%)\n",
      "2025-09-05 16:53:55,646 - INFO - 진행률: 5600/6900 (81.2%)\n",
      "2025-09-05 16:53:57,649 - INFO - 배치 처리 중: ID 5701 ~ 5800\n",
      "2025-09-05 16:53:57,852 - INFO - 진행률: 5610/6900 (81.3%)\n",
      "2025-09-05 16:53:57,948 - INFO - 진행률: 5620/6900 (81.4%)\n",
      "2025-09-05 16:53:57,976 - INFO - 진행률: 5630/6900 (81.6%)\n",
      "2025-09-05 16:53:58,011 - INFO - 진행률: 5640/6900 (81.7%)\n",
      "2025-09-05 16:53:58,106 - INFO - 진행률: 5650/6900 (81.9%)\n",
      "2025-09-05 16:53:58,164 - INFO - 진행률: 5660/6900 (82.0%)\n",
      "2025-09-05 16:53:58,261 - INFO - 진행률: 5670/6900 (82.2%)\n",
      "2025-09-05 16:53:58,301 - INFO - 진행률: 5680/6900 (82.3%)\n",
      "2025-09-05 16:53:58,367 - INFO - 진행률: 5690/6900 (82.5%)\n",
      "2025-09-05 16:53:58,544 - INFO - 진행률: 5700/6900 (82.6%)\n",
      "2025-09-05 16:54:00,547 - INFO - 배치 처리 중: ID 5801 ~ 5900\n",
      "2025-09-05 16:54:00,747 - INFO - 진행률: 5710/6900 (82.8%)\n",
      "2025-09-05 16:54:00,872 - INFO - 진행률: 5720/6900 (82.9%)\n",
      "2025-09-05 16:54:00,891 - INFO - 진행률: 5730/6900 (83.0%)\n",
      "2025-09-05 16:54:01,001 - INFO - 진행률: 5740/6900 (83.2%)\n",
      "2025-09-05 16:54:01,063 - INFO - 진행률: 5750/6900 (83.3%)\n",
      "2025-09-05 16:54:01,096 - INFO - 진행률: 5760/6900 (83.5%)\n",
      "2025-09-05 16:54:01,201 - INFO - 진행률: 5770/6900 (83.6%)\n",
      "2025-09-05 16:54:01,261 - INFO - 진행률: 5780/6900 (83.8%)\n",
      "2025-09-05 16:54:01,375 - INFO - 진행률: 5790/6900 (83.9%)\n",
      "2025-09-05 16:54:01,487 - INFO - 진행률: 5800/6900 (84.1%)\n",
      "2025-09-05 16:54:03,490 - INFO - 배치 처리 중: ID 5901 ~ 6000\n",
      "2025-09-05 16:54:03,805 - INFO - 진행률: 5810/6900 (84.2%)\n",
      "2025-09-05 16:54:03,825 - INFO - 진행률: 5820/6900 (84.3%)\n",
      "2025-09-05 16:54:03,837 - INFO - 진행률: 5830/6900 (84.5%)\n",
      "2025-09-05 16:54:03,981 - INFO - 진행률: 5840/6900 (84.6%)\n",
      "2025-09-05 16:54:04,013 - INFO - 진행률: 5850/6900 (84.8%)\n",
      "2025-09-05 16:54:04,099 - INFO - 진행률: 5860/6900 (84.9%)\n",
      "2025-09-05 16:54:04,159 - INFO - 진행률: 5870/6900 (85.1%)\n",
      "2025-09-05 16:54:04,222 - INFO - 진행률: 5880/6900 (85.2%)\n",
      "2025-09-05 16:54:04,312 - INFO - 진행률: 5890/6900 (85.4%)\n",
      "2025-09-05 16:54:04,608 - INFO - 진행률: 5900/6900 (85.5%)\n",
      "2025-09-05 16:54:06,611 - INFO - 배치 처리 중: ID 6001 ~ 6100\n",
      "2025-09-05 16:54:07,386 - INFO - 진행률: 5910/6900 (85.7%)\n",
      "2025-09-05 16:54:07,521 - INFO - 진행률: 5920/6900 (85.8%)\n",
      "2025-09-05 16:54:07,714 - INFO - 진행률: 5930/6900 (85.9%)\n",
      "2025-09-05 16:54:08,037 - INFO - 진행률: 5940/6900 (86.1%)\n",
      "2025-09-05 16:54:08,229 - INFO - 진행률: 5950/6900 (86.2%)\n",
      "2025-09-05 16:54:08,396 - INFO - 진행률: 5960/6900 (86.4%)\n",
      "2025-09-05 16:54:08,603 - INFO - 진행률: 5970/6900 (86.5%)\n",
      "2025-09-05 16:54:08,687 - INFO - 진행률: 5980/6900 (86.7%)\n",
      "2025-09-05 16:54:09,140 - INFO - 진행률: 5990/6900 (86.8%)\n",
      "2025-09-05 16:54:28,349 - INFO - 진행률: 6000/6900 (87.0%)\n",
      "2025-09-05 16:54:30,355 - INFO - 배치 처리 중: ID 6101 ~ 6200\n",
      "2025-09-05 16:54:30,984 - INFO - 진행률: 6010/6900 (87.1%)\n",
      "2025-09-05 16:54:31,208 - INFO - 진행률: 6020/6900 (87.2%)\n",
      "2025-09-05 16:54:31,349 - INFO - 진행률: 6030/6900 (87.4%)\n",
      "2025-09-05 16:54:31,471 - INFO - 진행률: 6040/6900 (87.5%)\n",
      "2025-09-05 16:54:31,669 - INFO - 진행률: 6050/6900 (87.7%)\n",
      "2025-09-05 16:54:32,171 - INFO - 진행률: 6060/6900 (87.8%)\n",
      "2025-09-05 16:54:32,305 - INFO - 진행률: 6070/6900 (88.0%)\n",
      "2025-09-05 16:54:32,457 - INFO - 진행률: 6080/6900 (88.1%)\n",
      "2025-09-05 16:54:32,610 - INFO - 진행률: 6090/6900 (88.3%)\n",
      "2025-09-05 16:54:32,912 - INFO - 진행률: 6100/6900 (88.4%)\n",
      "2025-09-05 16:54:34,916 - INFO - 배치 처리 중: ID 6201 ~ 6300\n",
      "2025-09-05 16:54:35,557 - INFO - 진행률: 6110/6900 (88.6%)\n",
      "2025-09-05 16:54:35,692 - INFO - 진행률: 6120/6900 (88.7%)\n",
      "2025-09-05 16:54:35,817 - INFO - 진행률: 6130/6900 (88.8%)\n",
      "2025-09-05 16:54:36,032 - INFO - 진행률: 6140/6900 (89.0%)\n",
      "2025-09-05 16:54:36,499 - INFO - 진행률: 6150/6900 (89.1%)\n",
      "2025-09-05 16:54:36,682 - INFO - 진행률: 6160/6900 (89.3%)\n",
      "2025-09-05 16:54:36,789 - INFO - 진행률: 6170/6900 (89.4%)\n",
      "2025-09-05 16:54:36,993 - INFO - 진행률: 6180/6900 (89.6%)\n",
      "2025-09-05 16:54:37,228 - INFO - 진행률: 6190/6900 (89.7%)\n",
      "2025-09-05 16:54:37,333 - INFO - 진행률: 6200/6900 (89.9%)\n",
      "2025-09-05 16:54:39,338 - INFO - 배치 처리 중: ID 6301 ~ 6400\n",
      "2025-09-05 16:54:39,931 - INFO - 진행률: 6210/6900 (90.0%)\n",
      "2025-09-05 16:54:40,080 - INFO - 진행률: 6220/6900 (90.1%)\n",
      "2025-09-05 16:54:40,452 - INFO - 진행률: 6230/6900 (90.3%)\n",
      "2025-09-05 16:54:40,623 - INFO - 진행률: 6240/6900 (90.4%)\n",
      "2025-09-05 16:54:40,760 - INFO - 진행률: 6250/6900 (90.6%)\n",
      "2025-09-05 16:54:40,972 - INFO - 진행률: 6260/6900 (90.7%)\n",
      "2025-09-05 16:54:41,205 - INFO - 진행률: 6270/6900 (90.9%)\n",
      "2025-09-05 16:54:41,442 - INFO - 진행률: 6280/6900 (91.0%)\n",
      "2025-09-05 16:54:41,579 - INFO - 진행률: 6290/6900 (91.2%)\n",
      "2025-09-05 16:54:41,666 - INFO - 진행률: 6300/6900 (91.3%)\n",
      "2025-09-05 16:54:43,671 - INFO - 배치 처리 중: ID 6401 ~ 6500\n",
      "2025-09-05 16:54:44,403 - INFO - 진행률: 6310/6900 (91.4%)\n",
      "2025-09-05 16:54:44,568 - INFO - 진행률: 6320/6900 (91.6%)\n",
      "2025-09-05 16:54:44,698 - INFO - 진행률: 6330/6900 (91.7%)\n",
      "2025-09-05 16:54:44,971 - INFO - 진행률: 6340/6900 (91.9%)\n",
      "2025-09-05 16:54:45,222 - INFO - 진행률: 6350/6900 (92.0%)\n",
      "2025-09-05 16:54:45,370 - INFO - 진행률: 6360/6900 (92.2%)\n",
      "2025-09-05 16:54:45,595 - INFO - 진행률: 6370/6900 (92.3%)\n",
      "2025-09-05 16:54:45,744 - INFO - 진행률: 6380/6900 (92.5%)\n",
      "2025-09-05 16:54:45,947 - INFO - 진행률: 6390/6900 (92.6%)\n",
      "2025-09-05 16:54:46,033 - INFO - 진행률: 6400/6900 (92.8%)\n",
      "2025-09-05 16:54:48,035 - INFO - 배치 처리 중: ID 6501 ~ 6600\n",
      "2025-09-05 16:54:48,730 - INFO - 진행률: 6410/6900 (92.9%)\n",
      "2025-09-05 16:54:48,885 - INFO - 진행률: 6420/6900 (93.0%)\n",
      "2025-09-05 16:54:49,015 - INFO - 진행률: 6430/6900 (93.2%)\n",
      "2025-09-05 16:54:49,174 - INFO - 진행률: 6440/6900 (93.3%)\n",
      "2025-09-05 16:54:49,367 - INFO - 진행률: 6450/6900 (93.5%)\n",
      "2025-09-05 16:54:49,607 - INFO - 진행률: 6460/6900 (93.6%)\n",
      "2025-09-05 16:54:49,782 - INFO - 진행률: 6470/6900 (93.8%)\n",
      "2025-09-05 16:54:49,916 - INFO - 진행률: 6480/6900 (93.9%)\n",
      "2025-09-05 16:54:50,102 - INFO - 진행률: 6490/6900 (94.1%)\n",
      "2025-09-05 16:54:50,384 - INFO - 진행률: 6500/6900 (94.2%)\n",
      "2025-09-05 16:54:52,389 - INFO - 배치 처리 중: ID 6601 ~ 6700\n",
      "2025-09-05 16:54:52,763 - INFO - 진행률: 6510/6900 (94.3%)\n",
      "2025-09-05 16:54:52,978 - INFO - 진행률: 6520/6900 (94.5%)\n",
      "2025-09-05 16:54:53,171 - INFO - 진행률: 6530/6900 (94.6%)\n",
      "2025-09-05 16:54:53,301 - INFO - 진행률: 6540/6900 (94.8%)\n",
      "2025-09-05 16:54:53,447 - INFO - 진행률: 6550/6900 (94.9%)\n",
      "2025-09-05 16:54:53,829 - INFO - 진행률: 6560/6900 (95.1%)\n",
      "2025-09-05 16:54:54,028 - INFO - 진행률: 6570/6900 (95.2%)\n",
      "2025-09-05 16:54:54,156 - INFO - 진행률: 6580/6900 (95.4%)\n",
      "2025-09-05 16:54:54,511 - INFO - 진행률: 6590/6900 (95.5%)\n",
      "2025-09-05 16:54:54,598 - INFO - 진행률: 6600/6900 (95.7%)\n",
      "2025-09-05 16:54:56,601 - INFO - 배치 처리 중: ID 6701 ~ 6800\n",
      "2025-09-05 16:54:57,119 - INFO - 진행률: 6610/6900 (95.8%)\n",
      "2025-09-05 16:54:57,227 - INFO - 진행률: 6620/6900 (95.9%)\n",
      "2025-09-05 16:54:57,330 - INFO - 진행률: 6630/6900 (96.1%)\n",
      "2025-09-05 16:54:57,481 - INFO - 진행률: 6640/6900 (96.2%)\n",
      "2025-09-05 16:54:57,687 - INFO - 진행률: 6650/6900 (96.4%)\n",
      "2025-09-05 16:54:57,916 - INFO - 진행률: 6660/6900 (96.5%)\n",
      "2025-09-05 16:54:58,106 - INFO - 진행률: 6670/6900 (96.7%)\n",
      "2025-09-05 16:54:58,249 - INFO - 진행률: 6680/6900 (96.8%)\n",
      "2025-09-05 16:54:58,609 - INFO - 진행률: 6690/6900 (97.0%)\n",
      "2025-09-05 16:54:58,684 - INFO - 진행률: 6700/6900 (97.1%)\n",
      "2025-09-05 16:55:00,688 - INFO - 배치 처리 중: ID 6801 ~ 6900\n",
      "2025-09-05 16:55:01,170 - INFO - 진행률: 6710/6900 (97.2%)\n",
      "2025-09-05 16:55:01,270 - INFO - 진행률: 6720/6900 (97.4%)\n",
      "2025-09-05 16:55:01,375 - INFO - 진행률: 6730/6900 (97.5%)\n",
      "2025-09-05 16:55:01,511 - INFO - 진행률: 6740/6900 (97.7%)\n",
      "2025-09-05 16:55:01,740 - INFO - 진행률: 6750/6900 (97.8%)\n",
      "2025-09-05 16:55:01,979 - INFO - 진행률: 6760/6900 (98.0%)\n",
      "2025-09-05 16:55:02,087 - INFO - 진행률: 6770/6900 (98.1%)\n",
      "2025-09-05 16:55:02,194 - INFO - 진행률: 6780/6900 (98.3%)\n",
      "2025-09-05 16:55:02,295 - INFO - 진행률: 6790/6900 (98.4%)\n",
      "2025-09-05 16:55:02,483 - INFO - 진행률: 6800/6900 (98.6%)\n",
      "2025-09-05 16:55:04,488 - INFO - 배치 처리 중: ID 6901 ~ 7000\n",
      "2025-09-05 16:55:04,994 - INFO - 진행률: 6810/6900 (98.7%)\n",
      "2025-09-05 16:55:05,208 - INFO - 진행률: 6820/6900 (98.8%)\n",
      "2025-09-05 16:55:05,268 - INFO - 진행률: 6830/6900 (99.0%)\n",
      "2025-09-05 16:55:05,336 - INFO - 진행률: 6840/6900 (99.1%)\n",
      "2025-09-05 16:55:05,426 - INFO - 진행률: 6850/6900 (99.3%)\n",
      "2025-09-05 16:55:05,481 - INFO - 진행률: 6860/6900 (99.4%)\n",
      "2025-09-05 16:55:05,573 - INFO - 진행률: 6870/6900 (99.6%)\n",
      "2025-09-05 16:55:05,634 - INFO - 진행률: 6880/6900 (99.7%)\n",
      "2025-09-05 16:55:05,680 - INFO - 진행률: 6890/6900 (99.9%)\n",
      "2025-09-05 16:55:06,019 - INFO - 진행률: 6900/6900 (100.0%)\n",
      "2025-09-05 16:55:08,074 - INFO - CSV 파일 저장 완료: anilife_data_20250905_165508.csv\n",
      "2025-09-05 16:55:08,075 - INFO - 성공 데이터: 4420개 항목\n",
      "2025-09-05 16:55:08,086 - INFO - CSV 파일 저장 완료: anilife_errors_20250905_165508.csv\n",
      "2025-09-05 16:55:08,086 - INFO - 에러 데이터: 2480개 항목\n",
      "2025-09-05 16:55:08,087 - INFO - \n",
      "크롤링 완료 통계:\n",
      "2025-09-05 16:55:08,088 - INFO - - 전체: 6900개\n",
      "2025-09-05 16:55:08,089 - INFO - - 성공: 4420개\n",
      "2025-09-05 16:55:08,089 - INFO - - 실패: 2480개\n",
      "2025-09-05 16:55:08,089 - INFO - - 성공률: 64.1%\n",
      "2025-09-05 16:55:08,090 - INFO - \n",
      "총 소요 시간: 0시간 4분 48초\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9193ca8b73ffab1e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
